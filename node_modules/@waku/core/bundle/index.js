import { e as equals$2, c as coerce, b as base32, a as base58btc, d as base36, s as sha256$1, f as concat$1, u as utf8ToBytes, v as version_0, g as allocUnsafe, h as alloc, i as encodingLength$1, j as encode$3, k as decode$4, L as Logger, F as FilterSubscribeRequest, l as FilterSubscribeResponse$1, M as MessagePush, P as PushRpc$1, m as LightPushRequestV3, n as LightPushResponseV3, S as StoreQueryRequest$1, o as StoreQueryResponse$1, t as toString, p as fromString, q as hexToBytes, r as isBytes, w as abytes, x as bytesToHex, y as concatBytes, z as anumber, A as randomBytes, B as sha512, C as enumeration, D as message, E as encodeMessage, G as decodeMessage, H as Hash, I as ahash, J as toBytes, K as clean, N as aexists, O as sha256$2, Q as bases, R as base64url, T as encodeUint8Array, U as bytesToUtf8, V as createEncoder, W as WakuMetadataRequest, X as WakuMetadataResponse } from './version_0-BnCDWsGV.js';
export { Y as createDecoder, Z as messageHash, _ as messageHashStr } from './version_0-BnCDWsGV.js';

/* eslint-disable */
var encode_1 = encode$2;
var MSB = 0x80, MSBALL = -128, INT = Math.pow(2, 31);
/**
 * @param {number} num
 * @param {number[]} out
 * @param {number} offset
 */
function encode$2(num, out, offset) {
    out = out || [];
    offset = offset || 0;
    var oldOffset = offset;
    while (num >= INT) {
        out[offset++] = (num & 0xFF) | MSB;
        num /= 128;
    }
    while (num & MSBALL) {
        out[offset++] = (num & 0xFF) | MSB;
        num >>>= 7;
    }
    out[offset] = num | 0;
    // @ts-ignore
    encode$2.bytes = offset - oldOffset + 1;
    return out;
}
var decode$3 = read;
var MSB$1 = 0x80, REST$1 = 0x7F;
/**
 * @param {string | any[]} buf
 * @param {number} offset
 */
function read(buf, offset) {
    var res = 0, offset = offset || 0, shift = 0, counter = offset, b, l = buf.length;
    do {
        if (counter >= l) {
            // @ts-ignore
            read.bytes = 0;
            throw new RangeError('Could not decode varint');
        }
        b = buf[counter++];
        res += shift < 28
            ? (b & REST$1) << shift
            : (b & REST$1) * Math.pow(2, shift);
        shift += 7;
    } while (b >= MSB$1);
    // @ts-ignore
    read.bytes = counter - offset;
    return res;
}
var N1 = Math.pow(2, 7);
var N2 = Math.pow(2, 14);
var N3 = Math.pow(2, 21);
var N4 = Math.pow(2, 28);
var N5 = Math.pow(2, 35);
var N6 = Math.pow(2, 42);
var N7 = Math.pow(2, 49);
var N8 = Math.pow(2, 56);
var N9 = Math.pow(2, 63);
var length = function (/** @type {number} */ value) {
    return (value < N1 ? 1
        : value < N2 ? 2
            : value < N3 ? 3
                : value < N4 ? 4
                    : value < N5 ? 5
                        : value < N6 ? 6
                            : value < N7 ? 7
                                : value < N8 ? 8
                                    : value < N9 ? 9
                                        : 10);
};
var varint = {
    encode: encode_1,
    decode: decode$3,
    encodingLength: length
};
var _brrp_varint = varint;

function decode$2(data, offset = 0) {
    const code = _brrp_varint.decode(data, offset);
    return [code, _brrp_varint.decode.bytes];
}
function encodeTo(int, target, offset = 0) {
    _brrp_varint.encode(int, target, offset);
    return target;
}
function encodingLength(int) {
    return _brrp_varint.encodingLength(int);
}

/**
 * Creates a multihash digest.
 */
function create(code, digest) {
    const size = digest.byteLength;
    const sizeOffset = encodingLength(code);
    const digestOffset = sizeOffset + encodingLength(size);
    const bytes = new Uint8Array(digestOffset + size);
    encodeTo(code, bytes, 0);
    encodeTo(size, bytes, sizeOffset);
    bytes.set(digest, digestOffset);
    return new Digest(code, size, digest, bytes);
}
/**
 * Turns bytes representation of multihash digest into an instance.
 */
function decode$1(multihash) {
    const bytes = coerce(multihash);
    const [code, sizeOffset] = decode$2(bytes);
    const [size, digestOffset] = decode$2(bytes.subarray(sizeOffset));
    const digest = bytes.subarray(sizeOffset + digestOffset);
    if (digest.byteLength !== size) {
        throw new Error('Incorrect length');
    }
    return new Digest(code, size, digest, bytes);
}
function equals$1(a, b) {
    if (a === b) {
        return true;
    }
    else {
        const data = b;
        return (a.code === data.code &&
            a.size === data.size &&
            data.bytes instanceof Uint8Array &&
            equals$2(a.bytes, data.bytes));
    }
}
/**
 * Represents a multihash digest which carries information about the
 * hashing algorithm and an actual hash digest.
 */
class Digest {
    code;
    size;
    digest;
    bytes;
    /**
     * Creates a multihash digest.
     */
    constructor(code, size, digest, bytes) {
        this.code = code;
        this.size = size;
        this.digest = digest;
        this.bytes = bytes;
    }
}

const code = 0x0;
const name = 'identity';
const encode$1 = coerce;
function digest(input) {
    return create(code, encode$1(input));
}
const identity = { code, name, encode: encode$1, digest };

function from({ name, code, encode }) {
    return new Hasher(name, code, encode);
}
/**
 * Hasher represents a hashing algorithm implementation that produces as
 * `MultihashDigest`.
 */
class Hasher {
    name;
    code;
    encode;
    constructor(name, code, encode) {
        this.name = name;
        this.code = code;
        this.encode = encode;
    }
    digest(input) {
        if (input instanceof Uint8Array) {
            const result = this.encode(input);
            return result instanceof Uint8Array
                ? create(this.code, result)
                /* c8 ignore next 1 */
                : result.then(digest => create(this.code, digest));
        }
        else {
            throw Error('Unknown type, must be binary type');
            /* c8 ignore next 1 */
        }
    }
}

/* global crypto */
function sha(name) {
    return async (data) => new Uint8Array(await crypto.subtle.digest(name, data));
}
const sha256 = from({
    name: 'sha2-256',
    code: 0x12,
    encode: sha('SHA-256')
});

function format(link, base) {
    const { bytes, version } = link;
    switch (version) {
        case 0:
            return toStringV0(bytes, baseCache(link), base ?? base58btc.encoder);
        default:
            return toStringV1(bytes, baseCache(link), (base ?? base32.encoder));
    }
}
const cache = new WeakMap();
function baseCache(cid) {
    const baseCache = cache.get(cid);
    if (baseCache == null) {
        const baseCache = new Map();
        cache.set(cid, baseCache);
        return baseCache;
    }
    return baseCache;
}
class CID {
    code;
    version;
    multihash;
    bytes;
    '/';
    /**
     * @param version - Version of the CID
     * @param code - Code of the codec content is encoded in, see https://github.com/multiformats/multicodec/blob/master/table.csv
     * @param multihash - (Multi)hash of the of the content.
     */
    constructor(version, code, multihash, bytes) {
        this.code = code;
        this.version = version;
        this.multihash = multihash;
        this.bytes = bytes;
        // flag to serializers that this is a CID and
        // should be treated specially
        this['/'] = bytes;
    }
    /**
     * Signalling `cid.asCID === cid` has been replaced with `cid['/'] === cid.bytes`
     * please either use `CID.asCID(cid)` or switch to new signalling mechanism
     *
     * @deprecated
     */
    get asCID() {
        return this;
    }
    // ArrayBufferView
    get byteOffset() {
        return this.bytes.byteOffset;
    }
    // ArrayBufferView
    get byteLength() {
        return this.bytes.byteLength;
    }
    toV0() {
        switch (this.version) {
            case 0: {
                return this;
            }
            case 1: {
                const { code, multihash } = this;
                if (code !== DAG_PB_CODE) {
                    throw new Error('Cannot convert a non dag-pb CID to CIDv0');
                }
                // sha2-256
                if (multihash.code !== SHA_256_CODE) {
                    throw new Error('Cannot convert non sha2-256 multihash CID to CIDv0');
                }
                return (CID.createV0(multihash));
            }
            default: {
                throw Error(`Can not convert CID version ${this.version} to version 0. This is a bug please report`);
            }
        }
    }
    toV1() {
        switch (this.version) {
            case 0: {
                const { code, digest } = this.multihash;
                const multihash = create(code, digest);
                return (CID.createV1(this.code, multihash));
            }
            case 1: {
                return this;
            }
            default: {
                throw Error(`Can not convert CID version ${this.version} to version 1. This is a bug please report`);
            }
        }
    }
    equals(other) {
        return CID.equals(this, other);
    }
    static equals(self, other) {
        const unknown = other;
        return (unknown != null &&
            self.code === unknown.code &&
            self.version === unknown.version &&
            equals$1(self.multihash, unknown.multihash));
    }
    toString(base) {
        return format(this, base);
    }
    toJSON() {
        return { '/': format(this) };
    }
    link() {
        return this;
    }
    [Symbol.toStringTag] = 'CID';
    // Legacy
    [Symbol.for('nodejs.util.inspect.custom')]() {
        return `CID(${this.toString()})`;
    }
    /**
     * Takes any input `value` and returns a `CID` instance if it was
     * a `CID` otherwise returns `null`. If `value` is instanceof `CID`
     * it will return value back. If `value` is not instance of this CID
     * class, but is compatible CID it will return new instance of this
     * `CID` class. Otherwise returns null.
     *
     * This allows two different incompatible versions of CID library to
     * co-exist and interop as long as binary interface is compatible.
     */
    static asCID(input) {
        if (input == null) {
            return null;
        }
        const value = input;
        if (value instanceof CID) {
            // If value is instance of CID then we're all set.
            return value;
        }
        else if ((value['/'] != null && value['/'] === value.bytes) || value.asCID === value) {
            // If value isn't instance of this CID class but `this.asCID === this` or
            // `value['/'] === value.bytes` is true it is CID instance coming from a
            // different implementation (diff version or duplicate). In that case we
            // rebase it to this `CID` implementation so caller is guaranteed to get
            // instance with expected API.
            const { version, code, multihash, bytes } = value;
            return new CID(version, code, multihash, bytes ?? encodeCID(version, code, multihash.bytes));
        }
        else if (value[cidSymbol] === true) {
            // If value is a CID from older implementation that used to be tagged via
            // symbol we still rebase it to the this `CID` implementation by
            // delegating that to a constructor.
            const { version, multihash, code } = value;
            const digest = decode$1(multihash);
            return CID.create(version, code, digest);
        }
        else {
            // Otherwise value is not a CID (or an incompatible version of it) in
            // which case we return `null`.
            return null;
        }
    }
    /**
     * @param version - Version of the CID
     * @param code - Code of the codec content is encoded in, see https://github.com/multiformats/multicodec/blob/master/table.csv
     * @param digest - (Multi)hash of the of the content.
     */
    static create(version, code, digest) {
        if (typeof code !== 'number') {
            throw new Error('String codecs are no longer supported');
        }
        if (!(digest.bytes instanceof Uint8Array)) {
            throw new Error('Invalid digest');
        }
        switch (version) {
            case 0: {
                if (code !== DAG_PB_CODE) {
                    throw new Error(`Version 0 CID must use dag-pb (code: ${DAG_PB_CODE}) block encoding`);
                }
                else {
                    return new CID(version, code, digest, digest.bytes);
                }
            }
            case 1: {
                const bytes = encodeCID(version, code, digest.bytes);
                return new CID(version, code, digest, bytes);
            }
            default: {
                throw new Error('Invalid version');
            }
        }
    }
    /**
     * Simplified version of `create` for CIDv0.
     */
    static createV0(digest) {
        return CID.create(0, DAG_PB_CODE, digest);
    }
    /**
     * Simplified version of `create` for CIDv1.
     *
     * @param code - Content encoding format code.
     * @param digest - Multihash of the content.
     */
    static createV1(code, digest) {
        return CID.create(1, code, digest);
    }
    /**
     * Decoded a CID from its binary representation. The byte array must contain
     * only the CID with no additional bytes.
     *
     * An error will be thrown if the bytes provided do not contain a valid
     * binary representation of a CID.
     */
    static decode(bytes) {
        const [cid, remainder] = CID.decodeFirst(bytes);
        if (remainder.length !== 0) {
            throw new Error('Incorrect length');
        }
        return cid;
    }
    /**
     * Decoded a CID from its binary representation at the beginning of a byte
     * array.
     *
     * Returns an array with the first element containing the CID and the second
     * element containing the remainder of the original byte array. The remainder
     * will be a zero-length byte array if the provided bytes only contained a
     * binary CID representation.
     */
    static decodeFirst(bytes) {
        const specs = CID.inspectBytes(bytes);
        const prefixSize = specs.size - specs.multihashSize;
        const multihashBytes = coerce(bytes.subarray(prefixSize, prefixSize + specs.multihashSize));
        if (multihashBytes.byteLength !== specs.multihashSize) {
            throw new Error('Incorrect length');
        }
        const digestBytes = multihashBytes.subarray(specs.multihashSize - specs.digestSize);
        const digest = new Digest(specs.multihashCode, specs.digestSize, digestBytes, multihashBytes);
        const cid = specs.version === 0
            ? CID.createV0(digest)
            : CID.createV1(specs.codec, digest);
        return [cid, bytes.subarray(specs.size)];
    }
    /**
     * Inspect the initial bytes of a CID to determine its properties.
     *
     * Involves decoding up to 4 varints. Typically this will require only 4 to 6
     * bytes but for larger multicodec code values and larger multihash digest
     * lengths these varints can be quite large. It is recommended that at least
     * 10 bytes be made available in the `initialBytes` argument for a complete
     * inspection.
     */
    static inspectBytes(initialBytes) {
        let offset = 0;
        const next = () => {
            const [i, length] = decode$2(initialBytes.subarray(offset));
            offset += length;
            return i;
        };
        let version = next();
        let codec = DAG_PB_CODE;
        if (version === 18) {
            // CIDv0
            version = 0;
            offset = 0;
        }
        else {
            codec = next();
        }
        if (version !== 0 && version !== 1) {
            throw new RangeError(`Invalid CID version ${version}`);
        }
        const prefixSize = offset;
        const multihashCode = next(); // multihash code
        const digestSize = next(); // multihash length
        const size = offset + digestSize;
        const multihashSize = size - prefixSize;
        return { version, codec, multihashCode, digestSize, multihashSize, size };
    }
    /**
     * Takes cid in a string representation and creates an instance. If `base`
     * decoder is not provided will use a default from the configuration. It will
     * throw an error if encoding of the CID is not compatible with supplied (or
     * a default decoder).
     */
    static parse(source, base) {
        const [prefix, bytes] = parseCIDtoBytes(source, base);
        const cid = CID.decode(bytes);
        if (cid.version === 0 && source[0] !== 'Q') {
            throw Error('Version 0 CID string must not include multibase prefix');
        }
        // Cache string representation to avoid computing it on `this.toString()`
        baseCache(cid).set(prefix, source);
        return cid;
    }
}
function parseCIDtoBytes(source, base) {
    switch (source[0]) {
        // CIDv0 is parsed differently
        case 'Q': {
            const decoder = base ?? base58btc;
            return [
                base58btc.prefix,
                decoder.decode(`${base58btc.prefix}${source}`)
            ];
        }
        case base58btc.prefix: {
            const decoder = base ?? base58btc;
            return [base58btc.prefix, decoder.decode(source)];
        }
        case base32.prefix: {
            const decoder = base ?? base32;
            return [base32.prefix, decoder.decode(source)];
        }
        case base36.prefix: {
            const decoder = base ?? base36;
            return [base36.prefix, decoder.decode(source)];
        }
        default: {
            if (base == null) {
                throw Error('To parse non base32, base36 or base58btc encoded CID multibase decoder must be provided');
            }
            return [source[0], base.decode(source)];
        }
    }
}
function toStringV0(bytes, cache, base) {
    const { prefix } = base;
    if (prefix !== base58btc.prefix) {
        throw Error(`Cannot string encode V0 in ${base.name} encoding`);
    }
    const cid = cache.get(prefix);
    if (cid == null) {
        const cid = base.encode(bytes).slice(1);
        cache.set(prefix, cid);
        return cid;
    }
    else {
        return cid;
    }
}
function toStringV1(bytes, cache, base) {
    const { prefix } = base;
    const cid = cache.get(prefix);
    if (cid == null) {
        const cid = base.encode(bytes);
        cache.set(prefix, cid);
        return cid;
    }
    else {
        return cid;
    }
}
const DAG_PB_CODE = 0x70;
const SHA_256_CODE = 0x12;
function encodeCID(version, code, multihash) {
    const codeOffset = encodingLength(version);
    const hashOffset = codeOffset + encodingLength(code);
    const bytes = new Uint8Array(hashOffset + multihash.byteLength);
    encodeTo(version, bytes, 0);
    encodeTo(code, bytes, codeOffset);
    bytes.set(multihash, hashOffset);
    return bytes;
}
const cidSymbol = Symbol.for('@ipld/js-cid/CID');

const MB = 1024 ** 2;
const SIZE_CAP_IN_MB = 1;
/**
 * Return whether the size of the message is under the upper limit for the network.
 * This performs a protobuf encoding! If you have access to the fully encoded message,
 * use {@link isSizeUnderCapBuf} instead.
 * @param message
 * @param encoder
 */
async function isMessageSizeUnderCap(encoder, message) {
    const buf = await encoder.toWire(message);
    if (!buf)
        return false;
    return isWireSizeUnderCap(buf);
}
const isWireSizeUnderCap = (buf) => buf.length / MB <= SIZE_CAP_IN_MB;

function isAutoSharding(config) {
    return "clusterId" in config && "numShardsInCluster" in config;
}

const formatPubsubTopic = (clusterId, shard) => {
    return `/waku/2/rs/${clusterId}/${shard}`;
};
/**
 * @deprecated will be removed
 */
const pubsubTopicToSingleShardInfo = (pubsubTopics) => {
    const parts = pubsubTopics.split("/");
    if (parts.length != 6 ||
        parts[1] !== "waku" ||
        parts[2] !== "2" ||
        parts[3] !== "rs")
        throw new Error("Invalid pubsub topic");
    const clusterId = parseInt(parts[4]);
    const shard = parseInt(parts[5]);
    if (isNaN(clusterId) || isNaN(shard))
        throw new Error("Invalid clusterId or shard");
    return {
        clusterId,
        shard
    };
};
/**
 * Given a string, will throw an error if it is not formatted as a valid content topic for autosharding based on https://rfc.vac.dev/spec/51/
 * @param contentTopic String to validate
 * @returns Object with each content topic field as an attribute
 */
function ensureValidContentTopic(contentTopic) {
    const parts = contentTopic.split("/");
    if (parts.length < 5 || parts.length > 6) {
        throw Error(`Content topic format is invalid: ${contentTopic}`);
    }
    // Validate generation field if present
    let generation = 0;
    if (parts.length == 6) {
        generation = parseInt(parts[1]);
        if (isNaN(generation)) {
            throw new Error(`Invalid generation field in content topic: ${contentTopic}`);
        }
        if (generation > 0) {
            throw new Error(`Generation greater than 0 is not supported: ${contentTopic}`);
        }
    }
    // Validate remaining fields
    const fields = parts.splice(-4);
    // Validate application field
    if (fields[0].length == 0) {
        throw new Error(`Application field cannot be empty: ${contentTopic}`);
    }
    // Validate version field
    if (fields[1].length == 0) {
        throw new Error(`Version field cannot be empty: ${contentTopic}`);
    }
    // Validate topic name field
    if (fields[2].length == 0) {
        throw new Error(`Topic name field cannot be empty: ${contentTopic}`);
    }
    // Validate encoding field
    if (fields[3].length == 0) {
        throw new Error(`Encoding field cannot be empty: ${contentTopic}`);
    }
    return {
        generation,
        application: fields[0],
        version: fields[1],
        topicName: fields[2],
        encoding: fields[3]
    };
}
/**
 * Given a string, determines which autoshard index to use for its pubsub topic.
 * Based on the algorithm described in the RFC: https://rfc.vac.dev/spec/51//#algorithm
 */
function contentTopicToShardIndex(contentTopic, numShardsInCluster) {
    const { application, version } = ensureValidContentTopic(contentTopic);
    const digest = sha256$1(concat$1([utf8ToBytes(application), utf8ToBytes(version)]));
    const dataview = new DataView(digest.buffer.slice(-8));
    return Number(dataview.getBigUint64(0, false) % BigInt(numShardsInCluster));
}

class BaseRoutingInfo {
    networkConfig;
    pubsubTopic;
    shardId;
    constructor(networkConfig, pubsubTopic, shardId) {
        this.networkConfig = networkConfig;
        this.pubsubTopic = pubsubTopic;
        this.shardId = shardId;
    }
}
class AutoShardingRoutingInfo extends BaseRoutingInfo {
    networkConfig;
    pubsubTopic;
    shardId;
    contentTopic;
    static fromContentTopic(contentTopic, networkConfig) {
        ensureValidContentTopic(contentTopic);
        const shardId = contentTopicToShardIndex(contentTopic, networkConfig.numShardsInCluster);
        const pubsubTopic = formatPubsubTopic(networkConfig.clusterId, shardId);
        return new AutoShardingRoutingInfo(networkConfig, pubsubTopic, shardId, contentTopic);
    }
    /**
     * No checks are done with this constructor,
     * Be sure you check that the network config (auto vs static)
     * matches other parameters.
     */
    constructor(networkConfig, pubsubTopic, shardId, contentTopic) {
        super(networkConfig, pubsubTopic, shardId);
        this.networkConfig = networkConfig;
        this.pubsubTopic = pubsubTopic;
        this.shardId = shardId;
        this.contentTopic = contentTopic;
    }
    get clusterId() {
        return this.networkConfig.clusterId;
    }
    get isAutoSharding() {
        return true;
    }
    get isStaticSharding() {
        return false;
    }
}
class StaticShardingRoutingInfo extends BaseRoutingInfo {
    networkConfig;
    pubsubTopic;
    shardId;
    /**
     * Create Routing Info for static sharding network, using shard
     *
     * @param shardId
     * @param networkConfig
     */
    static fromShard(shardId, networkConfig) {
        const pubsubTopic = formatPubsubTopic(networkConfig.clusterId, shardId);
        return new StaticShardingRoutingInfo(networkConfig, pubsubTopic, shardId);
    }
    /**
     * Create Routing Info for static sharding network, using pubsub topic
     *
     * @param pubsubTopic
     * @param networkConfig
     *
     * @throws if the pubsub topic is malformed, or does not match the network config
     */
    static fromPubsubTopic(pubsubTopic, networkConfig) {
        const { clusterId, shard } = pubsubTopicToSingleShardInfo(pubsubTopic);
        if (clusterId != networkConfig.clusterId)
            throw "Pubsub topic does not match network config's cluster id";
        return new StaticShardingRoutingInfo(networkConfig, pubsubTopic, shard);
    }
    /**
     * No checks are done with this constructor,
     * Be sure you check that the network config (auto vs static)
     * matches other parameters.
     */
    constructor(networkConfig, pubsubTopic, shardId) {
        super(networkConfig, pubsubTopic, shardId);
        this.networkConfig = networkConfig;
        this.pubsubTopic = pubsubTopic;
        this.shardId = shardId;
    }
    get clusterId() {
        return this.networkConfig.clusterId;
    }
    get isAutoSharding() {
        return false;
    }
    get isStaticSharding() {
        return true;
    }
}
function createRoutingInfo(networkConfig, options) {
    if (isAutoSharding(networkConfig)) {
        if (options.contentTopic) {
            return AutoShardingRoutingInfo.fromContentTopic(options.contentTopic, networkConfig);
        }
        throw new Error("AutoSharding requires contentTopic");
    }
    else {
        if (options.shardId !== undefined) {
            return StaticShardingRoutingInfo.fromShard(options.shardId, networkConfig);
        }
        else if (options.pubsubTopic) {
            return StaticShardingRoutingInfo.fromPubsubTopic(options.pubsubTopic, networkConfig);
        }
        throw new Error("StaticSharding requires shardId or pubsubTopic");
    }
}

const decodeRelayShard = (bytes) => {
    // explicitly converting to Uint8Array to avoid Buffer
    // https://github.com/libp2p/js-libp2p/issues/2146
    bytes = new Uint8Array(bytes);
    if (bytes.length < 3)
        throw new Error("Insufficient data");
    const view = new DataView(bytes.buffer);
    const clusterId = view.getUint16(0);
    const shards = [];
    if (bytes.length === 130) {
        // rsv format (Bit Vector)
        for (let i = 0; i < 1024; i++) {
            const byteIndex = Math.floor(i / 8) + 2; // Adjusted for the 2-byte cluster field
            const bitIndex = 7 - (i % 8);
            if (view.getUint8(byteIndex) & (1 << bitIndex)) {
                shards.push(i);
            }
        }
    }
    else {
        // rs format (Index List)
        const numIndices = view.getUint8(2);
        for (let i = 0, offset = 3; i < numIndices; i++, offset += 2) {
            if (offset + 1 >= bytes.length)
                throw new Error("Unexpected end of data");
            shards.push(view.getUint16(offset));
        }
    }
    return { clusterId, shards };
};
const encodeRelayShard = (shardInfo) => {
    const { clusterId, shards } = shardInfo;
    const totalLength = shards.length >= 64 ? 130 : 3 + 2 * shards.length;
    const buffer = new ArrayBuffer(totalLength);
    const view = new DataView(buffer);
    view.setUint16(0, clusterId);
    if (shards.length >= 64) {
        // rsv format (Bit Vector)
        for (const index of shards) {
            const byteIndex = Math.floor(index / 8) + 2; // Adjusted for the 2-byte cluster field
            const bitIndex = 7 - (index % 8);
            view.setUint8(byteIndex, view.getUint8(byteIndex) | (1 << bitIndex));
        }
    }
    else {
        // rs format (Index List)
        view.setUint8(2, shards.length);
        for (let i = 0, offset = 3; i < shards.length; i++, offset += 2) {
            view.setUint16(offset, shards[i]);
        }
    }
    return new Uint8Array(buffer);
};

/**
 * All PeerId implementations must use this symbol as the name of a property
 * with a boolean `true` value
 */
const peerIdSymbol = Symbol.for('@libp2p/peer-id');
/**
 * Returns true if the passed argument is a PeerId implementation
 */
function isPeerId(other) {
    return Boolean(other?.[peerIdSymbol]);
}

/**
 * When this error is thrown it means an operation was aborted,
 * usually in response to the `abort` event being emitted by an
 * AbortSignal.
 */
/**
 * Thrown when invalid parameters are passed to a function or method call
 */
let InvalidParametersError$1 = class InvalidParametersError extends Error {
    static name = 'InvalidParametersError';
    constructor(message = 'Invalid parameters') {
        super(message);
        this.name = 'InvalidParametersError';
    }
};
/**
 * Thrown when a public key is invalid
 */
class InvalidPublicKeyError extends Error {
    static name = 'InvalidPublicKeyError';
    constructor(message = 'Invalid public key') {
        super(message);
        this.name = 'InvalidPublicKeyError';
    }
}
/**
 * Thrown when an invalid CID is encountered
 */
class InvalidCIDError extends Error {
    static name = 'InvalidCIDError';
    constructor(message = 'Invalid CID') {
        super(message);
        this.name = 'InvalidCIDError';
    }
}
/**
 * Thrown when an invalid multihash is encountered
 */
class InvalidMultihashError extends Error {
    static name = 'InvalidMultihashError';
    constructor(message = 'Invalid Multihash') {
        super(message);
        this.name = 'InvalidMultihashError';
    }
}
/**
 * Thrown when an attempt to operate on an unsupported key was made
 */
class UnsupportedKeyTypeError extends Error {
    static name = 'UnsupportedKeyTypeError';
    constructor(message = 'Unsupported key type') {
        super(message);
        this.name = 'UnsupportedKeyTypeError';
    }
}

var index$3 = /*#__PURE__*/Object.freeze({
    __proto__: null,
    version_0: version_0
});

var LightPushStatusCode;
(function (LightPushStatusCode) {
    LightPushStatusCode[LightPushStatusCode["SUCCESS"] = 200] = "SUCCESS";
    LightPushStatusCode[LightPushStatusCode["BAD_REQUEST"] = 400] = "BAD_REQUEST";
    LightPushStatusCode[LightPushStatusCode["PAYLOAD_TOO_LARGE"] = 413] = "PAYLOAD_TOO_LARGE";
    LightPushStatusCode[LightPushStatusCode["INVALID_MESSAGE"] = 420] = "INVALID_MESSAGE";
    LightPushStatusCode[LightPushStatusCode["UNSUPPORTED_TOPIC"] = 421] = "UNSUPPORTED_TOPIC";
    LightPushStatusCode[LightPushStatusCode["TOO_MANY_REQUESTS"] = 429] = "TOO_MANY_REQUESTS";
    LightPushStatusCode[LightPushStatusCode["INTERNAL_ERROR"] = 500] = "INTERNAL_ERROR";
    LightPushStatusCode[LightPushStatusCode["UNAVAILABLE"] = 503] = "UNAVAILABLE";
    LightPushStatusCode[LightPushStatusCode["NO_RLN_PROOF"] = 504] = "NO_RLN_PROOF";
    LightPushStatusCode[LightPushStatusCode["NO_PEERS"] = 505] = "NO_PEERS";
})(LightPushStatusCode || (LightPushStatusCode = {}));
({
    [LightPushStatusCode.SUCCESS]: "Message sent successfully",
    [LightPushStatusCode.BAD_REQUEST]: "Bad request format",
    [LightPushStatusCode.PAYLOAD_TOO_LARGE]: "Message payload exceeds maximum size",
    [LightPushStatusCode.INVALID_MESSAGE]: "Message validation failed",
    [LightPushStatusCode.UNSUPPORTED_TOPIC]: "Unsupported pubsub topic",
    [LightPushStatusCode.TOO_MANY_REQUESTS]: "Rate limit exceeded",
    [LightPushStatusCode.INTERNAL_ERROR]: "Internal server error",
    [LightPushStatusCode.UNAVAILABLE]: "Service temporarily unavailable",
    [LightPushStatusCode.NO_RLN_PROOF]: "RLN proof generation failed",
    [LightPushStatusCode.NO_PEERS]: "No relay peers available"
});

var Protocols;
(function (Protocols) {
    Protocols["Relay"] = "relay";
    Protocols["Store"] = "store";
    Protocols["LightPush"] = "lightpush";
    Protocols["Filter"] = "filter";
})(Protocols || (Protocols = {}));
var LightPushError;
(function (LightPushError) {
    LightPushError["GENERIC_FAIL"] = "Generic error";
    LightPushError["DECODE_FAILED"] = "Failed to decode";
    LightPushError["NO_PEER_AVAILABLE"] = "No peer available";
    LightPushError["NO_STREAM_AVAILABLE"] = "No stream available";
    LightPushError["NO_RESPONSE"] = "No response received";
    LightPushError["STREAM_ABORTED"] = "Stream aborted";
    LightPushError["ENCODE_FAILED"] = "Failed to encode";
    LightPushError["EMPTY_PAYLOAD"] = "Payload is empty";
    LightPushError["SIZE_TOO_BIG"] = "Size is too big";
    LightPushError["TOPIC_NOT_CONFIGURED"] = "Topic not configured";
    LightPushError["RLN_PROOF_GENERATION"] = "Proof generation failed";
    LightPushError["REMOTE_PEER_REJECTED"] = "Remote peer rejected";
    LightPushError["BAD_REQUEST"] = "Bad request format";
    LightPushError["PAYLOAD_TOO_LARGE"] = "Message payload exceeds maximum size";
    LightPushError["INVALID_MESSAGE"] = "Message validation failed";
    LightPushError["UNSUPPORTED_TOPIC"] = "Unsupported pubsub topic";
    LightPushError["TOO_MANY_REQUESTS"] = "Rate limit exceeded";
    LightPushError["INTERNAL_ERROR"] = "Internal server error";
    LightPushError["UNAVAILABLE"] = "Service temporarily unavailable";
    LightPushError["NO_RLN_PROOF"] = "RLN proof generation failed";
    LightPushError["NO_PEERS"] = "No relay peers available";
})(LightPushError || (LightPushError = {}));
var FilterError;
(function (FilterError) {
    // General errors
    FilterError["GENERIC_FAIL"] = "Generic error";
    FilterError["DECODE_FAILED"] = "Failed to decode";
    FilterError["NO_PEER_AVAILABLE"] = "No peer available";
    FilterError["NO_STREAM_AVAILABLE"] = "No stream available";
    FilterError["NO_RESPONSE"] = "No response received";
    FilterError["STREAM_ABORTED"] = "Stream aborted";
    // Filter specific errors
    FilterError["REMOTE_PEER_REJECTED"] = "Remote peer rejected";
    FilterError["TOPIC_NOT_CONFIGURED"] = "Topic not configured";
    FilterError["SUBSCRIPTION_FAILED"] = "Subscription failed";
    FilterError["UNSUBSCRIBE_FAILED"] = "Unsubscribe failed";
    FilterError["PING_FAILED"] = "Ping failed";
    FilterError["TOPIC_DECODER_MISMATCH"] = "Topic decoder mismatch";
    FilterError["INVALID_DECODER_TOPICS"] = "Invalid decoder topics";
    FilterError["SUBSCRIPTION_LIMIT_EXCEEDED"] = "Subscription limit exceeded";
    FilterError["INVALID_CONTENT_TOPIC"] = "Invalid content topic";
    FilterError["PUSH_MESSAGE_FAILED"] = "Push message failed";
    FilterError["EMPTY_MESSAGE"] = "Empty message received";
    FilterError["MISSING_PUBSUB_TOPIC"] = "Pubsub topic missing from push message";
})(FilterError || (FilterError = {}));
/**
 * @deprecated replace usage by specific result types
 */
var ProtocolError;
(function (ProtocolError) {
    ProtocolError["GENERIC_FAIL"] = "Generic error";
    ProtocolError["REMOTE_PEER_REJECTED"] = "Remote peer rejected";
    ProtocolError["DECODE_FAILED"] = "Failed to decode";
    ProtocolError["NO_PEER_AVAILABLE"] = "No peer available";
    ProtocolError["NO_STREAM_AVAILABLE"] = "No stream available";
    ProtocolError["NO_RESPONSE"] = "No response received";
    ProtocolError["ENCODE_FAILED"] = "Failed to encode";
    ProtocolError["EMPTY_PAYLOAD"] = "Payload is empty";
    ProtocolError["SIZE_TOO_BIG"] = "Size is too big";
    ProtocolError["TOPIC_NOT_CONFIGURED"] = "Topic not configured";
    ProtocolError["STREAM_ABORTED"] = "Stream aborted";
    ProtocolError["RLN_PROOF_GENERATION"] = "Proof generation failed";
    ProtocolError["TOPIC_DECODER_MISMATCH"] = "Topic decoder mismatch";
    ProtocolError["INVALID_DECODER_TOPICS"] = "Invalid decoder topics";
})(ProtocolError || (ProtocolError = {}));

var WakuEvent;
(function (WakuEvent) {
    WakuEvent["Connection"] = "waku:connection";
    WakuEvent["Health"] = "waku:health";
})(WakuEvent || (WakuEvent = {}));

// Peer tags
var Tags;
(function (Tags) {
    Tags["BOOTSTRAP"] = "bootstrap";
    Tags["PEER_EXCHANGE"] = "peer-exchange";
    Tags["PEER_CACHE"] = "peer-cache";
})(Tags || (Tags = {}));
// Connection tag
const CONNECTION_LOCKED_TAG = "locked";

var HealthStatus;
(function (HealthStatus) {
    /**
     * No peer connections
     */
    HealthStatus["Unhealthy"] = "Unhealthy";
    /**
     * At least 1 peer supporting both Filter and LightPush protocols
     */
    HealthStatus["MinimallyHealthy"] = "MinimallyHealthy";
    /**
     * At least 2 peers supporting both Filter and LightPush protocols
     */
    HealthStatus["SufficientlyHealthy"] = "SufficientlyHealthy";
})(HealthStatus || (HealthStatus = {}));

/**
 * @packageDocumentation
 *
 * For when you need a one-liner to collect iterable values.
 *
 * @example
 *
 * ```javascript
 * import all from 'it-all'
 *
 * // This can also be an iterator, etc
 * const values = function * () {
 *   yield * [0, 1, 2, 3, 4]
 * }
 *
 * const arr = all(values)
 *
 * console.info(arr) // 0, 1, 2, 3, 4
 * ```
 *
 * Async sources must be awaited:
 *
 * ```javascript
 * const values = async function * () {
 *   yield * [0, 1, 2, 3, 4]
 * }
 *
 * const arr = await all(values())
 *
 * console.info(arr) // 0, 1, 2, 3, 4
 * ```
 */
function isAsyncIterable$3(thing) {
    return thing[Symbol.asyncIterator] != null;
}
function all(source) {
    if (isAsyncIterable$3(source)) {
        return (async () => {
            const arr = [];
            for await (const entry of source) {
                arr.push(entry);
            }
            return arr;
        })();
    }
    const arr = [];
    for (const entry of source) {
        arr.push(entry);
    }
    return arr;
}

/**
 * To guarantee Uint8Array semantics, convert nodejs Buffers
 * into vanilla Uint8Arrays
 */
function asUint8Array(buf) {
    return buf;
}

/**
 * Returns a new Uint8Array created by concatenating the passed Uint8Arrays
 */
function concat(arrays, length) {
    if (length == null) {
        length = arrays.reduce((acc, curr) => acc + curr.length, 0);
    }
    const output = allocUnsafe(length);
    let offset = 0;
    for (const arr of arrays) {
        output.set(arr, offset);
        offset += arr.length;
    }
    return asUint8Array(output);
}

/**
 * Returns true if the two passed Uint8Arrays have the same content
 */
function equals(a, b) {
    if (a === b) {
        return true;
    }
    if (a.byteLength !== b.byteLength) {
        return false;
    }
    for (let i = 0; i < a.byteLength; i++) {
        if (a[i] !== b[i]) {
            return false;
        }
    }
    return true;
}

/**
 * @packageDocumentation
 *
 * A class that lets you do operations over a list of Uint8Arrays without
 * copying them.
 *
 * ```js
 * import { Uint8ArrayList } from 'uint8arraylist'
 *
 * const list = new Uint8ArrayList()
 * list.append(Uint8Array.from([0, 1, 2]))
 * list.append(Uint8Array.from([3, 4, 5]))
 *
 * list.subarray()
 * // -> Uint8Array([0, 1, 2, 3, 4, 5])
 *
 * list.consume(3)
 * list.subarray()
 * // -> Uint8Array([3, 4, 5])
 *
 * // you can also iterate over the list
 * for (const buf of list) {
 *   // ..do something with `buf`
 * }
 *
 * list.subarray(0, 1)
 * // -> Uint8Array([0])
 * ```
 *
 * ## Converting Uint8ArrayLists to Uint8Arrays
 *
 * There are two ways to turn a `Uint8ArrayList` into a `Uint8Array` - `.slice` and `.subarray` and one way to turn a `Uint8ArrayList` into a `Uint8ArrayList` with different contents - `.sublist`.
 *
 * ### slice
 *
 * Slice follows the same semantics as [Uint8Array.slice](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray/slice) in that it creates a new `Uint8Array` and copies bytes into it using an optional offset & length.
 *
 * ```js
 * const list = new Uint8ArrayList()
 * list.append(Uint8Array.from([0, 1, 2]))
 * list.append(Uint8Array.from([3, 4, 5]))
 *
 * list.slice(0, 1)
 * // -> Uint8Array([0])
 * ```
 *
 * ### subarray
 *
 * Subarray attempts to follow the same semantics as [Uint8Array.subarray](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray/subarray) with one important different - this is a no-copy operation, unless the requested bytes span two internal buffers in which case it is a copy operation.
 *
 * ```js
 * const list = new Uint8ArrayList()
 * list.append(Uint8Array.from([0, 1, 2]))
 * list.append(Uint8Array.from([3, 4, 5]))
 *
 * list.subarray(0, 1)
 * // -> Uint8Array([0]) - no-copy
 *
 * list.subarray(2, 5)
 * // -> Uint8Array([2, 3, 4]) - copy
 * ```
 *
 * ### sublist
 *
 * Sublist creates and returns a new `Uint8ArrayList` that shares the underlying buffers with the original so is always a no-copy operation.
 *
 * ```js
 * const list = new Uint8ArrayList()
 * list.append(Uint8Array.from([0, 1, 2]))
 * list.append(Uint8Array.from([3, 4, 5]))
 *
 * list.sublist(0, 1)
 * // -> Uint8ArrayList([0]) - no-copy
 *
 * list.sublist(2, 5)
 * // -> Uint8ArrayList([2], [3, 4]) - no-copy
 * ```
 *
 * ## Inspiration
 *
 * Borrows liberally from [bl](https://www.npmjs.com/package/bl) but only uses native JS types.
 */
const symbol$1 = Symbol.for('@achingbrain/uint8arraylist');
function findBufAndOffset(bufs, index) {
    if (index == null || index < 0) {
        throw new RangeError('index is out of bounds');
    }
    let offset = 0;
    for (const buf of bufs) {
        const bufEnd = offset + buf.byteLength;
        if (index < bufEnd) {
            return {
                buf,
                index: index - offset
            };
        }
        offset = bufEnd;
    }
    throw new RangeError('index is out of bounds');
}
/**
 * Check if object is a CID instance
 *
 * @example
 *
 * ```js
 * import { isUint8ArrayList, Uint8ArrayList } from 'uint8arraylist'
 *
 * isUint8ArrayList(true) // false
 * isUint8ArrayList([]) // false
 * isUint8ArrayList(new Uint8ArrayList()) // true
 * ```
 */
function isUint8ArrayList(value) {
    return Boolean(value?.[symbol$1]);
}
class Uint8ArrayList {
    bufs;
    length;
    [symbol$1] = true;
    constructor(...data) {
        this.bufs = [];
        this.length = 0;
        if (data.length > 0) {
            this.appendAll(data);
        }
    }
    *[Symbol.iterator]() {
        yield* this.bufs;
    }
    get byteLength() {
        return this.length;
    }
    /**
     * Add one or more `bufs` to the end of this Uint8ArrayList
     */
    append(...bufs) {
        this.appendAll(bufs);
    }
    /**
     * Add all `bufs` to the end of this Uint8ArrayList
     */
    appendAll(bufs) {
        let length = 0;
        for (const buf of bufs) {
            if (buf instanceof Uint8Array) {
                length += buf.byteLength;
                this.bufs.push(buf);
            }
            else if (isUint8ArrayList(buf)) {
                length += buf.byteLength;
                this.bufs.push(...buf.bufs);
            }
            else {
                throw new Error('Could not append value, must be an Uint8Array or a Uint8ArrayList');
            }
        }
        this.length += length;
    }
    /**
     * Add one or more `bufs` to the start of this Uint8ArrayList
     */
    prepend(...bufs) {
        this.prependAll(bufs);
    }
    /**
     * Add all `bufs` to the start of this Uint8ArrayList
     */
    prependAll(bufs) {
        let length = 0;
        for (const buf of bufs.reverse()) {
            if (buf instanceof Uint8Array) {
                length += buf.byteLength;
                this.bufs.unshift(buf);
            }
            else if (isUint8ArrayList(buf)) {
                length += buf.byteLength;
                this.bufs.unshift(...buf.bufs);
            }
            else {
                throw new Error('Could not prepend value, must be an Uint8Array or a Uint8ArrayList');
            }
        }
        this.length += length;
    }
    /**
     * Read the value at `index`
     */
    get(index) {
        const res = findBufAndOffset(this.bufs, index);
        return res.buf[res.index];
    }
    /**
     * Set the value at `index` to `value`
     */
    set(index, value) {
        const res = findBufAndOffset(this.bufs, index);
        res.buf[res.index] = value;
    }
    /**
     * Copy bytes from `buf` to the index specified by `offset`
     */
    write(buf, offset = 0) {
        if (buf instanceof Uint8Array) {
            for (let i = 0; i < buf.length; i++) {
                this.set(offset + i, buf[i]);
            }
        }
        else if (isUint8ArrayList(buf)) {
            for (let i = 0; i < buf.length; i++) {
                this.set(offset + i, buf.get(i));
            }
        }
        else {
            throw new Error('Could not write value, must be an Uint8Array or a Uint8ArrayList');
        }
    }
    /**
     * Remove bytes from the front of the pool
     */
    consume(bytes) {
        // first, normalize the argument, in accordance with how Buffer does it
        bytes = Math.trunc(bytes);
        // do nothing if not a positive number
        if (Number.isNaN(bytes) || bytes <= 0) {
            return;
        }
        // if consuming all bytes, skip iterating
        if (bytes === this.byteLength) {
            this.bufs = [];
            this.length = 0;
            return;
        }
        while (this.bufs.length > 0) {
            if (bytes >= this.bufs[0].byteLength) {
                bytes -= this.bufs[0].byteLength;
                this.length -= this.bufs[0].byteLength;
                this.bufs.shift();
            }
            else {
                this.bufs[0] = this.bufs[0].subarray(bytes);
                this.length -= bytes;
                break;
            }
        }
    }
    /**
     * Extracts a section of an array and returns a new array.
     *
     * This is a copy operation as it is with Uint8Arrays and Arrays
     * - note this is different to the behaviour of Node Buffers.
     */
    slice(beginInclusive, endExclusive) {
        const { bufs, length } = this._subList(beginInclusive, endExclusive);
        return concat(bufs, length);
    }
    /**
     * Returns a alloc from the given start and end element index.
     *
     * In the best case where the data extracted comes from a single Uint8Array
     * internally this is a no-copy operation otherwise it is a copy operation.
     */
    subarray(beginInclusive, endExclusive) {
        const { bufs, length } = this._subList(beginInclusive, endExclusive);
        if (bufs.length === 1) {
            return bufs[0];
        }
        return concat(bufs, length);
    }
    /**
     * Returns a allocList from the given start and end element index.
     *
     * This is a no-copy operation.
     */
    sublist(beginInclusive, endExclusive) {
        const { bufs, length } = this._subList(beginInclusive, endExclusive);
        const list = new Uint8ArrayList();
        list.length = length;
        // don't loop, just set the bufs
        list.bufs = [...bufs];
        return list;
    }
    _subList(beginInclusive, endExclusive) {
        beginInclusive = beginInclusive ?? 0;
        endExclusive = endExclusive ?? this.length;
        if (beginInclusive < 0) {
            beginInclusive = this.length + beginInclusive;
        }
        if (endExclusive < 0) {
            endExclusive = this.length + endExclusive;
        }
        if (beginInclusive < 0 || endExclusive > this.length) {
            throw new RangeError('index is out of bounds');
        }
        if (beginInclusive === endExclusive) {
            return { bufs: [], length: 0 };
        }
        if (beginInclusive === 0 && endExclusive === this.length) {
            return { bufs: this.bufs, length: this.length };
        }
        const bufs = [];
        let offset = 0;
        for (let i = 0; i < this.bufs.length; i++) {
            const buf = this.bufs[i];
            const bufStart = offset;
            const bufEnd = bufStart + buf.byteLength;
            // for next loop
            offset = bufEnd;
            if (beginInclusive >= bufEnd) {
                // start after this buf
                continue;
            }
            const sliceStartInBuf = beginInclusive >= bufStart && beginInclusive < bufEnd;
            const sliceEndsInBuf = endExclusive > bufStart && endExclusive <= bufEnd;
            if (sliceStartInBuf && sliceEndsInBuf) {
                // slice is wholly contained within this buffer
                if (beginInclusive === bufStart && endExclusive === bufEnd) {
                    // requested whole buffer
                    bufs.push(buf);
                    break;
                }
                // requested part of buffer
                const start = beginInclusive - bufStart;
                bufs.push(buf.subarray(start, start + (endExclusive - beginInclusive)));
                break;
            }
            if (sliceStartInBuf) {
                // slice starts in this buffer
                if (beginInclusive === 0) {
                    // requested whole buffer
                    bufs.push(buf);
                    continue;
                }
                // requested part of buffer
                bufs.push(buf.subarray(beginInclusive - bufStart));
                continue;
            }
            if (sliceEndsInBuf) {
                if (endExclusive === bufEnd) {
                    // requested whole buffer
                    bufs.push(buf);
                    break;
                }
                // requested part of buffer
                bufs.push(buf.subarray(0, endExclusive - bufStart));
                break;
            }
            // slice started before this buffer and ends after it
            bufs.push(buf);
        }
        return { bufs, length: endExclusive - beginInclusive };
    }
    indexOf(search, offset = 0) {
        if (!isUint8ArrayList(search) && !(search instanceof Uint8Array)) {
            throw new TypeError('The "value" argument must be a Uint8ArrayList or Uint8Array');
        }
        const needle = search instanceof Uint8Array ? search : search.subarray();
        offset = Number(offset ?? 0);
        if (isNaN(offset)) {
            offset = 0;
        }
        if (offset < 0) {
            offset = this.length + offset;
        }
        if (offset < 0) {
            offset = 0;
        }
        if (search.length === 0) {
            return offset > this.length ? this.length : offset;
        }
        // https://en.wikipedia.org/wiki/Boyer%E2%80%93Moore_string-search_algorithm
        const M = needle.byteLength;
        if (M === 0) {
            throw new TypeError('search must be at least 1 byte long');
        }
        // radix
        const radix = 256;
        const rightmostPositions = new Int32Array(radix);
        // position of the rightmost occurrence of the byte c in the pattern
        for (let c = 0; c < radix; c++) {
            // -1 for bytes not in pattern
            rightmostPositions[c] = -1;
        }
        for (let j = 0; j < M; j++) {
            // rightmost position for bytes in pattern
            rightmostPositions[needle[j]] = j;
        }
        // Return offset of first match, -1 if no match
        const right = rightmostPositions;
        const lastIndex = this.byteLength - needle.byteLength;
        const lastPatIndex = needle.byteLength - 1;
        let skip;
        for (let i = offset; i <= lastIndex; i += skip) {
            skip = 0;
            for (let j = lastPatIndex; j >= 0; j--) {
                const char = this.get(i + j);
                if (needle[j] !== char) {
                    skip = Math.max(1, j - right[char]);
                    break;
                }
            }
            if (skip === 0) {
                return i;
            }
        }
        return -1;
    }
    getInt8(byteOffset) {
        const buf = this.subarray(byteOffset, byteOffset + 1);
        const view = new DataView(buf.buffer, buf.byteOffset, buf.byteLength);
        return view.getInt8(0);
    }
    setInt8(byteOffset, value) {
        const buf = allocUnsafe(1);
        const view = new DataView(buf.buffer, buf.byteOffset, buf.byteLength);
        view.setInt8(0, value);
        this.write(buf, byteOffset);
    }
    getInt16(byteOffset, littleEndian) {
        const buf = this.subarray(byteOffset, byteOffset + 2);
        const view = new DataView(buf.buffer, buf.byteOffset, buf.byteLength);
        return view.getInt16(0, littleEndian);
    }
    setInt16(byteOffset, value, littleEndian) {
        const buf = alloc(2);
        const view = new DataView(buf.buffer, buf.byteOffset, buf.byteLength);
        view.setInt16(0, value, littleEndian);
        this.write(buf, byteOffset);
    }
    getInt32(byteOffset, littleEndian) {
        const buf = this.subarray(byteOffset, byteOffset + 4);
        const view = new DataView(buf.buffer, buf.byteOffset, buf.byteLength);
        return view.getInt32(0, littleEndian);
    }
    setInt32(byteOffset, value, littleEndian) {
        const buf = alloc(4);
        const view = new DataView(buf.buffer, buf.byteOffset, buf.byteLength);
        view.setInt32(0, value, littleEndian);
        this.write(buf, byteOffset);
    }
    getBigInt64(byteOffset, littleEndian) {
        const buf = this.subarray(byteOffset, byteOffset + 8);
        const view = new DataView(buf.buffer, buf.byteOffset, buf.byteLength);
        return view.getBigInt64(0, littleEndian);
    }
    setBigInt64(byteOffset, value, littleEndian) {
        const buf = alloc(8);
        const view = new DataView(buf.buffer, buf.byteOffset, buf.byteLength);
        view.setBigInt64(0, value, littleEndian);
        this.write(buf, byteOffset);
    }
    getUint8(byteOffset) {
        const buf = this.subarray(byteOffset, byteOffset + 1);
        const view = new DataView(buf.buffer, buf.byteOffset, buf.byteLength);
        return view.getUint8(0);
    }
    setUint8(byteOffset, value) {
        const buf = allocUnsafe(1);
        const view = new DataView(buf.buffer, buf.byteOffset, buf.byteLength);
        view.setUint8(0, value);
        this.write(buf, byteOffset);
    }
    getUint16(byteOffset, littleEndian) {
        const buf = this.subarray(byteOffset, byteOffset + 2);
        const view = new DataView(buf.buffer, buf.byteOffset, buf.byteLength);
        return view.getUint16(0, littleEndian);
    }
    setUint16(byteOffset, value, littleEndian) {
        const buf = alloc(2);
        const view = new DataView(buf.buffer, buf.byteOffset, buf.byteLength);
        view.setUint16(0, value, littleEndian);
        this.write(buf, byteOffset);
    }
    getUint32(byteOffset, littleEndian) {
        const buf = this.subarray(byteOffset, byteOffset + 4);
        const view = new DataView(buf.buffer, buf.byteOffset, buf.byteLength);
        return view.getUint32(0, littleEndian);
    }
    setUint32(byteOffset, value, littleEndian) {
        const buf = alloc(4);
        const view = new DataView(buf.buffer, buf.byteOffset, buf.byteLength);
        view.setUint32(0, value, littleEndian);
        this.write(buf, byteOffset);
    }
    getBigUint64(byteOffset, littleEndian) {
        const buf = this.subarray(byteOffset, byteOffset + 8);
        const view = new DataView(buf.buffer, buf.byteOffset, buf.byteLength);
        return view.getBigUint64(0, littleEndian);
    }
    setBigUint64(byteOffset, value, littleEndian) {
        const buf = alloc(8);
        const view = new DataView(buf.buffer, buf.byteOffset, buf.byteLength);
        view.setBigUint64(0, value, littleEndian);
        this.write(buf, byteOffset);
    }
    getFloat32(byteOffset, littleEndian) {
        const buf = this.subarray(byteOffset, byteOffset + 4);
        const view = new DataView(buf.buffer, buf.byteOffset, buf.byteLength);
        return view.getFloat32(0, littleEndian);
    }
    setFloat32(byteOffset, value, littleEndian) {
        const buf = alloc(4);
        const view = new DataView(buf.buffer, buf.byteOffset, buf.byteLength);
        view.setFloat32(0, value, littleEndian);
        this.write(buf, byteOffset);
    }
    getFloat64(byteOffset, littleEndian) {
        const buf = this.subarray(byteOffset, byteOffset + 8);
        const view = new DataView(buf.buffer, buf.byteOffset, buf.byteLength);
        return view.getFloat64(0, littleEndian);
    }
    setFloat64(byteOffset, value, littleEndian) {
        const buf = alloc(8);
        const view = new DataView(buf.buffer, buf.byteOffset, buf.byteLength);
        view.setFloat64(0, value, littleEndian);
        this.write(buf, byteOffset);
    }
    equals(other) {
        if (other == null) {
            return false;
        }
        if (!(other instanceof Uint8ArrayList)) {
            return false;
        }
        if (other.bufs.length !== this.bufs.length) {
            return false;
        }
        for (let i = 0; i < this.bufs.length; i++) {
            if (!equals(this.bufs[i], other.bufs[i])) {
                return false;
            }
        }
        return true;
    }
    /**
     * Create a Uint8ArrayList from a pre-existing list of Uint8Arrays.  Use this
     * method if you know the total size of all the Uint8Arrays ahead of time.
     */
    static fromUint8Arrays(bufs, length) {
        const list = new Uint8ArrayList();
        list.bufs = bufs;
        if (length == null) {
            length = bufs.reduce((acc, curr) => acc + curr.byteLength, 0);
        }
        list.length = length;
        return list;
    }
}
/*
function indexOf (needle: Uint8Array, haystack: Uint8Array, offset = 0) {
  for (let i = offset; i < haystack.byteLength; i++) {
    for (let j = 0; j < needle.length; j++) {
      if (haystack[i + j] !== needle[j]) {
        break
      }

      if (j === needle.byteLength -1) {
        return i
      }
    }

    if (haystack.byteLength - i < needle.byteLength) {
      break
    }
  }

  return -1
}
*/

function isAsyncIterable$2(thing) {
    return thing[Symbol.asyncIterator] != null;
}

const defaultEncoder = (length) => {
    const lengthLength = encodingLength$1(length);
    const lengthBuf = allocUnsafe(lengthLength);
    encode$3(length, lengthBuf);
    defaultEncoder.bytes = lengthLength;
    return lengthBuf;
};
defaultEncoder.bytes = 0;
function encode(source, options) {
    options = options ?? {};
    const encodeLength = options.lengthEncoder ?? defaultEncoder;
    function* maybeYield(chunk) {
        // length + data
        const length = encodeLength(chunk.byteLength);
        // yield only Uint8Arrays
        if (length instanceof Uint8Array) {
            yield length;
        }
        else {
            yield* length;
        }
        // yield only Uint8Arrays
        if (chunk instanceof Uint8Array) {
            yield chunk;
        }
        else {
            yield* chunk;
        }
    }
    if (isAsyncIterable$2(source)) {
        return (async function* () {
            for await (const chunk of source) {
                yield* maybeYield(chunk);
            }
        })();
    }
    return (function* () {
        for (const chunk of source) {
            yield* maybeYield(chunk);
        }
    })();
}
encode.single = (chunk, options) => {
    options = options ?? {};
    const encodeLength = options.lengthEncoder ?? defaultEncoder;
    return new Uint8ArrayList(encodeLength(chunk.byteLength), chunk);
};

/**
 * The reported length of the next data message was not a positive integer
 */
class InvalidMessageLengthError extends Error {
    name = 'InvalidMessageLengthError';
    code = 'ERR_INVALID_MSG_LENGTH';
}
/**
 * The reported length of the next data message was larger than the configured
 * max allowable value
 */
class InvalidDataLengthError extends Error {
    name = 'InvalidDataLengthError';
    code = 'ERR_MSG_DATA_TOO_LONG';
}
/**
 * The varint used to specify the length of the next data message contained more
 * bytes than the configured max allowable value
 */
class InvalidDataLengthLengthError extends Error {
    name = 'InvalidDataLengthLengthError';
    code = 'ERR_MSG_LENGTH_TOO_LONG';
}
/**
 * The incoming stream ended before the expected number of bytes were read
 */
class UnexpectedEOFError extends Error {
    name = 'UnexpectedEOFError';
    code = 'ERR_UNEXPECTED_EOF';
}

/* eslint max-depth: ["error", 6] */
// Maximum length of the length section of the message
const MAX_LENGTH_LENGTH = 8; // Varint.encode(Number.MAX_SAFE_INTEGER).length
// Maximum length of the data section of the message
const MAX_DATA_LENGTH = 1024 * 1024 * 4;
var ReadMode;
(function (ReadMode) {
    ReadMode[ReadMode["LENGTH"] = 0] = "LENGTH";
    ReadMode[ReadMode["DATA"] = 1] = "DATA";
})(ReadMode || (ReadMode = {}));
const defaultDecoder = (buf) => {
    const length = decode$4(buf);
    defaultDecoder.bytes = encodingLength$1(length);
    return length;
};
defaultDecoder.bytes = 0;
function decode(source, options) {
    const buffer = new Uint8ArrayList();
    let mode = ReadMode.LENGTH;
    let dataLength = -1;
    const lengthDecoder = options?.lengthDecoder ?? defaultDecoder;
    const maxLengthLength = options?.maxLengthLength ?? MAX_LENGTH_LENGTH;
    const maxDataLength = options?.maxDataLength ?? MAX_DATA_LENGTH;
    function* maybeYield() {
        while (buffer.byteLength > 0) {
            if (mode === ReadMode.LENGTH) {
                // read length, ignore errors for short reads
                try {
                    dataLength = lengthDecoder(buffer);
                    if (dataLength < 0) {
                        throw new InvalidMessageLengthError('Invalid message length');
                    }
                    if (dataLength > maxDataLength) {
                        throw new InvalidDataLengthError('Message length too long');
                    }
                    const dataLengthLength = lengthDecoder.bytes;
                    buffer.consume(dataLengthLength);
                    if (options?.onLength != null) {
                        options.onLength(dataLength);
                    }
                    mode = ReadMode.DATA;
                }
                catch (err) {
                    if (err instanceof RangeError) {
                        if (buffer.byteLength > maxLengthLength) {
                            throw new InvalidDataLengthLengthError('Message length length too long');
                        }
                        break;
                    }
                    throw err;
                }
            }
            if (mode === ReadMode.DATA) {
                if (buffer.byteLength < dataLength) {
                    // not enough data, wait for more
                    break;
                }
                const data = buffer.sublist(0, dataLength);
                buffer.consume(dataLength);
                if (options?.onData != null) {
                    options.onData(data);
                }
                yield data;
                mode = ReadMode.LENGTH;
            }
        }
    }
    if (isAsyncIterable$2(source)) {
        return (async function* () {
            for await (const buf of source) {
                buffer.append(buf);
                yield* maybeYield();
            }
            if (buffer.byteLength > 0) {
                throw new UnexpectedEOFError('Unexpected end of input');
            }
        })();
    }
    return (function* () {
        for (const buf of source) {
            buffer.append(buf);
            yield* maybeYield();
        }
        if (buffer.byteLength > 0) {
            throw new UnexpectedEOFError('Unexpected end of input');
        }
    })();
}
decode.fromReader = (reader, options) => {
    let byteLength = 1; // Read single byte chunks until the length is known
    const varByteSource = (async function* () {
        while (true) {
            try {
                const { done, value } = await reader.next(byteLength);
                if (done === true) {
                    return;
                }
                if (value != null) {
                    yield value;
                }
            }
            catch (err) {
                if (err.code === 'ERR_UNDER_READ') {
                    return { done: true, value: null };
                }
                throw err;
            }
            finally {
                // Reset the byteLength so we continue to check for varints
                byteLength = 1;
            }
        }
    }());
    /**
     * Once the length has been parsed, read chunk for that length
     */
    const onLength = (l) => { byteLength = l; };
    return decode(varByteSource, {
        ...(options ?? {}),
        onLength
    });
};

function pDefer() {
	const deferred = {};

	deferred.promise = new Promise((resolve, reject) => {
		deferred.resolve = resolve;
		deferred.reject = reject;
	});

	return deferred;
}

// ported from https://www.npmjs.com/package/fast-fifo
class FixedFIFO {
    buffer;
    mask;
    top;
    btm;
    next;
    constructor(hwm) {
        if (!(hwm > 0) || ((hwm - 1) & hwm) !== 0) {
            throw new Error('Max size for a FixedFIFO should be a power of two');
        }
        this.buffer = new Array(hwm);
        this.mask = hwm - 1;
        this.top = 0;
        this.btm = 0;
        this.next = null;
    }
    push(data) {
        if (this.buffer[this.top] !== undefined) {
            return false;
        }
        this.buffer[this.top] = data;
        this.top = (this.top + 1) & this.mask;
        return true;
    }
    shift() {
        const last = this.buffer[this.btm];
        if (last === undefined) {
            return undefined;
        }
        this.buffer[this.btm] = undefined;
        this.btm = (this.btm + 1) & this.mask;
        return last;
    }
    isEmpty() {
        return this.buffer[this.btm] === undefined;
    }
}
class FIFO {
    size;
    hwm;
    head;
    tail;
    constructor(options = {}) {
        this.hwm = options.splitLimit ?? 16;
        this.head = new FixedFIFO(this.hwm);
        this.tail = this.head;
        this.size = 0;
    }
    calculateSize(obj) {
        if (obj?.byteLength != null) {
            return obj.byteLength;
        }
        return 1;
    }
    push(val) {
        if (val?.value != null) {
            this.size += this.calculateSize(val.value);
        }
        if (!this.head.push(val)) {
            const prev = this.head;
            this.head = prev.next = new FixedFIFO(2 * this.head.buffer.length);
            this.head.push(val);
        }
    }
    shift() {
        let val = this.tail.shift();
        if (val === undefined && (this.tail.next != null)) {
            const next = this.tail.next;
            this.tail.next = null;
            this.tail = next;
            val = this.tail.shift();
        }
        if (val?.value != null) {
            this.size -= this.calculateSize(val.value);
        }
        return val;
    }
    isEmpty() {
        return this.head.isEmpty();
    }
}

/**
 * @packageDocumentation
 *
 * An iterable that you can push values into.
 *
 * @example
 *
 * ```js
 * import { pushable } from 'it-pushable'
 *
 * const source = pushable()
 *
 * setTimeout(() => source.push('hello'), 100)
 * setTimeout(() => source.push('world'), 200)
 * setTimeout(() => source.end(), 300)
 *
 * const start = Date.now()
 *
 * for await (const value of source) {
 *   console.log(`got "${value}" after ${Date.now() - start}ms`)
 * }
 * console.log(`done after ${Date.now() - start}ms`)
 *
 * // Output:
 * // got "hello" after 105ms
 * // got "world" after 207ms
 * // done after 309ms
 * ```
 *
 * @example
 *
 * ```js
 * import { pushableV } from 'it-pushable'
 * import all from 'it-all'
 *
 * const source = pushableV()
 *
 * source.push(1)
 * source.push(2)
 * source.push(3)
 * source.end()
 *
 * console.info(await all(source))
 *
 * // Output:
 * // [ [1, 2, 3] ]
 * ```
 */
let AbortError$1 = class AbortError extends Error {
    type;
    code;
    constructor(message, code) {
        super(message ?? 'The operation was aborted');
        this.type = 'aborted';
        this.code = code ?? 'ABORT_ERR';
    }
};
function pushable(options = {}) {
    const getNext = (buffer) => {
        const next = buffer.shift();
        if (next == null) {
            return { done: true };
        }
        if (next.error != null) {
            throw next.error;
        }
        return {
            done: next.done === true,
            // @ts-expect-error if done is false, value will be present
            value: next.value
        };
    };
    return _pushable(getNext, options);
}
function _pushable(getNext, options) {
    options = options ?? {};
    let onEnd = options.onEnd;
    let buffer = new FIFO();
    let pushable;
    let onNext;
    let ended;
    let drain = pDefer();
    const waitNext = async () => {
        try {
            if (!buffer.isEmpty()) {
                return getNext(buffer);
            }
            if (ended) {
                return { done: true };
            }
            return await new Promise((resolve, reject) => {
                onNext = (next) => {
                    onNext = null;
                    buffer.push(next);
                    try {
                        resolve(getNext(buffer));
                    }
                    catch (err) {
                        reject(err);
                    }
                    return pushable;
                };
            });
        }
        finally {
            if (buffer.isEmpty()) {
                // settle promise in the microtask queue to give consumers a chance to
                // await after calling .push
                queueMicrotask(() => {
                    drain.resolve();
                    drain = pDefer();
                });
            }
        }
    };
    const bufferNext = (next) => {
        if (onNext != null) {
            return onNext(next);
        }
        buffer.push(next);
        return pushable;
    };
    const bufferError = (err) => {
        buffer = new FIFO();
        if (onNext != null) {
            return onNext({ error: err });
        }
        buffer.push({ error: err });
        return pushable;
    };
    const push = (value) => {
        if (ended) {
            return pushable;
        }
        // @ts-expect-error `byteLength` is not declared on PushType
        if (options?.objectMode !== true && value?.byteLength == null) {
            throw new Error('objectMode was not true but tried to push non-Uint8Array value');
        }
        return bufferNext({ done: false, value });
    };
    const end = (err) => {
        if (ended)
            return pushable;
        ended = true;
        return (err != null) ? bufferError(err) : bufferNext({ done: true });
    };
    const _return = () => {
        buffer = new FIFO();
        end();
        return { done: true };
    };
    const _throw = (err) => {
        end(err);
        return { done: true };
    };
    pushable = {
        [Symbol.asyncIterator]() { return this; },
        next: waitNext,
        return: _return,
        throw: _throw,
        push,
        end,
        get readableLength() {
            return buffer.size;
        },
        onEmpty: async (options) => {
            const signal = options?.signal;
            signal?.throwIfAborted();
            if (buffer.isEmpty()) {
                return;
            }
            let cancel;
            let listener;
            if (signal != null) {
                cancel = new Promise((resolve, reject) => {
                    listener = () => {
                        reject(new AbortError$1());
                    };
                    signal.addEventListener('abort', listener);
                });
            }
            try {
                await Promise.race([
                    drain.promise,
                    cancel
                ]);
            }
            finally {
                if (listener != null && signal != null) {
                    signal?.removeEventListener('abort', listener);
                }
            }
        }
    };
    if (onEnd == null) {
        return pushable;
    }
    const _pushable = pushable;
    pushable = {
        [Symbol.asyncIterator]() { return this; },
        next() {
            return _pushable.next();
        },
        throw(err) {
            _pushable.throw(err);
            if (onEnd != null) {
                onEnd(err);
                onEnd = undefined;
            }
            return { done: true };
        },
        return() {
            _pushable.return();
            if (onEnd != null) {
                onEnd();
                onEnd = undefined;
            }
            return { done: true };
        },
        push,
        end(err) {
            _pushable.end(err);
            if (onEnd != null) {
                onEnd(err);
                onEnd = undefined;
            }
            return pushable;
        },
        get readableLength() {
            return _pushable.readableLength;
        },
        onEmpty: (opts) => {
            return _pushable.onEmpty(opts);
        }
    };
    return pushable;
}

/**
 * An abort error class that extends error
 */
class AbortError extends Error {
    type;
    code;
    constructor(message, code, name) {
        super(message ?? 'The operation was aborted');
        this.type = 'aborted';
        this.name = name ?? 'AbortError';
        this.code = code ?? 'ABORT_ERR';
    }
}
/**
 * Race a promise against an abort signal
 */
async function raceSignal(promise, signal, opts) {
    if (signal == null) {
        return promise;
    }
    if (signal.aborted) {
        // the passed promise may yet resolve or reject but the use has signalled
        // they are no longer interested so smother the error
        promise.catch(() => { });
        return Promise.reject(new AbortError(opts?.errorMessage, opts?.errorCode, opts?.errorName));
    }
    let listener;
    // create the error here so we have more context in the stack trace
    const error = new AbortError(opts?.errorMessage, opts?.errorCode, opts?.errorName);
    try {
        return await Promise.race([
            promise,
            new Promise((resolve, reject) => {
                listener = () => {
                    reject(error);
                };
                signal.addEventListener('abort', listener);
            })
        ]);
    }
    finally {
        if (listener != null) {
            signal.removeEventListener('abort', listener);
        }
    }
}

/**
 * @packageDocumentation
 *
 * A pushable async generator that waits until the current value is consumed
 * before allowing a new value to be pushed.
 *
 * Useful for when you don't want to keep memory usage under control and/or
 * allow a downstream consumer to dictate how fast data flows through a pipe,
 * but you want to be able to apply a transform to that data.
 *
 * @example
 *
 * ```typescript
 * import { queuelessPushable } from 'it-queueless-pushable'
 *
 * const pushable = queuelessPushable<string>()
 *
 * // run asynchronously
 * Promise.resolve().then(async () => {
 *   // push a value - the returned promise will not resolve until the value is
 *   // read from the pushable
 *   await pushable.push('hello')
 * })
 *
 * // read a value
 * const result = await pushable.next()
 * console.info(result) // { done: false, value: 'hello' }
 * ```
 */
class QueuelessPushable {
    readNext;
    haveNext;
    ended;
    nextResult;
    error;
    constructor() {
        this.ended = false;
        this.readNext = pDefer();
        this.haveNext = pDefer();
    }
    [Symbol.asyncIterator]() {
        return this;
    }
    async next() {
        if (this.nextResult == null) {
            // wait for the supplier to push a value
            await this.haveNext.promise;
        }
        if (this.nextResult == null) {
            throw new Error('HaveNext promise resolved but nextResult was undefined');
        }
        const nextResult = this.nextResult;
        this.nextResult = undefined;
        // signal to the supplier that we read the value
        this.readNext.resolve();
        this.readNext = pDefer();
        return nextResult;
    }
    async throw(err) {
        this.ended = true;
        this.error = err;
        if (err != null) {
            // this can cause unhandled promise rejections if nothing is awaiting the
            // next value so attach a dummy catch listener to the promise
            this.haveNext.promise.catch(() => { });
            this.haveNext.reject(err);
        }
        const result = {
            done: true,
            value: undefined
        };
        return result;
    }
    async return() {
        const result = {
            done: true,
            value: undefined
        };
        this.ended = true;
        this.nextResult = result;
        // let the consumer know we have a new value
        this.haveNext.resolve();
        return result;
    }
    async push(value, options) {
        await this._push(value, options);
    }
    async end(err, options) {
        if (err != null) {
            await this.throw(err);
        }
        else {
            // abortable return
            await this._push(undefined, options);
        }
    }
    async _push(value, options) {
        if (value != null && this.ended) {
            throw this.error ?? new Error('Cannot push value onto an ended pushable');
        }
        // wait for all values to be read
        while (this.nextResult != null) {
            await this.readNext.promise;
        }
        if (value != null) {
            this.nextResult = { done: false, value };
        }
        else {
            this.ended = true;
            this.nextResult = { done: true, value: undefined };
        }
        // let the consumer know we have a new value
        this.haveNext.resolve();
        this.haveNext = pDefer();
        // wait for the consumer to have finished processing the value and requested
        // the next one or for the passed signal to abort the waiting
        await raceSignal(this.readNext.promise, options?.signal, options);
    }
}
function queuelessPushable() {
    return new QueuelessPushable();
}

/**
 * @packageDocumentation
 *
 * Merge several (async)iterables into one, yield values as they arrive.
 *
 * Nb. sources are iterated over in parallel so the order of emitted items is not guaranteed.
 *
 * @example
 *
 * ```javascript
 * import merge from 'it-merge'
 * import all from 'it-all'
 *
 * // This can also be an iterator, generator, etc
 * const values1 = [0, 1, 2, 3, 4]
 * const values2 = [5, 6, 7, 8, 9]
 *
 * const arr = all(merge(values1, values2))
 *
 * console.info(arr) // 0, 1, 2, 3, 4, 5, 6, 7, 8, 9
 * ```
 *
 * Async sources must be awaited:
 *
 * ```javascript
 * import merge from 'it-merge'
 * import all from 'it-all'
 *
 * // This can also be an iterator, async iterator, generator, etc
 * const values1 = async function * () {
 *   yield * [0, 1, 2, 3, 4]
 * }
 * const values2 = async function * () {
 *   yield * [5, 6, 7, 8, 9]
 * }
 *
 * const arr = await all(merge(values1(), values2()))
 *
 * console.info(arr) // 0, 1, 5, 6, 2, 3, 4, 7, 8, 9  <- nb. order is not guaranteed
 * ```
 */
function isAsyncIterable$1(thing) {
    return thing[Symbol.asyncIterator] != null;
}
async function addAllToPushable(sources, output, signal) {
    try {
        await Promise.all(sources.map(async (source) => {
            for await (const item of source) {
                await output.push(item, {
                    signal
                });
                signal.throwIfAborted();
            }
        }));
        await output.end(undefined, {
            signal
        });
    }
    catch (err) {
        await output.end(err, {
            signal
        })
            .catch(() => { });
    }
}
async function* mergeSources(sources) {
    const controller = new AbortController();
    const output = queuelessPushable();
    addAllToPushable(sources, output, controller.signal)
        .catch(() => { });
    try {
        yield* output;
    }
    finally {
        controller.abort();
    }
}
function* mergeSyncSources(syncSources) {
    for (const source of syncSources) {
        yield* source;
    }
}
function merge(...sources) {
    const syncSources = [];
    for (const source of sources) {
        if (!isAsyncIterable$1(source)) {
            syncSources.push(source);
        }
    }
    if (syncSources.length === sources.length) {
        // all sources are synchronous
        return mergeSyncSources(syncSources);
    }
    return mergeSources(sources);
}

function pipe(first, ...rest) {
    if (first == null) {
        throw new Error('Empty pipeline');
    }
    // Duplex at start: wrap in function and return duplex source
    if (isDuplex(first)) {
        const duplex = first;
        first = () => duplex.source;
        // Iterable at start: wrap in function
    }
    else if (isIterable(first) || isAsyncIterable(first)) {
        const source = first;
        first = () => source;
    }
    const fns = [first, ...rest];
    if (fns.length > 1) {
        // Duplex at end: use duplex sink
        if (isDuplex(fns[fns.length - 1])) {
            fns[fns.length - 1] = fns[fns.length - 1].sink;
        }
    }
    if (fns.length > 2) {
        // Duplex in the middle, consume source with duplex sink and return duplex source
        for (let i = 1; i < fns.length - 1; i++) {
            if (isDuplex(fns[i])) {
                fns[i] = duplexPipelineFn(fns[i]);
            }
        }
    }
    return rawPipe(...fns);
}
const rawPipe = (...fns) => {
    let res;
    while (fns.length > 0) {
        res = fns.shift()(res);
    }
    return res;
};
const isAsyncIterable = (obj) => {
    return obj?.[Symbol.asyncIterator] != null;
};
const isIterable = (obj) => {
    return obj?.[Symbol.iterator] != null;
};
const isDuplex = (obj) => {
    if (obj == null) {
        return false;
    }
    return obj.sink != null && obj.source != null;
};
const duplexPipelineFn = (duplex) => {
    return (source) => {
        const p = duplex.sink(source);
        if (p?.then != null) {
            const stream = pushable({
                objectMode: true
            });
            p.then(() => {
                stream.end();
            }, (err) => {
                stream.end(err);
            });
            let sourceWrap;
            const source = duplex.source;
            if (isAsyncIterable(source)) {
                sourceWrap = async function* () {
                    yield* source;
                    stream.end();
                };
            }
            else if (isIterable(source)) {
                sourceWrap = function* () {
                    yield* source;
                    stream.end();
                };
            }
            else {
                throw new Error('Unknown duplex source type - must be Iterable or AsyncIterable');
            }
            return merge(stream, sourceWrap());
        }
        return duplex.source;
    };
};

function selectOpenConnection(connections) {
    return connections
        .filter((c) => c.status === "open")
        .sort((left, right) => right.timeline.open - left.timeline.open)
        .at(0);
}

const STREAM_LOCK_KEY = "consumed";
class StreamManager {
    multicodec;
    libp2p;
    log;
    ongoingCreation = new Set();
    streamPool = new Map();
    constructor(multicodec, libp2p) {
        this.multicodec = multicodec;
        this.libp2p = libp2p;
        this.log = new Logger(`stream-manager:${multicodec}`);
        this.libp2p.events.addEventListener("peer:update", this.handlePeerUpdateStreamPool);
    }
    async getStream(peerId) {
        try {
            const peerIdStr = peerId.toString();
            const scheduledStream = this.streamPool.get(peerIdStr);
            if (scheduledStream) {
                this.streamPool.delete(peerIdStr);
                await scheduledStream;
            }
            const stream = this.getOpenStreamForCodec(peerId) || (await this.createStream(peerId));
            if (!stream) {
                return;
            }
            this.log.info(`Using stream for peerId=${peerIdStr} multicodec=${this.multicodec}`);
            this.lockStream(peerIdStr, stream);
            return stream;
        }
        catch (error) {
            this.log.error(`Failed to getStream:`, error);
            return;
        }
    }
    async createStream(peerId, retries = 0) {
        const connections = this.libp2p.connectionManager.getConnections(peerId);
        const connection = selectOpenConnection(connections);
        if (!connection) {
            this.log.error(`Failed to get a connection to the peer peerId=${peerId.toString()} multicodec=${this.multicodec}`);
            return;
        }
        let lastError;
        let stream;
        for (let i = 0; i < retries + 1; i++) {
            try {
                this.log.info(`Attempting to create a stream for peerId=${peerId.toString()} multicodec=${this.multicodec}`);
                stream = await connection.newStream(this.multicodec);
                this.log.info(`Created stream for peerId=${peerId.toString()} multicodec=${this.multicodec}`);
                break;
            }
            catch (error) {
                lastError = error;
            }
        }
        if (!stream) {
            this.log.error(`Failed to create a new stream for ${peerId.toString()} -- ` + lastError);
            return;
        }
        return stream;
    }
    async createStreamWithLock(peer) {
        const peerId = peer.id.toString();
        if (this.ongoingCreation.has(peerId)) {
            this.log.info(`Skipping creation of a stream due to lock for peerId=${peerId} multicodec=${this.multicodec}`);
            return;
        }
        try {
            this.ongoingCreation.add(peerId);
            await this.createStream(peer.id);
        }
        catch (error) {
            this.log.error(`Failed to createStreamWithLock:`, error);
        }
        finally {
            this.ongoingCreation.delete(peerId);
        }
        return;
    }
    handlePeerUpdateStreamPool = (evt) => {
        const { peer } = evt.detail;
        if (!peer.protocols.includes(this.multicodec)) {
            return;
        }
        const stream = this.getOpenStreamForCodec(peer.id);
        if (stream) {
            return;
        }
        this.scheduleNewStream(peer);
    };
    scheduleNewStream(peer) {
        this.log.info(`Scheduling creation of a stream for peerId=${peer.id.toString()} multicodec=${this.multicodec}`);
        // abandon previous attempt
        if (this.streamPool.has(peer.id.toString())) {
            this.streamPool.delete(peer.id.toString());
        }
        this.streamPool.set(peer.id.toString(), this.createStreamWithLock(peer));
    }
    getOpenStreamForCodec(peerId) {
        const connections = this.libp2p.connectionManager.getConnections(peerId);
        const connection = selectOpenConnection(connections);
        if (!connection) {
            this.log.info(`No open connection found for peerId=${peerId.toString()} multicodec=${this.multicodec}`);
            return;
        }
        const stream = connection.streams.find((s) => s.protocol === this.multicodec);
        if (!stream) {
            this.log.info(`No open stream found for peerId=${peerId.toString()} multicodec=${this.multicodec}`);
            return;
        }
        const isStreamUnusable = ["done", "closed", "closing"].includes(stream.writeStatus || "");
        if (isStreamUnusable || this.isStreamLocked(stream)) {
            this.log.info(`Stream for peerId=${peerId.toString()} multicodec=${this.multicodec} is unusable`);
            return;
        }
        this.log.info(`Found open stream for peerId=${peerId.toString()} multicodec=${this.multicodec}`);
        return stream;
    }
    lockStream(peerId, stream) {
        this.log.info(`Locking stream for peerId:${peerId}\tstreamId:${stream.id}`);
        stream.metadata[STREAM_LOCK_KEY] = true;
    }
    isStreamLocked(stream) {
        return !!stream.metadata[STREAM_LOCK_KEY];
    }
}

// Unique ID creation requires a high quality random # generator. In the browser we therefore
// require the crypto API and do not support built-in fallback to lower quality random number
// generators (like Math.random()).
let getRandomValues;
const rnds8 = new Uint8Array(16);
function rng() {
  // lazy load so that environments that need to polyfill have a chance to do so
  if (!getRandomValues) {
    // getRandomValues needs to be invoked in a context where "this" is a Crypto implementation.
    getRandomValues = typeof crypto !== 'undefined' && crypto.getRandomValues && crypto.getRandomValues.bind(crypto);

    if (!getRandomValues) {
      throw new Error('crypto.getRandomValues() not supported. See https://github.com/uuidjs/uuid#getrandomvalues-not-supported');
    }
  }

  return getRandomValues(rnds8);
}

/**
 * Convert array of 16 byte values to UUID string format of the form:
 * XXXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXXXX
 */

const byteToHex = [];

for (let i = 0; i < 256; ++i) {
  byteToHex.push((i + 0x100).toString(16).slice(1));
}

function unsafeStringify(arr, offset = 0) {
  // Note: Be careful editing this code!  It's been tuned for performance
  // and works in ways you may not expect. See https://github.com/uuidjs/uuid/pull/434
  return byteToHex[arr[offset + 0]] + byteToHex[arr[offset + 1]] + byteToHex[arr[offset + 2]] + byteToHex[arr[offset + 3]] + '-' + byteToHex[arr[offset + 4]] + byteToHex[arr[offset + 5]] + '-' + byteToHex[arr[offset + 6]] + byteToHex[arr[offset + 7]] + '-' + byteToHex[arr[offset + 8]] + byteToHex[arr[offset + 9]] + '-' + byteToHex[arr[offset + 10]] + byteToHex[arr[offset + 11]] + byteToHex[arr[offset + 12]] + byteToHex[arr[offset + 13]] + byteToHex[arr[offset + 14]] + byteToHex[arr[offset + 15]];
}

const randomUUID = typeof crypto !== 'undefined' && crypto.randomUUID && crypto.randomUUID.bind(crypto);
var native = {
  randomUUID
};

function v4(options, buf, offset) {
  if (native.randomUUID && true && !options) {
    return native.randomUUID();
  }

  options = options || {};
  const rnds = options.random || (options.rng || rng)(); // Per 4.4, set bits for version and `clock_seq_hi_and_reserved`

  rnds[6] = rnds[6] & 0x0f | 0x40;
  rnds[8] = rnds[8] & 0x3f | 0x80; // Copy bytes to buffer, if provided

  return unsafeStringify(rnds);
}

/**
 * FilterPushRPC represents a message conforming to the Waku FilterPush protocol.
 * Protocol documentation: https://rfc.vac.dev/spec/12/
 */
class FilterPushRpc {
    proto;
    constructor(proto) {
        this.proto = proto;
    }
    static decode(bytes) {
        const res = MessagePush.decode(bytes);
        return new FilterPushRpc(res);
    }
    encode() {
        return MessagePush.encode(this.proto);
    }
    get wakuMessage() {
        return this.proto.wakuMessage;
    }
    /**
     * Get the pubsub topic from the FilterPushRpc object.
     * @returns string
     */
    get pubsubTopic() {
        return this.proto.pubsubTopic;
    }
}
class FilterSubscribeRpc {
    proto;
    constructor(proto) {
        this.proto = proto;
    }
    static createSubscribeRequest(pubsubTopic, contentTopics) {
        return new FilterSubscribeRpc({
            requestId: v4(),
            filterSubscribeType: FilterSubscribeRequest.FilterSubscribeType.SUBSCRIBE,
            pubsubTopic,
            contentTopics
        });
    }
    static createUnsubscribeRequest(pubsubTopic, contentTopics) {
        return new FilterSubscribeRpc({
            requestId: v4(),
            filterSubscribeType: FilterSubscribeRequest.FilterSubscribeType.UNSUBSCRIBE,
            pubsubTopic,
            contentTopics
        });
    }
    static createUnsubscribeAllRequest(pubsubTopic) {
        return new FilterSubscribeRpc({
            requestId: v4(),
            filterSubscribeType: FilterSubscribeRequest.FilterSubscribeType.UNSUBSCRIBE_ALL,
            pubsubTopic,
            contentTopics: []
        });
    }
    static createSubscriberPingRequest() {
        return new FilterSubscribeRpc({
            requestId: v4(),
            filterSubscribeType: FilterSubscribeRequest.FilterSubscribeType.SUBSCRIBER_PING,
            pubsubTopic: "",
            contentTopics: []
        });
    }
    static decode(bytes) {
        const res = FilterSubscribeRequest.decode(bytes);
        return new FilterSubscribeRpc(res);
    }
    encode() {
        return FilterSubscribeRequest.encode(this.proto);
    }
    get filterSubscribeType() {
        return this.proto.filterSubscribeType;
    }
    get requestId() {
        return this.proto.requestId;
    }
    get pubsubTopic() {
        return this.proto.pubsubTopic;
    }
    get contentTopics() {
        return this.proto.contentTopics;
    }
}
class FilterSubscribeResponse {
    proto;
    constructor(proto) {
        this.proto = proto;
    }
    static decode(bytes) {
        const res = FilterSubscribeResponse$1.decode(bytes);
        return new FilterSubscribeResponse(res);
    }
    encode() {
        return FilterSubscribeResponse$1.encode(this.proto);
    }
    get statusCode() {
        return this.proto.statusCode;
    }
    get statusDesc() {
        return this.proto.statusDesc;
    }
    get requestId() {
        return this.proto.requestId;
    }
}

const log$a = new Logger("filter-core");
const FilterCodecs = {
    SUBSCRIBE: "/vac/waku/filter-subscribe/2.0.0-beta1",
    PUSH: "/vac/waku/filter-push/2.0.0-beta1"
};
class FilterCore {
    handleIncomingMessage;
    libp2p;
    streamManager;
    multicodec = FilterCodecs.SUBSCRIBE;
    constructor(handleIncomingMessage, libp2p) {
        this.handleIncomingMessage = handleIncomingMessage;
        this.libp2p = libp2p;
        this.streamManager = new StreamManager(FilterCodecs.SUBSCRIBE, libp2p.components);
    }
    async start() {
        try {
            await this.libp2p.handle(FilterCodecs.PUSH, this.onRequest.bind(this), {
                maxInboundStreams: 100
            });
        }
        catch (e) {
            log$a.error("Failed to register ", FilterCodecs.PUSH, e);
        }
    }
    async stop() {
        try {
            await this.libp2p.unhandle(FilterCodecs.PUSH);
        }
        catch (e) {
            log$a.error("Failed to unregister ", FilterCodecs.PUSH, e);
        }
    }
    async subscribe(pubsubTopic, peerId, contentTopics) {
        const stream = await this.streamManager.getStream(peerId);
        if (!stream) {
            return {
                success: null,
                failure: {
                    error: FilterError.NO_STREAM_AVAILABLE,
                    peerId: peerId
                }
            };
        }
        const request = FilterSubscribeRpc.createSubscribeRequest(pubsubTopic, contentTopics);
        let res;
        try {
            res = await pipe([request.encode()], encode, stream, decode, async (source) => await all(source));
            if (!res?.length) {
                throw Error("Received no response from subscription request.");
            }
        }
        catch (error) {
            log$a.error("Failed to send subscribe request", error);
            return {
                success: null,
                failure: {
                    error: FilterError.GENERIC_FAIL,
                    peerId: peerId
                }
            };
        }
        const { statusCode, requestId, statusDesc } = FilterSubscribeResponse.decode(res[0].slice());
        if (statusCode < 200 || statusCode >= 300) {
            log$a.error(`Filter subscribe request ${requestId} failed with status code ${statusCode}: ${statusDesc}`);
            return {
                failure: {
                    error: FilterError.REMOTE_PEER_REJECTED,
                    peerId: peerId
                },
                success: null
            };
        }
        return {
            failure: null,
            success: peerId
        };
    }
    async unsubscribe(pubsubTopic, peerId, contentTopics) {
        const stream = await this.streamManager.getStream(peerId);
        if (!stream) {
            log$a.error(`Failed to get a stream for remote peer:${peerId.toString()}`);
            return {
                success: null,
                failure: {
                    error: FilterError.NO_STREAM_AVAILABLE,
                    peerId: peerId
                }
            };
        }
        const unsubscribeRequest = FilterSubscribeRpc.createUnsubscribeRequest(pubsubTopic, contentTopics);
        try {
            await pipe([unsubscribeRequest.encode()], encode, stream.sink);
        }
        catch (error) {
            log$a.error("Failed to send unsubscribe request", error);
            return {
                success: null,
                failure: {
                    error: FilterError.GENERIC_FAIL,
                    peerId: peerId
                }
            };
        }
        return {
            success: peerId,
            failure: null
        };
    }
    async unsubscribeAll(pubsubTopic, peerId) {
        const stream = await this.streamManager.getStream(peerId);
        if (!stream) {
            log$a.error(`Failed to get a stream for remote peer:${peerId.toString()}`);
            return {
                success: null,
                failure: {
                    error: FilterError.NO_STREAM_AVAILABLE,
                    peerId: peerId
                }
            };
        }
        const request = FilterSubscribeRpc.createUnsubscribeAllRequest(pubsubTopic);
        const res = await pipe([request.encode()], encode, stream, decode, async (source) => await all(source));
        if (!res || !res.length) {
            return {
                failure: {
                    error: FilterError.NO_RESPONSE,
                    peerId: peerId
                },
                success: null
            };
        }
        const { statusCode, requestId, statusDesc } = FilterSubscribeResponse.decode(res[0].slice());
        if (statusCode < 200 || statusCode >= 300) {
            log$a.error(`Filter unsubscribe all request ${requestId} failed with status code ${statusCode}: ${statusDesc}`);
            return {
                failure: {
                    error: FilterError.REMOTE_PEER_REJECTED,
                    peerId: peerId
                },
                success: null
            };
        }
        return {
            failure: null,
            success: peerId
        };
    }
    async ping(peerId) {
        const stream = await this.streamManager.getStream(peerId);
        if (!stream) {
            log$a.error(`Failed to get a stream for remote peer:${peerId.toString()}`);
            return {
                success: null,
                failure: {
                    error: FilterError.NO_STREAM_AVAILABLE,
                    peerId: peerId
                }
            };
        }
        const request = FilterSubscribeRpc.createSubscriberPingRequest();
        let res;
        try {
            res = await pipe([request.encode()], encode, stream, decode, async (source) => await all(source));
        }
        catch (error) {
            log$a.error("Failed to send ping request", error);
            return {
                success: null,
                failure: {
                    error: FilterError.GENERIC_FAIL,
                    peerId: peerId
                }
            };
        }
        if (!res || !res.length) {
            return {
                success: null,
                failure: {
                    error: FilterError.NO_RESPONSE,
                    peerId: peerId
                }
            };
        }
        const { statusCode, requestId, statusDesc } = FilterSubscribeResponse.decode(res[0].slice());
        if (statusCode < 200 || statusCode >= 300) {
            log$a.error(`Filter ping request ${requestId} failed with status code ${statusCode}: ${statusDesc}`);
            return {
                success: null,
                failure: {
                    error: FilterError.REMOTE_PEER_REJECTED,
                    peerId: peerId
                }
            };
        }
        return {
            success: peerId,
            failure: null
        };
    }
    onRequest(streamData) {
        const { connection, stream } = streamData;
        const { remotePeer } = connection;
        log$a.info(`Received message from ${remotePeer.toString()}`);
        try {
            pipe(stream, decode, async (source) => {
                for await (const bytes of source) {
                    const response = FilterPushRpc.decode(bytes.slice());
                    const { pubsubTopic, wakuMessage } = response;
                    if (!wakuMessage) {
                        log$a.error("Received empty message");
                        return;
                    }
                    if (!pubsubTopic) {
                        log$a.error("Pubsub topic missing from push message");
                        return;
                    }
                    await this.handleIncomingMessage(pubsubTopic, wakuMessage, connection.remotePeer.toString());
                }
            }).then(() => {
                log$a.info("Receiving pipe closed.");
            }, async (e) => {
                log$a.error(`Error with receiving pipe on peer:${connection.remotePeer.toString()} -- stream:${stream.id} -- protocol:${stream.protocol}: `, e);
            });
        }
        catch (e) {
            log$a.error("Error decoding message", e);
        }
    }
}

var index$2 = /*#__PURE__*/Object.freeze({
    __proto__: null,
    FilterCodecs: FilterCodecs,
    FilterCore: FilterCore
});

const CODECS = {
    v2: "/vac/waku/lightpush/2.0.0-beta1",
    v3: "/vac/waku/lightpush/3.0.0"
};
const LightPushCodecV2 = CODECS.v2;
const LightPushCodec = CODECS.v3;

class PushRpcV2 {
    proto;
    constructor(proto) {
        this.proto = proto;
    }
    static createRequest(message, pubsubTopic) {
        return new PushRpcV2({
            requestId: v4(),
            request: {
                message: message,
                pubsubTopic: pubsubTopic
            },
            response: undefined
        });
    }
    static decode(bytes) {
        const res = PushRpc$1.decode(bytes);
        return new PushRpcV2(res);
    }
    encode() {
        return PushRpc$1.encode(this.proto);
    }
    get query() {
        return this.proto.request;
    }
    get response() {
        return this.proto.response;
    }
}

/**
 * LightPush v3 protocol RPC handler.
 * Implements the v3 message format with correct field numbers:
 * - requestId: 1
 * - pubsubTopic: 20
 * - message: 21
 */
class PushRpc {
    proto;
    constructor(proto) {
        this.proto = proto;
    }
    /**
     * Create a v3 request message with proper field numbering
     */
    static createRequest(message, pubsubTopic) {
        return new PushRpc({
            requestId: v4(),
            pubsubTopic: pubsubTopic,
            message: message
        });
    }
    /**
     * Create a v3 response message with status code handling
     */
    static createResponse(requestId, statusCode, statusDesc, relayPeerCount) {
        return new PushRpc({
            requestId,
            statusCode,
            statusDesc,
            relayPeerCount
        });
    }
    /**
     * Decode v3 request message
     */
    static decodeRequest(bytes) {
        const res = LightPushRequestV3.decode(bytes);
        return new PushRpc(res);
    }
    /**
     * Decode v3 response message
     */
    static decodeResponse(bytes) {
        const res = LightPushResponseV3.decode(bytes);
        return new PushRpc(res);
    }
    /**
     * Encode message to bytes
     */
    encode() {
        if (this.isRequest()) {
            return LightPushRequestV3.encode(this.proto);
        }
        else {
            return LightPushResponseV3.encode(this.proto);
        }
    }
    /**
     * Get request data (if this is a request message)
     */
    get request() {
        return this.isRequest()
            ? this.proto
            : undefined;
    }
    /**
     * Get response data (if this is a response message)
     */
    get response() {
        return this.isResponse()
            ? this.proto
            : undefined;
    }
    /**
     * Get the request ID
     */
    get requestId() {
        return this.proto.requestId;
    }
    /**
     * Get the pubsub topic (only available in requests)
     */
    get pubsubTopic() {
        return this.isRequest()
            ? this.proto.pubsubTopic
            : undefined;
    }
    /**
     * Get the message (only available in requests)
     */
    get message() {
        return this.isRequest()
            ? this.proto.message
            : undefined;
    }
    /**
     * Get the status code (only available in responses)
     */
    get statusCode() {
        return this.isResponse()
            ? this.proto.statusCode
            : undefined;
    }
    /**
     * Get the status description (only available in responses)
     */
    get statusDesc() {
        return this.isResponse()
            ? this.proto.statusDesc
            : undefined;
    }
    /**
     * Get the relay peer count (only available in responses)
     */
    get relayPeerCount() {
        return this.isResponse()
            ? this.proto.relayPeerCount
            : undefined;
    }
    /**
     * Check if this is a request message
     */
    isRequest() {
        return "pubsubTopic" in this.proto && "message" in this.proto;
    }
    /**
     * Check if this is a response message
     */
    isResponse() {
        return "statusCode" in this.proto;
    }
}

// should match nwaku
// https://github.com/waku-org/nwaku/blob/c3cb06ac6c03f0f382d3941ea53b330f6a8dd127/waku/waku_rln_relay/rln_relay.nim#L309
// https://github.com/waku-org/nwaku/blob/c3cb06ac6c03f0f382d3941ea53b330f6a8dd127/tests/waku_rln_relay/rln/waku_rln_relay_utils.nim#L20
const RLN_GENERATION_PREFIX_ERROR = "could not generate rln proof";
const RLN_MESSAGE_ID_PREFIX_ERROR = "could not get new message id to generate an rln proof";
// rare case on nwaku side
// https://github.com/waku-org/nwaku/blob/a4e92a3d02448fd708857b7b6cac2a7faa7eb4f9/waku/waku_lightpush/callbacks.nim#L49
// https://github.com/waku-org/nwaku/blob/a4e92a3d02448fd708857b7b6cac2a7faa7eb4f9/waku/node/waku_node.nim#L1117
const RLN_REMOTE_VALIDATION = "RLN validation failed";
const isRLNResponseError = (info) => {
    if (!info) {
        return false;
    }
    return (info.includes(RLN_GENERATION_PREFIX_ERROR) ||
        info.includes(RLN_MESSAGE_ID_PREFIX_ERROR) ||
        info.includes(RLN_REMOTE_VALIDATION));
};

const log$9 = new Logger("light-push:protocol-handler");
class ProtocolHandler {
    static async preparePushMessage(encoder, message, protocol) {
        try {
            if (!message.payload || message.payload.length === 0) {
                log$9.error("Failed to send waku light push: payload is empty");
                return { rpc: null, error: LightPushError.EMPTY_PAYLOAD };
            }
            if (!(await isMessageSizeUnderCap(encoder, message))) {
                log$9.error("Failed to send waku light push: message is bigger than 1MB");
                return { rpc: null, error: LightPushError.SIZE_TOO_BIG };
            }
            const protoMessage = await encoder.toProtoObj(message);
            if (!protoMessage) {
                log$9.error("Failed to encode to protoMessage, aborting push");
                return { rpc: null, error: LightPushError.ENCODE_FAILED };
            }
            if (protocol === CODECS.v3) {
                log$9.info("Creating v3 RPC message");
                return {
                    rpc: ProtocolHandler.createV3Rpc(protoMessage, encoder.pubsubTopic),
                    error: null
                };
            }
            log$9.info("Creating v2 RPC message");
            return {
                rpc: ProtocolHandler.createV2Rpc(protoMessage, encoder.pubsubTopic),
                error: null
            };
        }
        catch (err) {
            log$9.error("Failed to prepare push message", err);
            return { rpc: null, error: LightPushError.GENERIC_FAIL };
        }
    }
    /**
     * Decode and evaluate a LightPush response according to the protocol version
     */
    static handleResponse(bytes, protocol, peerId) {
        if (protocol === CODECS.v3) {
            return ProtocolHandler.handleV3Response(bytes, peerId);
        }
        return ProtocolHandler.handleV2Response(bytes, peerId);
    }
    static handleV3Response(bytes, peerId) {
        try {
            const decodedRpcV3 = PushRpc.decodeResponse(bytes);
            const statusCode = decodedRpcV3.statusCode;
            const statusDesc = decodedRpcV3.statusDesc;
            if (statusCode !== LightPushStatusCode.SUCCESS) {
                const error = LightPushError.REMOTE_PEER_REJECTED;
                log$9.error(`Remote peer rejected with v3 status code ${statusCode}: ${statusDesc}`);
                return {
                    success: null,
                    failure: {
                        error,
                        peerId: peerId
                    }
                };
            }
            if (decodedRpcV3.relayPeerCount !== undefined) {
                log$9.info(`Message relayed to ${decodedRpcV3.relayPeerCount} peers`);
            }
            return { success: peerId, failure: null };
        }
        catch (err) {
            return {
                success: null,
                failure: {
                    error: LightPushError.DECODE_FAILED,
                    peerId: peerId
                }
            };
        }
    }
    static handleV2Response(bytes, peerId) {
        let response;
        try {
            const decodedRpc = PushRpcV2.decode(bytes);
            response = decodedRpc.response;
        }
        catch (err) {
            return {
                success: null,
                failure: {
                    error: LightPushError.DECODE_FAILED,
                    peerId: peerId
                }
            };
        }
        if (!response) {
            return {
                success: null,
                failure: {
                    error: LightPushError.NO_RESPONSE,
                    peerId: peerId
                }
            };
        }
        if (isRLNResponseError(response.info)) {
            log$9.error("Remote peer fault: RLN generation");
            return {
                success: null,
                failure: {
                    error: LightPushError.RLN_PROOF_GENERATION,
                    peerId: peerId
                }
            };
        }
        if (!response.isSuccess) {
            log$9.error("Remote peer rejected the message: ", response.info);
            return {
                success: null,
                failure: {
                    error: LightPushError.REMOTE_PEER_REJECTED,
                    peerId: peerId
                }
            };
        }
        return { success: peerId, failure: null };
    }
    static createV2Rpc(message, pubsubTopic) {
        const v2Rpc = PushRpcV2.createRequest(message, pubsubTopic);
        return Object.assign(v2Rpc, { version: "v2" });
    }
    static createV3Rpc(message, pubsubTopic) {
        if (!message.timestamp) {
            message.timestamp = BigInt(Date.now()) * BigInt(1_000_000);
        }
        const v3Rpc = PushRpc.createRequest(message, pubsubTopic);
        return Object.assign(v3Rpc, { version: "v3" });
    }
}

const log$8 = new Logger("light-push");
/**
 * Implements the [Waku v2 Light Push protocol](https://rfc.vac.dev/spec/19/).
 */
class LightPushCore {
    libp2p;
    streamManager;
    streamManagerV2;
    multicodec = [CODECS.v3, CODECS.v2];
    constructor(libp2p) {
        this.libp2p = libp2p;
        this.streamManagerV2 = new StreamManager(CODECS.v2, libp2p.components);
        this.streamManager = new StreamManager(CODECS.v3, libp2p.components);
    }
    async send(encoder, message, peerId, useLegacy = false) {
        const protocol = await this.getProtocol(peerId, useLegacy);
        log$8.info(`Sending light push request to peer:${peerId.toString()}, protocol:${protocol}`);
        if (!protocol) {
            return {
                success: null,
                failure: {
                    error: LightPushError.GENERIC_FAIL,
                    peerId
                }
            };
        }
        const { rpc, error: prepError } = await ProtocolHandler.preparePushMessage(encoder, message, protocol);
        if (prepError) {
            return {
                success: null,
                failure: {
                    error: prepError,
                    peerId
                }
            };
        }
        const stream = await this.getStream(peerId, protocol);
        if (!stream) {
            log$8.error(`Failed to get a stream for remote peer:${peerId.toString()}`);
            return {
                success: null,
                failure: {
                    error: LightPushError.NO_STREAM_AVAILABLE,
                    peerId: peerId
                }
            };
        }
        let res;
        try {
            res = await pipe([rpc.encode()], encode, stream, decode, async (source) => await all(source));
        }
        catch (err) {
            log$8.error("Failed to send waku light push request", err);
            return {
                success: null,
                failure: {
                    error: LightPushError.STREAM_ABORTED,
                    peerId: peerId
                }
            };
        }
        const bytes = new Uint8ArrayList();
        res.forEach((chunk) => bytes.append(chunk));
        if (bytes.length === 0) {
            return {
                success: null,
                failure: {
                    error: LightPushError.NO_RESPONSE,
                    peerId: peerId
                }
            };
        }
        return ProtocolHandler.handleResponse(bytes, protocol, peerId);
    }
    async getProtocol(peerId, useLegacy) {
        try {
            const peer = await this.libp2p.peerStore.get(peerId);
            if (useLegacy ||
                (!peer.protocols.includes(CODECS.v3) &&
                    peer.protocols.includes(CODECS.v2))) {
                return CODECS.v2;
            }
            else if (peer.protocols.includes(CODECS.v3)) {
                return CODECS.v3;
            }
            else {
                throw new Error("No supported protocol found");
            }
        }
        catch (error) {
            log$8.error("Failed to get protocol", error);
            return undefined;
        }
    }
    async getStream(peerId, protocol) {
        switch (protocol) {
            case CODECS.v2:
                return this.streamManagerV2.getStream(peerId);
            case CODECS.v3:
                return this.streamManager.getStream(peerId);
            default:
                return undefined;
        }
    }
}

var index$1 = /*#__PURE__*/Object.freeze({
    __proto__: null,
    LightPushCodec: LightPushCodec,
    LightPushCodecV2: LightPushCodecV2,
    LightPushCore: LightPushCore
});

const EmptyMessage = {
    payload: new Uint8Array(),
    contentTopic: "",
    version: undefined,
    timestamp: undefined,
    meta: undefined,
    rateLimitProof: undefined,
    ephemeral: undefined
};
function toProtoMessage(wire) {
    return { ...EmptyMessage, ...wire };
}

// https://github.com/waku-org/nwaku/blob/7205f95cff9f49ca0bb762e8fd0bf56a6a7f3b3b/waku/waku_store/common.nim#L12
const DEFAULT_PAGE_SIZE = 20;
const MAX_PAGE_SIZE = 100;
const MAX_TIME_RANGE = 24 * 60 * 60 * 1000;
const ONE_MILLION = 1_000000;
class StoreQueryRequest {
    proto;
    constructor(proto) {
        this.proto = proto;
    }
    static create(params) {
        const request = new StoreQueryRequest({
            ...params,
            contentTopics: params.contentTopics || [],
            requestId: v4(),
            timeStart: params.timeStart
                ? BigInt(params.timeStart.getTime() * ONE_MILLION)
                : undefined,
            timeEnd: params.timeEnd
                ? BigInt(params.timeEnd.getTime() * ONE_MILLION)
                : undefined,
            messageHashes: params.messageHashes || [],
            paginationLimit: params.paginationLimit
                ? BigInt(params.paginationLimit)
                : undefined
        });
        const isHashQuery = params.messageHashes && params.messageHashes.length > 0;
        const hasContentTopics = params.contentTopics && params.contentTopics.length > 0;
        const hasTimeFilter = params.timeStart || params.timeEnd;
        if (isHashQuery) {
            if (hasContentTopics || hasTimeFilter) {
                throw new Error("Message hash lookup queries cannot include content filter criteria (contentTopics, timeStart, or timeEnd)");
            }
        }
        else {
            if ((params.pubsubTopic &&
                (!params.contentTopics || params.contentTopics.length === 0)) ||
                (!params.pubsubTopic &&
                    params.contentTopics &&
                    params.contentTopics.length > 0)) {
                throw new Error("Both pubsubTopic and contentTopics must be set together for content-filtered queries");
            }
        }
        return request;
    }
    static decode(bytes) {
        const res = StoreQueryRequest$1.decode(bytes);
        return new StoreQueryRequest(res);
    }
    encode() {
        return StoreQueryRequest$1.encode(this.proto);
    }
}
class StoreQueryResponse {
    proto;
    constructor(proto) {
        this.proto = proto;
    }
    static decode(bytes) {
        const res = StoreQueryResponse$1.decode(bytes);
        return new StoreQueryResponse(res);
    }
    encode() {
        return StoreQueryResponse$1.encode(this.proto);
    }
    get statusCode() {
        return this.proto.statusCode;
    }
    get statusDesc() {
        return this.proto.statusDesc;
    }
    get messages() {
        return this.proto.messages;
    }
    get paginationCursor() {
        return this.proto.paginationCursor;
    }
}

const log$7 = new Logger("store");
const StoreCodec = "/vac/waku/store-query/3.0.0";
class StoreCore {
    streamManager;
    multicodec = StoreCodec;
    constructor(libp2p) {
        this.streamManager = new StreamManager(StoreCodec, libp2p.components);
    }
    get maxTimeLimit() {
        return MAX_TIME_RANGE;
    }
    async *queryPerPage(queryOpts, decoders, peerId) {
        if (queryOpts.timeStart && queryOpts.timeEnd) {
            const timeDiff = queryOpts.timeEnd.getTime() - queryOpts.timeStart.getTime();
            if (timeDiff > MAX_TIME_RANGE) {
                throw new Error("Time range bigger than 24h");
            }
        }
        // Only validate decoder content topics for content-filtered queries
        const isHashQuery = queryOpts.messageHashes && queryOpts.messageHashes.length > 0;
        if (!isHashQuery &&
            queryOpts.contentTopics &&
            queryOpts.contentTopics.toString() !==
                Array.from(decoders.keys()).toString()) {
            throw new Error("Internal error, the decoders should match the query's content topics");
        }
        let currentCursor = queryOpts.paginationCursor;
        while (true) {
            const storeQueryRequest = StoreQueryRequest.create({
                ...queryOpts,
                paginationCursor: currentCursor
            });
            log$7.info("Sending store query request:", {
                hasMessageHashes: !!queryOpts.messageHashes?.length,
                messageHashCount: queryOpts.messageHashes?.length,
                pubsubTopic: queryOpts.pubsubTopic,
                contentTopics: queryOpts.contentTopics
            });
            const stream = await this.streamManager.getStream(peerId);
            if (!stream) {
                log$7.error(`Failed to get a stream for remote peer:${peerId.toString()}`);
                break;
            }
            const res = await pipe([storeQueryRequest.encode()], encode, stream, decode, async (source) => await all(source));
            const bytes = new Uint8ArrayList();
            res.forEach((chunk) => {
                bytes.append(chunk);
            });
            const storeQueryResponse = StoreQueryResponse.decode(bytes);
            if (!storeQueryResponse.statusCode ||
                storeQueryResponse.statusCode >= 300) {
                const errorMessage = `Store query failed with status code: ${storeQueryResponse.statusCode}, description: ${storeQueryResponse.statusDesc}`;
                log$7.error(errorMessage);
                throw new Error(errorMessage);
            }
            if (!storeQueryResponse.messages || !storeQueryResponse.messages.length) {
                log$7.warn("Stopping pagination due to empty messages in response");
                break;
            }
            log$7.info(`${storeQueryResponse.messages.length} messages retrieved from store`);
            const decodedMessages = storeQueryResponse.messages.map((protoMsg) => {
                if (!protoMsg.message) {
                    return Promise.resolve(undefined);
                }
                const contentTopic = protoMsg.message.contentTopic;
                if (contentTopic) {
                    const decoder = decoders.get(contentTopic);
                    if (decoder) {
                        return decoder.fromProtoObj(protoMsg.pubsubTopic || "", toProtoMessage(protoMsg.message));
                    }
                }
                return Promise.resolve(undefined);
            });
            yield decodedMessages;
            if (queryOpts.paginationForward) {
                currentCursor =
                    storeQueryResponse.messages[storeQueryResponse.messages.length - 1]
                        .messageHash;
            }
            else {
                currentCursor = storeQueryResponse.messages[0].messageHash;
            }
            if (storeQueryResponse.messages.length > MAX_PAGE_SIZE &&
                storeQueryResponse.messages.length <
                    (queryOpts.paginationLimit || DEFAULT_PAGE_SIZE)) {
                break;
            }
        }
    }
}

var index = /*#__PURE__*/Object.freeze({
    __proto__: null,
    StoreCodec: StoreCodec,
    StoreCore: StoreCore
});

const TAG_MASK = parseInt('11111', 2);
const LONG_LENGTH_MASK = parseInt('10000000', 2);
const LONG_LENGTH_BYTES_MASK = parseInt('01111111', 2);
const decoders$1 = {
    0x0: readSequence,
    0x1: readSequence,
    0x2: readInteger,
    0x3: readBitString,
    0x4: readOctetString,
    0x5: readNull,
    0x6: readObjectIdentifier,
    0x10: readSequence,
    0x16: readSequence,
    0x30: readSequence
};
function decodeDer(buf, context = { offset: 0 }) {
    const tag = buf[context.offset] & TAG_MASK;
    context.offset++;
    if (decoders$1[tag] != null) {
        return decoders$1[tag](buf, context);
    }
    throw new Error('No decoder for tag ' + tag);
}
function readLength(buf, context) {
    let length = 0;
    if ((buf[context.offset] & LONG_LENGTH_MASK) === LONG_LENGTH_MASK) {
        // long length
        const count = buf[context.offset] & LONG_LENGTH_BYTES_MASK;
        let str = '0x';
        context.offset++;
        for (let i = 0; i < count; i++, context.offset++) {
            str += buf[context.offset].toString(16).padStart(2, '0');
        }
        length = parseInt(str, 16);
    }
    else {
        length = buf[context.offset];
        context.offset++;
    }
    return length;
}
function readSequence(buf, context) {
    readLength(buf, context);
    const entries = [];
    while (true) {
        if (context.offset >= buf.byteLength) {
            break;
        }
        const result = decodeDer(buf, context);
        if (result === null) {
            break;
        }
        entries.push(result);
    }
    return entries;
}
function readInteger(buf, context) {
    const length = readLength(buf, context);
    const start = context.offset;
    const end = context.offset + length;
    const vals = [];
    for (let i = start; i < end; i++) {
        if (i === start && buf[i] === 0) {
            continue;
        }
        vals.push(buf[i]);
    }
    context.offset += length;
    return Uint8Array.from(vals);
}
function readObjectIdentifier(buf, context) {
    const count = readLength(buf, context);
    const finalOffset = context.offset + count;
    const byte = buf[context.offset];
    context.offset++;
    let val1 = 0;
    let val2 = 0;
    if (byte < 40) {
        val1 = 0;
        val2 = byte;
    }
    else if (byte < 80) {
        val1 = 1;
        val2 = byte - 40;
    }
    else {
        val1 = 2;
        val2 = byte - 80;
    }
    let oid = `${val1}.${val2}`;
    let num = [];
    while (context.offset < finalOffset) {
        const byte = buf[context.offset];
        context.offset++;
        // remove msb
        num.push(byte & 0b01111111);
        if (byte < 128) {
            num.reverse();
            // reached the end of the encoding
            let val = 0;
            for (let i = 0; i < num.length; i++) {
                val += num[i] << (i * 7);
            }
            oid += `.${val}`;
            num = [];
        }
    }
    return oid;
}
function readNull(buf, context) {
    context.offset++;
    return null;
}
function readBitString(buf, context) {
    const length = readLength(buf, context);
    const unusedBits = buf[context.offset];
    context.offset++;
    const bytes = buf.subarray(context.offset, context.offset + length - 1);
    context.offset += length;
    if (unusedBits !== 0) {
        // need to shift all bytes along by this many bits
        throw new Error('Unused bits in bit string is unimplemented');
    }
    return bytes;
}
function readOctetString(buf, context) {
    const length = readLength(buf, context);
    const bytes = buf.subarray(context.offset, context.offset + length);
    context.offset += length;
    return bytes;
}
function encodeNumber(value) {
    let number = value.toString(16);
    if (number.length % 2 === 1) {
        number = '0' + number;
    }
    const array = new Uint8ArrayList();
    for (let i = 0; i < number.length; i += 2) {
        array.append(Uint8Array.from([parseInt(`${number[i]}${number[i + 1]}`, 16)]));
    }
    return array;
}
function encodeLength(bytes) {
    if (bytes.byteLength < 128) {
        return Uint8Array.from([bytes.byteLength]);
    }
    // long length
    const length = encodeNumber(bytes.byteLength);
    return new Uint8ArrayList(Uint8Array.from([
        length.byteLength | LONG_LENGTH_MASK
    ]), length);
}
function encodeInteger(value) {
    const contents = new Uint8ArrayList();
    const mask = 0b10000000;
    const positive = (value.subarray()[0] & mask) === mask;
    if (positive) {
        contents.append(Uint8Array.from([0]));
    }
    contents.append(value);
    return new Uint8ArrayList(Uint8Array.from([0x02]), encodeLength(contents), contents);
}
function encodeBitString(value) {
    // unused bits is always 0 with full-byte-only values
    const unusedBits = Uint8Array.from([0]);
    const contents = new Uint8ArrayList(unusedBits, value);
    return new Uint8ArrayList(Uint8Array.from([0x03]), encodeLength(contents), contents);
}
function encodeSequence(values, tag = 0x30) {
    const output = new Uint8ArrayList();
    for (const buf of values) {
        output.append(buf);
    }
    return new Uint8ArrayList(Uint8Array.from([tag]), encodeLength(output), output);
}

async function hashAndVerify$2(key, sig, msg, options) {
    const publicKey = await crypto.subtle.importKey('jwk', key, {
        name: 'ECDSA',
        namedCurve: key.crv ?? 'P-256'
    }, false, ['verify']);
    options?.signal?.throwIfAborted();
    const result = await crypto.subtle.verify({
        name: 'ECDSA',
        hash: {
            name: 'SHA-256'
        }
    }, publicKey, sig, msg.subarray());
    options?.signal?.throwIfAborted();
    return result;
}

// 1.2.840.10045.3.1.7 prime256v1 (ANSI X9.62 named elliptic curve)
const OID_256 = Uint8Array.from([0x06, 0x08, 0x2A, 0x86, 0x48, 0xCE, 0x3D, 0x03, 0x01, 0x07]);
// 1.3.132.0.34 secp384r1 (SECG (Certicom) named elliptic curve)
const OID_384 = Uint8Array.from([0x06, 0x05, 0x2B, 0x81, 0x04, 0x00, 0x22]);
// 1.3.132.0.35 secp521r1 (SECG (Certicom) named elliptic curve)
const OID_521 = Uint8Array.from([0x06, 0x05, 0x2B, 0x81, 0x04, 0x00, 0x23]);
const P_256_KEY_JWK = {
    ext: true,
    kty: 'EC',
    crv: 'P-256'
};
const P_384_KEY_JWK = {
    ext: true,
    kty: 'EC',
    crv: 'P-384'
};
const P_521_KEY_JWK = {
    ext: true,
    kty: 'EC',
    crv: 'P-521'
};
const P_256_KEY_LENGTH = 32;
const P_384_KEY_LENGTH = 48;
const P_521_KEY_LENGTH = 66;
function unmarshalECDSAPublicKey(bytes) {
    const message = decodeDer(bytes);
    return pkiMessageToECDSAPublicKey(message);
}
function pkiMessageToECDSAPublicKey(message) {
    const coordinates = message[1][1][0];
    const offset = 1;
    let x;
    let y;
    if (coordinates.byteLength === ((P_256_KEY_LENGTH * 2) + 1)) {
        x = toString(coordinates.subarray(offset, offset + P_256_KEY_LENGTH), 'base64url');
        y = toString(coordinates.subarray(offset + P_256_KEY_LENGTH), 'base64url');
        return new ECDSAPublicKey({
            ...P_256_KEY_JWK,
            key_ops: ['verify'],
            x,
            y
        });
    }
    if (coordinates.byteLength === ((P_384_KEY_LENGTH * 2) + 1)) {
        x = toString(coordinates.subarray(offset, offset + P_384_KEY_LENGTH), 'base64url');
        y = toString(coordinates.subarray(offset + P_384_KEY_LENGTH), 'base64url');
        return new ECDSAPublicKey({
            ...P_384_KEY_JWK,
            key_ops: ['verify'],
            x,
            y
        });
    }
    if (coordinates.byteLength === ((P_521_KEY_LENGTH * 2) + 1)) {
        x = toString(coordinates.subarray(offset, offset + P_521_KEY_LENGTH), 'base64url');
        y = toString(coordinates.subarray(offset + P_521_KEY_LENGTH), 'base64url');
        return new ECDSAPublicKey({
            ...P_521_KEY_JWK,
            key_ops: ['verify'],
            x,
            y
        });
    }
    throw new InvalidParametersError$1(`coordinates were wrong length, got ${coordinates.byteLength}, expected 65, 97 or 133`);
}
function publicKeyToPKIMessage(publicKey) {
    return encodeSequence([
        encodeInteger(Uint8Array.from([1])), // header
        encodeSequence([
            getOID(publicKey.crv)
        ], 0xA0),
        encodeSequence([
            encodeBitString(new Uint8ArrayList(Uint8Array.from([0x04]), fromString(publicKey.x ?? '', 'base64url'), fromString(publicKey.y ?? '', 'base64url')))
        ], 0xA1)
    ]).subarray();
}
function getOID(curve) {
    if (curve === 'P-256') {
        return OID_256;
    }
    if (curve === 'P-384') {
        return OID_384;
    }
    if (curve === 'P-521') {
        return OID_521;
    }
    throw new InvalidParametersError$1(`Invalid curve ${curve}`);
}

class ECDSAPublicKey {
    type = 'ECDSA';
    jwk;
    _raw;
    constructor(jwk) {
        this.jwk = jwk;
    }
    get raw() {
        if (this._raw == null) {
            this._raw = publicKeyToPKIMessage(this.jwk);
        }
        return this._raw;
    }
    toMultihash() {
        return identity.digest(publicKeyToProtobuf(this));
    }
    toCID() {
        return CID.createV1(114, this.toMultihash());
    }
    toString() {
        return base58btc.encode(this.toMultihash().bytes).substring(1);
    }
    equals(key) {
        if (key == null || !(key.raw instanceof Uint8Array)) {
            return false;
        }
        return equals(this.raw, key.raw);
    }
    async verify(data, sig, options) {
        return hashAndVerify$2(this.jwk, sig, data, options);
    }
}

/**
 * Hex, bytes and number utilities.
 * @module
 */
/*! noble-curves - MIT License (c) 2022 Paul Miller (paulmillr.com) */
const _0n$4 = /* @__PURE__ */ BigInt(0);
const _1n$6 = /* @__PURE__ */ BigInt(1);
function abool(title, value) {
    if (typeof value !== 'boolean')
        throw new Error(title + ' boolean expected, got ' + value);
}
// Used in weierstrass, der
function numberToHexUnpadded(num) {
    const hex = num.toString(16);
    return hex.length & 1 ? '0' + hex : hex;
}
function hexToNumber(hex) {
    if (typeof hex !== 'string')
        throw new Error('hex string expected, got ' + typeof hex);
    return hex === '' ? _0n$4 : BigInt('0x' + hex); // Big Endian
}
// BE: Big Endian, LE: Little Endian
function bytesToNumberBE(bytes) {
    return hexToNumber(bytesToHex(bytes));
}
function bytesToNumberLE(bytes) {
    abytes(bytes);
    return hexToNumber(bytesToHex(Uint8Array.from(bytes).reverse()));
}
function numberToBytesBE(n, len) {
    return hexToBytes(n.toString(16).padStart(len * 2, '0'));
}
function numberToBytesLE(n, len) {
    return numberToBytesBE(n, len).reverse();
}
/**
 * Takes hex string or Uint8Array, converts to Uint8Array.
 * Validates output length.
 * Will throw error for other types.
 * @param title descriptive title for an error e.g. 'private key'
 * @param hex hex string or Uint8Array
 * @param expectedLength optional, will compare to result array's length
 * @returns
 */
function ensureBytes(title, hex, expectedLength) {
    let res;
    if (typeof hex === 'string') {
        try {
            res = hexToBytes(hex);
        }
        catch (e) {
            throw new Error(title + ' must be hex string or Uint8Array, cause: ' + e);
        }
    }
    else if (isBytes(hex)) {
        // Uint8Array.from() instead of hash.slice() because node.js Buffer
        // is instance of Uint8Array, and its slice() creates **mutable** copy
        res = Uint8Array.from(hex);
    }
    else {
        throw new Error(title + ' must be hex string or Uint8Array');
    }
    const len = res.length;
    if (typeof expectedLength === 'number' && len !== expectedLength)
        throw new Error(title + ' of length ' + expectedLength + ' expected, got ' + len);
    return res;
}
/**
 * @example utf8ToBytes('abc') // new Uint8Array([97, 98, 99])
 */
// export const utf8ToBytes: typeof utf8ToBytes_ = utf8ToBytes_;
/**
 * Converts bytes to string using UTF8 encoding.
 * @example bytesToUtf8(Uint8Array.from([97, 98, 99])) // 'abc'
 */
// export const bytesToUtf8: typeof bytesToUtf8_ = bytesToUtf8_;
// Is positive bigint
const isPosBig = (n) => typeof n === 'bigint' && _0n$4 <= n;
function inRange(n, min, max) {
    return isPosBig(n) && isPosBig(min) && isPosBig(max) && min <= n && n < max;
}
/**
 * Asserts min <= n < max. NOTE: It's < max and not <= max.
 * @example
 * aInRange('x', x, 1n, 256n); // would assume x is in (1n..255n)
 */
function aInRange(title, n, min, max) {
    // Why min <= n < max and not a (min < n < max) OR b (min <= n <= max)?
    // consider P=256n, min=0n, max=P
    // - a for min=0 would require -1:          `inRange('x', x, -1n, P)`
    // - b would commonly require subtraction:  `inRange('x', x, 0n, P - 1n)`
    // - our way is the cleanest:               `inRange('x', x, 0n, P)
    if (!inRange(n, min, max))
        throw new Error('expected valid ' + title + ': ' + min + ' <= n < ' + max + ', got ' + n);
}
// Bit operations
/**
 * Calculates amount of bits in a bigint.
 * Same as `n.toString(2).length`
 * TODO: merge with nLength in modular
 */
function bitLen(n) {
    let len;
    for (len = 0; n > _0n$4; n >>= _1n$6, len += 1)
        ;
    return len;
}
/**
 * Calculate mask for N bits. Not using ** operator with bigints because of old engines.
 * Same as BigInt(`0b${Array(i).fill('1').join('')}`)
 */
const bitMask = (n) => (_1n$6 << BigInt(n)) - _1n$6;
/**
 * Minimal HMAC-DRBG from NIST 800-90 for RFC6979 sigs.
 * @returns function that will call DRBG until 2nd arg returns something meaningful
 * @example
 *   const drbg = createHmacDRBG<Key>(32, 32, hmac);
 *   drbg(seed, bytesToKey); // bytesToKey must return Key or undefined
 */
function createHmacDrbg(hashLen, qByteLen, hmacFn) {
    if (typeof hashLen !== 'number' || hashLen < 2)
        throw new Error('hashLen must be a number');
    if (typeof qByteLen !== 'number' || qByteLen < 2)
        throw new Error('qByteLen must be a number');
    if (typeof hmacFn !== 'function')
        throw new Error('hmacFn must be a function');
    // Step B, Step C: set hashLen to 8*ceil(hlen/8)
    const u8n = (len) => new Uint8Array(len); // creates Uint8Array
    const u8of = (byte) => Uint8Array.of(byte); // another shortcut
    let v = u8n(hashLen); // Minimal non-full-spec HMAC-DRBG from NIST 800-90 for RFC6979 sigs.
    let k = u8n(hashLen); // Steps B and C of RFC6979 3.2: set hashLen, in our case always same
    let i = 0; // Iterations counter, will throw when over 1000
    const reset = () => {
        v.fill(1);
        k.fill(0);
        i = 0;
    };
    const h = (...b) => hmacFn(k, v, ...b); // hmac(k)(v, ...values)
    const reseed = (seed = u8n(0)) => {
        // HMAC-DRBG reseed() function. Steps D-G
        k = h(u8of(0x00), seed); // k = hmac(k || v || 0x00 || seed)
        v = h(); // v = hmac(k || v)
        if (seed.length === 0)
            return;
        k = h(u8of(0x01), seed); // k = hmac(k || v || 0x01 || seed)
        v = h(); // v = hmac(k || v)
    };
    const gen = () => {
        // HMAC-DRBG generate() function
        if (i++ >= 1000)
            throw new Error('drbg: tried 1000 values');
        let len = 0;
        const out = [];
        while (len < qByteLen) {
            v = h();
            const sl = v.slice();
            out.push(sl);
            len += v.length;
        }
        return concatBytes(...out);
    };
    const genUntil = (seed, pred) => {
        reset();
        reseed(seed); // Steps D-G
        let res = undefined; // Step H: grind until k is in [1..n-1]
        while (!(res = pred(gen())))
            reseed();
        reset();
        return res;
    };
    return genUntil;
}
function _validateObject(object, fields, optFields = {}) {
    if (!object || typeof object !== 'object')
        throw new Error('expected valid options object');
    function checkField(fieldName, expectedType, isOpt) {
        const val = object[fieldName];
        if (isOpt && val === undefined)
            return;
        const current = typeof val;
        if (current !== expectedType || val === null)
            throw new Error(`param "${fieldName}" is invalid: expected ${expectedType}, got ${current}`);
    }
    Object.entries(fields).forEach(([k, v]) => checkField(k, v, false));
    Object.entries(optFields).forEach(([k, v]) => checkField(k, v, true));
}
/**
 * Memoizes (caches) computation result.
 * Uses WeakMap: the value is going auto-cleaned by GC after last reference is removed.
 */
function memoized(fn) {
    const map = new WeakMap();
    return (arg, ...args) => {
        const val = map.get(arg);
        if (val !== undefined)
            return val;
        const computed = fn(arg, ...args);
        map.set(arg, computed);
        return computed;
    };
}

/**
 * Utils for modular division and fields.
 * Field over 11 is a finite (Galois) field is integer number operations `mod 11`.
 * There is no division: it is replaced by modular multiplicative inverse.
 * @module
 */
/*! noble-curves - MIT License (c) 2022 Paul Miller (paulmillr.com) */
// prettier-ignore
const _0n$3 = BigInt(0), _1n$5 = BigInt(1), _2n$4 = /* @__PURE__ */ BigInt(2), _3n$1 = /* @__PURE__ */ BigInt(3);
// prettier-ignore
const _4n$1 = /* @__PURE__ */ BigInt(4), _5n$1 = /* @__PURE__ */ BigInt(5);
const _8n$2 = /* @__PURE__ */ BigInt(8);
// Calculates a modulo b
function mod(a, b) {
    const result = a % b;
    return result >= _0n$3 ? result : b + result;
}
/** Does `x^(2^power)` mod p. `pow2(30, 4)` == `30^(2^4)` */
function pow2(x, power, modulo) {
    let res = x;
    while (power-- > _0n$3) {
        res *= res;
        res %= modulo;
    }
    return res;
}
/**
 * Inverses number over modulo.
 * Implemented using [Euclidean GCD](https://brilliant.org/wiki/extended-euclidean-algorithm/).
 */
function invert(number, modulo) {
    if (number === _0n$3)
        throw new Error('invert: expected non-zero number');
    if (modulo <= _0n$3)
        throw new Error('invert: expected positive modulus, got ' + modulo);
    // Fermat's little theorem "CT-like" version inv(n) = n^(m-2) mod m is 30x slower.
    let a = mod(number, modulo);
    let b = modulo;
    // prettier-ignore
    let x = _0n$3, u = _1n$5;
    while (a !== _0n$3) {
        // JIT applies optimization if those two lines follow each other
        const q = b / a;
        const r = b % a;
        const m = x - u * q;
        // prettier-ignore
        b = a, a = r, x = u, u = m;
    }
    const gcd = b;
    if (gcd !== _1n$5)
        throw new Error('invert: does not exist');
    return mod(x, modulo);
}
// Not all roots are possible! Example which will throw:
// const NUM =
// n = 72057594037927816n;
// Fp = Field(BigInt('0x1a0111ea397fe69a4b1ba7b6434bacd764774b84f38512bf6730d2a0f6b0f6241eabfffeb153ffffb9feffffffffaaab'));
function sqrt3mod4(Fp, n) {
    const p1div4 = (Fp.ORDER + _1n$5) / _4n$1;
    const root = Fp.pow(n, p1div4);
    // Throw if root^2 != n
    if (!Fp.eql(Fp.sqr(root), n))
        throw new Error('Cannot find square root');
    return root;
}
function sqrt5mod8(Fp, n) {
    const p5div8 = (Fp.ORDER - _5n$1) / _8n$2;
    const n2 = Fp.mul(n, _2n$4);
    const v = Fp.pow(n2, p5div8);
    const nv = Fp.mul(n, v);
    const i = Fp.mul(Fp.mul(nv, _2n$4), v);
    const root = Fp.mul(nv, Fp.sub(i, Fp.ONE));
    if (!Fp.eql(Fp.sqr(root), n))
        throw new Error('Cannot find square root');
    return root;
}
// TODO: Commented-out for now. Provide test vectors.
// Tonelli is too slow for extension fields Fp2.
// That means we can't use sqrt (c1, c2...) even for initialization constants.
// if (P % _16n === _9n) return sqrt9mod16;
// // prettier-ignore
// function sqrt9mod16<T>(Fp: IField<T>, n: T, p7div16?: bigint) {
//   if (p7div16 === undefined) p7div16 = (Fp.ORDER + BigInt(7)) / _16n;
//   const c1 = Fp.sqrt(Fp.neg(Fp.ONE)); //  1. c1 = sqrt(-1) in F, i.e., (c1^2) == -1 in F
//   const c2 = Fp.sqrt(c1);             //  2. c2 = sqrt(c1) in F, i.e., (c2^2) == c1 in F
//   const c3 = Fp.sqrt(Fp.neg(c1));     //  3. c3 = sqrt(-c1) in F, i.e., (c3^2) == -c1 in F
//   const c4 = p7div16;                 //  4. c4 = (q + 7) / 16        # Integer arithmetic
//   let tv1 = Fp.pow(n, c4);            //  1. tv1 = x^c4
//   let tv2 = Fp.mul(c1, tv1);          //  2. tv2 = c1 * tv1
//   const tv3 = Fp.mul(c2, tv1);        //  3. tv3 = c2 * tv1
//   let tv4 = Fp.mul(c3, tv1);          //  4. tv4 = c3 * tv1
//   const e1 = Fp.eql(Fp.sqr(tv2), n);  //  5.  e1 = (tv2^2) == x
//   const e2 = Fp.eql(Fp.sqr(tv3), n);  //  6.  e2 = (tv3^2) == x
//   tv1 = Fp.cmov(tv1, tv2, e1); //  7. tv1 = CMOV(tv1, tv2, e1)  # Select tv2 if (tv2^2) == x
//   tv2 = Fp.cmov(tv4, tv3, e2); //  8. tv2 = CMOV(tv4, tv3, e2)  # Select tv3 if (tv3^2) == x
//   const e3 = Fp.eql(Fp.sqr(tv2), n);  //  9.  e3 = (tv2^2) == x
//   return Fp.cmov(tv1, tv2, e3); // 10.  z = CMOV(tv1, tv2, e3) # Select the sqrt from tv1 and tv2
// }
/**
 * Tonelli-Shanks square root search algorithm.
 * 1. https://eprint.iacr.org/2012/685.pdf (page 12)
 * 2. Square Roots from 1; 24, 51, 10 to Dan Shanks
 * @param P field order
 * @returns function that takes field Fp (created from P) and number n
 */
function tonelliShanks(P) {
    // Initialization (precomputation).
    // Caching initialization could boost perf by 7%.
    if (P < BigInt(3))
        throw new Error('sqrt is not defined for small field');
    // Factor P - 1 = Q * 2^S, where Q is odd
    let Q = P - _1n$5;
    let S = 0;
    while (Q % _2n$4 === _0n$3) {
        Q /= _2n$4;
        S++;
    }
    // Find the first quadratic non-residue Z >= 2
    let Z = _2n$4;
    const _Fp = Field(P);
    while (FpLegendre(_Fp, Z) === 1) {
        // Basic primality test for P. After x iterations, chance of
        // not finding quadratic non-residue is 2^x, so 2^1000.
        if (Z++ > 1000)
            throw new Error('Cannot find square root: probably non-prime P');
    }
    // Fast-path; usually done before Z, but we do "primality test".
    if (S === 1)
        return sqrt3mod4;
    // Slow-path
    // TODO: test on Fp2 and others
    let cc = _Fp.pow(Z, Q); // c = z^Q
    const Q1div2 = (Q + _1n$5) / _2n$4;
    return function tonelliSlow(Fp, n) {
        if (Fp.is0(n))
            return n;
        // Check if n is a quadratic residue using Legendre symbol
        if (FpLegendre(Fp, n) !== 1)
            throw new Error('Cannot find square root');
        // Initialize variables for the main loop
        let M = S;
        let c = Fp.mul(Fp.ONE, cc); // c = z^Q, move cc from field _Fp into field Fp
        let t = Fp.pow(n, Q); // t = n^Q, first guess at the fudge factor
        let R = Fp.pow(n, Q1div2); // R = n^((Q+1)/2), first guess at the square root
        // Main loop
        // while t != 1
        while (!Fp.eql(t, Fp.ONE)) {
            if (Fp.is0(t))
                return Fp.ZERO; // if t=0 return R=0
            let i = 1;
            // Find the smallest i >= 1 such that t^(2^i)  1 (mod P)
            let t_tmp = Fp.sqr(t); // t^(2^1)
            while (!Fp.eql(t_tmp, Fp.ONE)) {
                i++;
                t_tmp = Fp.sqr(t_tmp); // t^(2^2)...
                if (i === M)
                    throw new Error('Cannot find square root');
            }
            // Calculate the exponent for b: 2^(M - i - 1)
            const exponent = _1n$5 << BigInt(M - i - 1); // bigint is important
            const b = Fp.pow(c, exponent); // b = 2^(M - i - 1)
            // Update variables
            M = i;
            c = Fp.sqr(b); // c = b^2
            t = Fp.mul(t, c); // t = (t * b^2)
            R = Fp.mul(R, b); // R = R*b
        }
        return R;
    };
}
/**
 * Square root for a finite field. Will try optimized versions first:
 *
 * 1. P  3 (mod 4)
 * 2. P  5 (mod 8)
 * 3. Tonelli-Shanks algorithm
 *
 * Different algorithms can give different roots, it is up to user to decide which one they want.
 * For example there is FpSqrtOdd/FpSqrtEven to choice root based on oddness (used for hash-to-curve).
 */
function FpSqrt(P) {
    // P  3 (mod 4) => n = n^((P+1)/4)
    if (P % _4n$1 === _3n$1)
        return sqrt3mod4;
    // P  5 (mod 8) => Atkin algorithm, page 10 of https://eprint.iacr.org/2012/685.pdf
    if (P % _8n$2 === _5n$1)
        return sqrt5mod8;
    // P  9 (mod 16) not implemented, see above
    // Tonelli-Shanks algorithm
    return tonelliShanks(P);
}
// Little-endian check for first LE bit (last BE bit);
const isNegativeLE = (num, modulo) => (mod(num, modulo) & _1n$5) === _1n$5;
// prettier-ignore
const FIELD_FIELDS = [
    'create', 'isValid', 'is0', 'neg', 'inv', 'sqrt', 'sqr',
    'eql', 'add', 'sub', 'mul', 'pow', 'div',
    'addN', 'subN', 'mulN', 'sqrN'
];
function validateField(field) {
    const initial = {
        ORDER: 'bigint',
        MASK: 'bigint',
        BYTES: 'number',
        BITS: 'number',
    };
    const opts = FIELD_FIELDS.reduce((map, val) => {
        map[val] = 'function';
        return map;
    }, initial);
    _validateObject(field, opts);
    // const max = 16384;
    // if (field.BYTES < 1 || field.BYTES > max) throw new Error('invalid field');
    // if (field.BITS < 1 || field.BITS > 8 * max) throw new Error('invalid field');
    return field;
}
// Generic field functions
/**
 * Same as `pow` but for Fp: non-constant-time.
 * Unsafe in some contexts: uses ladder, so can expose bigint bits.
 */
function FpPow(Fp, num, power) {
    if (power < _0n$3)
        throw new Error('invalid exponent, negatives unsupported');
    if (power === _0n$3)
        return Fp.ONE;
    if (power === _1n$5)
        return num;
    let p = Fp.ONE;
    let d = num;
    while (power > _0n$3) {
        if (power & _1n$5)
            p = Fp.mul(p, d);
        d = Fp.sqr(d);
        power >>= _1n$5;
    }
    return p;
}
/**
 * Efficiently invert an array of Field elements.
 * Exception-free. Will return `undefined` for 0 elements.
 * @param passZero map 0 to 0 (instead of undefined)
 */
function FpInvertBatch(Fp, nums, passZero = false) {
    const inverted = new Array(nums.length).fill(passZero ? Fp.ZERO : undefined);
    // Walk from first to last, multiply them by each other MOD p
    const multipliedAcc = nums.reduce((acc, num, i) => {
        if (Fp.is0(num))
            return acc;
        inverted[i] = acc;
        return Fp.mul(acc, num);
    }, Fp.ONE);
    // Invert last element
    const invertedAcc = Fp.inv(multipliedAcc);
    // Walk from last to first, multiply them by inverted each other MOD p
    nums.reduceRight((acc, num, i) => {
        if (Fp.is0(num))
            return acc;
        inverted[i] = Fp.mul(acc, inverted[i]);
        return Fp.mul(acc, num);
    }, invertedAcc);
    return inverted;
}
/**
 * Legendre symbol.
 * Legendre constant is used to calculate Legendre symbol (a | p)
 * which denotes the value of a^((p-1)/2) (mod p).
 *
 * * (a | p)  1    if a is a square (mod p), quadratic residue
 * * (a | p)  -1   if a is not a square (mod p), quadratic non residue
 * * (a | p)  0    if a  0 (mod p)
 */
function FpLegendre(Fp, n) {
    // We can use 3rd argument as optional cache of this value
    // but seems unneeded for now. The operation is very fast.
    const p1mod2 = (Fp.ORDER - _1n$5) / _2n$4;
    const powered = Fp.pow(n, p1mod2);
    const yes = Fp.eql(powered, Fp.ONE);
    const zero = Fp.eql(powered, Fp.ZERO);
    const no = Fp.eql(powered, Fp.neg(Fp.ONE));
    if (!yes && !zero && !no)
        throw new Error('invalid Legendre symbol result');
    return yes ? 1 : zero ? 0 : -1;
}
// CURVE.n lengths
function nLength(n, nBitLength) {
    // Bit size, byte size of CURVE.n
    if (nBitLength !== undefined)
        anumber(nBitLength);
    const _nBitLength = nBitLength !== undefined ? nBitLength : n.toString(2).length;
    const nByteLength = Math.ceil(_nBitLength / 8);
    return { nBitLength: _nBitLength, nByteLength };
}
/**
 * Creates a finite field. Major performance optimizations:
 * * 1. Denormalized operations like mulN instead of mul.
 * * 2. Identical object shape: never add or remove keys.
 * * 3. `Object.freeze`.
 * Fragile: always run a benchmark on a change.
 * Security note: operations don't check 'isValid' for all elements for performance reasons,
 * it is caller responsibility to check this.
 * This is low-level code, please make sure you know what you're doing.
 *
 * Note about field properties:
 * * CHARACTERISTIC p = prime number, number of elements in main subgroup.
 * * ORDER q = similar to cofactor in curves, may be composite `q = p^m`.
 *
 * @param ORDER field order, probably prime, or could be composite
 * @param bitLen how many bits the field consumes
 * @param isLE (default: false) if encoding / decoding should be in little-endian
 * @param redef optional faster redefinitions of sqrt and other methods
 */
function Field(ORDER, bitLenOrOpts, isLE = false, opts = {}) {
    if (ORDER <= _0n$3)
        throw new Error('invalid field: expected ORDER > 0, got ' + ORDER);
    let _nbitLength = undefined;
    let _sqrt = undefined;
    if (typeof bitLenOrOpts === 'object' && bitLenOrOpts != null) {
        if (opts.sqrt || isLE)
            throw new Error('cannot specify opts in two arguments');
        const _opts = bitLenOrOpts;
        if (_opts.BITS)
            _nbitLength = _opts.BITS;
        if (_opts.sqrt)
            _sqrt = _opts.sqrt;
        if (typeof _opts.isLE === 'boolean')
            isLE = _opts.isLE;
    }
    else {
        if (typeof bitLenOrOpts === 'number')
            _nbitLength = bitLenOrOpts;
        if (opts.sqrt)
            _sqrt = opts.sqrt;
    }
    const { nBitLength: BITS, nByteLength: BYTES } = nLength(ORDER, _nbitLength);
    if (BYTES > 2048)
        throw new Error('invalid field: expected ORDER of <= 2048 bytes');
    let sqrtP; // cached sqrtP
    const f = Object.freeze({
        ORDER,
        isLE,
        BITS,
        BYTES,
        MASK: bitMask(BITS),
        ZERO: _0n$3,
        ONE: _1n$5,
        create: (num) => mod(num, ORDER),
        isValid: (num) => {
            if (typeof num !== 'bigint')
                throw new Error('invalid field element: expected bigint, got ' + typeof num);
            return _0n$3 <= num && num < ORDER; // 0 is valid element, but it's not invertible
        },
        is0: (num) => num === _0n$3,
        // is valid and invertible
        isValidNot0: (num) => !f.is0(num) && f.isValid(num),
        isOdd: (num) => (num & _1n$5) === _1n$5,
        neg: (num) => mod(-num, ORDER),
        eql: (lhs, rhs) => lhs === rhs,
        sqr: (num) => mod(num * num, ORDER),
        add: (lhs, rhs) => mod(lhs + rhs, ORDER),
        sub: (lhs, rhs) => mod(lhs - rhs, ORDER),
        mul: (lhs, rhs) => mod(lhs * rhs, ORDER),
        pow: (num, power) => FpPow(f, num, power),
        div: (lhs, rhs) => mod(lhs * invert(rhs, ORDER), ORDER),
        // Same as above, but doesn't normalize
        sqrN: (num) => num * num,
        addN: (lhs, rhs) => lhs + rhs,
        subN: (lhs, rhs) => lhs - rhs,
        mulN: (lhs, rhs) => lhs * rhs,
        inv: (num) => invert(num, ORDER),
        sqrt: _sqrt ||
            ((n) => {
                if (!sqrtP)
                    sqrtP = FpSqrt(ORDER);
                return sqrtP(f, n);
            }),
        toBytes: (num) => (isLE ? numberToBytesLE(num, BYTES) : numberToBytesBE(num, BYTES)),
        fromBytes: (bytes) => {
            if (bytes.length !== BYTES)
                throw new Error('Field.fromBytes: expected ' + BYTES + ' bytes, got ' + bytes.length);
            return isLE ? bytesToNumberLE(bytes) : bytesToNumberBE(bytes);
        },
        // TODO: we don't need it here, move out to separate fn
        invertBatch: (lst) => FpInvertBatch(f, lst),
        // We can't move this out because Fp6, Fp12 implement it
        // and it's unclear what to return in there.
        cmov: (a, b, c) => (c ? b : a),
    });
    return Object.freeze(f);
}
/**
 * Returns total number of bytes consumed by the field element.
 * For example, 32 bytes for usual 256-bit weierstrass curve.
 * @param fieldOrder number of field elements, usually CURVE.n
 * @returns byte length of field
 */
function getFieldBytesLength(fieldOrder) {
    if (typeof fieldOrder !== 'bigint')
        throw new Error('field order must be bigint');
    const bitLength = fieldOrder.toString(2).length;
    return Math.ceil(bitLength / 8);
}
/**
 * Returns minimal amount of bytes that can be safely reduced
 * by field order.
 * Should be 2^-128 for 128-bit curve such as P256.
 * @param fieldOrder number of field elements, usually CURVE.n
 * @returns byte length of target hash
 */
function getMinHashLength(fieldOrder) {
    const length = getFieldBytesLength(fieldOrder);
    return length + Math.ceil(length / 2);
}
/**
 * "Constant-time" private key generation utility.
 * Can take (n + n/2) or more bytes of uniform input e.g. from CSPRNG or KDF
 * and convert them into private scalar, with the modulo bias being negligible.
 * Needs at least 48 bytes of input for 32-byte private key.
 * https://research.kudelskisecurity.com/2020/07/28/the-definitive-guide-to-modulo-bias-and-how-to-avoid-it/
 * FIPS 186-5, A.2 https://csrc.nist.gov/publications/detail/fips/186/5/final
 * RFC 9380, https://www.rfc-editor.org/rfc/rfc9380#section-5
 * @param hash hash output from SHA3 or a similar function
 * @param groupOrder size of subgroup - (e.g. secp256k1.CURVE.n)
 * @param isLE interpret hash bytes as LE num
 * @returns valid private scalar
 */
function mapHashToField(key, fieldOrder, isLE = false) {
    const len = key.length;
    const fieldLen = getFieldBytesLength(fieldOrder);
    const minLen = getMinHashLength(fieldOrder);
    // No small numbers: need to understand bias story. No huge numbers: easier to detect JS timings.
    if (len < 16 || len < minLen || len > 1024)
        throw new Error('expected ' + minLen + '-1024 bytes of input, got ' + len);
    const num = isLE ? bytesToNumberLE(key) : bytesToNumberBE(key);
    // `mod(x, 11)` can sometimes produce 0. `mod(x, 10) + 1` is the same, but no 0
    const reduced = mod(num, fieldOrder - _1n$5) + _1n$5;
    return isLE ? numberToBytesLE(reduced, fieldLen) : numberToBytesBE(reduced, fieldLen);
}

/**
 * Methods for elliptic curve multiplication by scalars.
 * Contains wNAF, pippenger
 * @module
 */
/*! noble-curves - MIT License (c) 2022 Paul Miller (paulmillr.com) */
const _0n$2 = BigInt(0);
const _1n$4 = BigInt(1);
function negateCt(condition, item) {
    const neg = item.negate();
    return condition ? neg : item;
}
/**
 * Takes a bunch of Projective Points but executes only one
 * inversion on all of them. Inversion is very slow operation,
 * so this improves performance massively.
 * Optimization: converts a list of projective points to a list of identical points with Z=1.
 */
function normalizeZ(c, property, points) {
    const getz = property === 'pz' ? (p) => p.pz : (p) => p.ez;
    const toInv = FpInvertBatch(c.Fp, points.map(getz));
    // @ts-ignore
    const affined = points.map((p, i) => p.toAffine(toInv[i]));
    return affined.map(c.fromAffine);
}
function validateW(W, bits) {
    if (!Number.isSafeInteger(W) || W <= 0 || W > bits)
        throw new Error('invalid window size, expected [1..' + bits + '], got W=' + W);
}
function calcWOpts(W, scalarBits) {
    validateW(W, scalarBits);
    const windows = Math.ceil(scalarBits / W) + 1; // W=8 33. Not 32, because we skip zero
    const windowSize = 2 ** (W - 1); // W=8 128. Not 256, because we skip zero
    const maxNumber = 2 ** W; // W=8 256
    const mask = bitMask(W); // W=8 255 == mask 0b11111111
    const shiftBy = BigInt(W); // W=8 8
    return { windows, windowSize, mask, maxNumber, shiftBy };
}
function calcOffsets(n, window, wOpts) {
    const { windowSize, mask, maxNumber, shiftBy } = wOpts;
    let wbits = Number(n & mask); // extract W bits.
    let nextN = n >> shiftBy; // shift number by W bits.
    // What actually happens here:
    // const highestBit = Number(mask ^ (mask >> 1n));
    // let wbits2 = wbits - 1; // skip zero
    // if (wbits2 & highestBit) { wbits2 ^= Number(mask); // (~);
    // split if bits > max: +224 => 256-32
    if (wbits > windowSize) {
        // we skip zero, which means instead of `>= size-1`, we do `> size`
        wbits -= maxNumber; // -32, can be maxNumber - wbits, but then we need to set isNeg here.
        nextN += _1n$4; // +256 (carry)
    }
    const offsetStart = window * windowSize;
    const offset = offsetStart + Math.abs(wbits) - 1; // -1 because we skip zero
    const isZero = wbits === 0; // is current window slice a 0?
    const isNeg = wbits < 0; // is current window slice negative?
    const isNegF = window % 2 !== 0; // fake random statement for noise
    const offsetF = offsetStart; // fake offset for noise
    return { nextN, offset, isZero, isNeg, isNegF, offsetF };
}
function validateMSMPoints(points, c) {
    if (!Array.isArray(points))
        throw new Error('array expected');
    points.forEach((p, i) => {
        if (!(p instanceof c))
            throw new Error('invalid point at index ' + i);
    });
}
function validateMSMScalars(scalars, field) {
    if (!Array.isArray(scalars))
        throw new Error('array of scalars expected');
    scalars.forEach((s, i) => {
        if (!field.isValid(s))
            throw new Error('invalid scalar at index ' + i);
    });
}
// Since points in different groups cannot be equal (different object constructor),
// we can have single place to store precomputes.
// Allows to make points frozen / immutable.
const pointPrecomputes = new WeakMap();
const pointWindowSizes = new WeakMap();
function getW(P) {
    return pointWindowSizes.get(P) || 1;
}
function assert0(n) {
    if (n !== _0n$2)
        throw new Error('invalid wNAF');
}
/**
 * Elliptic curve multiplication of Point by scalar. Fragile.
 * Scalars should always be less than curve order: this should be checked inside of a curve itself.
 * Creates precomputation tables for fast multiplication:
 * - private scalar is split by fixed size windows of W bits
 * - every window point is collected from window's table & added to accumulator
 * - since windows are different, same point inside tables won't be accessed more than once per calc
 * - each multiplication is 'Math.ceil(CURVE_ORDER / ) + 1' point additions (fixed for any scalar)
 * - +1 window is neccessary for wNAF
 * - wNAF reduces table size: 2x less memory + 2x faster generation, but 10% slower multiplication
 *
 * @todo Research returning 2d JS array of windows, instead of a single window.
 * This would allow windows to be in different memory locations
 */
function wNAF(c, bits) {
    return {
        constTimeNegate: negateCt,
        hasPrecomputes(elm) {
            return getW(elm) !== 1;
        },
        // non-const time multiplication ladder
        unsafeLadder(elm, n, p = c.ZERO) {
            let d = elm;
            while (n > _0n$2) {
                if (n & _1n$4)
                    p = p.add(d);
                d = d.double();
                n >>= _1n$4;
            }
            return p;
        },
        /**
         * Creates a wNAF precomputation window. Used for caching.
         * Default window size is set by `utils.precompute()` and is equal to 8.
         * Number of precomputed points depends on the curve size:
         * 2^(1) * (Math.ceil( / ) + 1), where:
         * -  is the window size
         * -  is the bitlength of the curve order.
         * For a 256-bit curve and window size 8, the number of precomputed points is 128 * 33 = 4224.
         * @param elm Point instance
         * @param W window size
         * @returns precomputed point tables flattened to a single array
         */
        precomputeWindow(elm, W) {
            const { windows, windowSize } = calcWOpts(W, bits);
            const points = [];
            let p = elm;
            let base = p;
            for (let window = 0; window < windows; window++) {
                base = p;
                points.push(base);
                // i=1, bc we skip 0
                for (let i = 1; i < windowSize; i++) {
                    base = base.add(p);
                    points.push(base);
                }
                p = base.double();
            }
            return points;
        },
        /**
         * Implements ec multiplication using precomputed tables and w-ary non-adjacent form.
         * @param W window size
         * @param precomputes precomputed tables
         * @param n scalar (we don't check here, but should be less than curve order)
         * @returns real and fake (for const-time) points
         */
        wNAF(W, precomputes, n) {
            // Smaller version:
            // https://github.com/paulmillr/noble-secp256k1/blob/47cb1669b6e506ad66b35fe7d76132ae97465da2/index.ts#L502-L541
            // TODO: check the scalar is less than group order?
            // wNAF behavior is undefined otherwise. But have to carefully remove
            // other checks before wNAF. ORDER == bits here.
            // Accumulators
            let p = c.ZERO;
            let f = c.BASE;
            // This code was first written with assumption that 'f' and 'p' will never be infinity point:
            // since each addition is multiplied by 2 ** W, it cannot cancel each other. However,
            // there is negate now: it is possible that negated element from low value
            // would be the same as high element, which will create carry into next window.
            // It's not obvious how this can fail, but still worth investigating later.
            const wo = calcWOpts(W, bits);
            for (let window = 0; window < wo.windows; window++) {
                // (n === _0n) is handled and not early-exited. isEven and offsetF are used for noise
                const { nextN, offset, isZero, isNeg, isNegF, offsetF } = calcOffsets(n, window, wo);
                n = nextN;
                if (isZero) {
                    // bits are 0: add garbage to fake point
                    // Important part for const-time getPublicKey: add random "noise" point to f.
                    f = f.add(negateCt(isNegF, precomputes[offsetF]));
                }
                else {
                    // bits are 1: add to result point
                    p = p.add(negateCt(isNeg, precomputes[offset]));
                }
            }
            assert0(n);
            // Return both real and fake points: JIT won't eliminate f.
            // At this point there is a way to F be infinity-point even if p is not,
            // which makes it less const-time: around 1 bigint multiply.
            return { p, f };
        },
        /**
         * Implements ec unsafe (non const-time) multiplication using precomputed tables and w-ary non-adjacent form.
         * @param W window size
         * @param precomputes precomputed tables
         * @param n scalar (we don't check here, but should be less than curve order)
         * @param acc accumulator point to add result of multiplication
         * @returns point
         */
        wNAFUnsafe(W, precomputes, n, acc = c.ZERO) {
            const wo = calcWOpts(W, bits);
            for (let window = 0; window < wo.windows; window++) {
                if (n === _0n$2)
                    break; // Early-exit, skip 0 value
                const { nextN, offset, isZero, isNeg } = calcOffsets(n, window, wo);
                n = nextN;
                if (isZero) {
                    // Window bits are 0: skip processing.
                    // Move to next window.
                    continue;
                }
                else {
                    const item = precomputes[offset];
                    acc = acc.add(isNeg ? item.negate() : item); // Re-using acc allows to save adds in MSM
                }
            }
            assert0(n);
            return acc;
        },
        getPrecomputes(W, P, transform) {
            // Calculate precomputes on a first run, reuse them after
            let comp = pointPrecomputes.get(P);
            if (!comp) {
                comp = this.precomputeWindow(P, W);
                if (W !== 1) {
                    // Doing transform outside of if brings 15% perf hit
                    if (typeof transform === 'function')
                        comp = transform(comp);
                    pointPrecomputes.set(P, comp);
                }
            }
            return comp;
        },
        wNAFCached(P, n, transform) {
            const W = getW(P);
            return this.wNAF(W, this.getPrecomputes(W, P, transform), n);
        },
        wNAFCachedUnsafe(P, n, transform, prev) {
            const W = getW(P);
            if (W === 1)
                return this.unsafeLadder(P, n, prev); // For W=1 ladder is ~x2 faster
            return this.wNAFUnsafe(W, this.getPrecomputes(W, P, transform), n, prev);
        },
        // We calculate precomputes for elliptic curve point multiplication
        // using windowed method. This specifies window size and
        // stores precomputed values. Usually only base point would be precomputed.
        setWindowSize(P, W) {
            validateW(W, bits);
            pointWindowSizes.set(P, W);
            pointPrecomputes.delete(P);
        },
    };
}
/**
 * Endomorphism-specific multiplication for Koblitz curves.
 * Cost: 128 dbl, 0-256 adds.
 */
function mulEndoUnsafe(c, point, k1, k2) {
    let acc = point;
    let p1 = c.ZERO;
    let p2 = c.ZERO;
    while (k1 > _0n$2 || k2 > _0n$2) {
        if (k1 & _1n$4)
            p1 = p1.add(acc);
        if (k2 & _1n$4)
            p2 = p2.add(acc);
        acc = acc.double();
        k1 >>= _1n$4;
        k2 >>= _1n$4;
    }
    return { p1, p2 };
}
/**
 * Pippenger algorithm for multi-scalar multiplication (MSM, Pa + Qb + Rc + ...).
 * 30x faster vs naive addition on L=4096, 10x faster than precomputes.
 * For N=254bit, L=1, it does: 1024 ADD + 254 DBL. For L=5: 1536 ADD + 254 DBL.
 * Algorithmically constant-time (for same L), even when 1 point + scalar, or when scalar = 0.
 * @param c Curve Point constructor
 * @param fieldN field over CURVE.N - important that it's not over CURVE.P
 * @param points array of L curve points
 * @param scalars array of L scalars (aka private keys / bigints)
 */
function pippenger(c, fieldN, points, scalars) {
    // If we split scalars by some window (let's say 8 bits), every chunk will only
    // take 256 buckets even if there are 4096 scalars, also re-uses double.
    // TODO:
    // - https://eprint.iacr.org/2024/750.pdf
    // - https://tches.iacr.org/index.php/TCHES/article/view/10287
    // 0 is accepted in scalars
    validateMSMPoints(points, c);
    validateMSMScalars(scalars, fieldN);
    const plength = points.length;
    const slength = scalars.length;
    if (plength !== slength)
        throw new Error('arrays of points and scalars must have equal length');
    // if (plength === 0) throw new Error('array must be of length >= 2');
    const zero = c.ZERO;
    const wbits = bitLen(BigInt(plength));
    let windowSize = 1; // bits
    if (wbits > 12)
        windowSize = wbits - 3;
    else if (wbits > 4)
        windowSize = wbits - 2;
    else if (wbits > 0)
        windowSize = 2;
    const MASK = bitMask(windowSize);
    const buckets = new Array(Number(MASK) + 1).fill(zero); // +1 for zero array
    const lastBits = Math.floor((fieldN.BITS - 1) / windowSize) * windowSize;
    let sum = zero;
    for (let i = lastBits; i >= 0; i -= windowSize) {
        buckets.fill(zero);
        for (let j = 0; j < slength; j++) {
            const scalar = scalars[j];
            const wbits = Number((scalar >> BigInt(i)) & MASK);
            buckets[wbits] = buckets[wbits].add(points[j]);
        }
        let resI = zero; // not using this will do small speed-up, but will lose ct
        // Skip first bucket, because it is zero
        for (let j = buckets.length - 1, sumI = zero; j > 0; j--) {
            sumI = sumI.add(buckets[j]);
            resI = resI.add(sumI);
        }
        sum = sum.add(resI);
        if (i !== 0)
            for (let j = 0; j < windowSize; j++)
                sum = sum.double();
    }
    return sum;
}
function createField(order, field) {
    if (field) {
        if (field.ORDER !== order)
            throw new Error('Field.ORDER must match order: Fp == p, Fn == n');
        validateField(field);
        return field;
    }
    else {
        return Field(order);
    }
}
/** Validates CURVE opts and creates fields */
function _createCurveFields(type, CURVE, curveOpts = {}) {
    if (!CURVE || typeof CURVE !== 'object')
        throw new Error(`expected valid ${type} CURVE object`);
    for (const p of ['p', 'n', 'h']) {
        const val = CURVE[p];
        if (!(typeof val === 'bigint' && val > _0n$2))
            throw new Error(`CURVE.${p} must be positive bigint`);
    }
    const Fp = createField(CURVE.p, curveOpts.Fp);
    const Fn = createField(CURVE.n, curveOpts.Fn);
    const _b = type === 'weierstrass' ? 'b' : 'd';
    const params = ['Gx', 'Gy', 'a', _b];
    for (const p of params) {
        // @ts-ignore
        if (!Fp.isValid(CURVE[p]))
            throw new Error(`CURVE.${p} must be valid field element of CURVE.Fp`);
    }
    return { Fp, Fn };
}

/**
 * Twisted Edwards curve. The formula is: ax + y = 1 + dxy.
 * For design rationale of types / exports, see weierstrass module documentation.
 * Untwisted Edwards curves exist, but they aren't used in real-world protocols.
 * @module
 */
/*! noble-curves - MIT License (c) 2022 Paul Miller (paulmillr.com) */
// Be friendly to bad ECMAScript parsers by not using bigint literals
// prettier-ignore
const _0n$1 = BigInt(0), _1n$3 = BigInt(1), _2n$3 = BigInt(2), _8n$1 = BigInt(8);
// verification rule is either zip215 or rfc8032 / nist186-5. Consult fromHex:
const VERIFY_DEFAULT = { zip215: true };
function isEdValidXY(Fp, CURVE, x, y) {
    const x2 = Fp.sqr(x);
    const y2 = Fp.sqr(y);
    const left = Fp.add(Fp.mul(CURVE.a, x2), y2);
    const right = Fp.add(Fp.ONE, Fp.mul(CURVE.d, Fp.mul(x2, y2)));
    return Fp.eql(left, right);
}
function edwards(CURVE, curveOpts = {}) {
    const { Fp, Fn } = _createCurveFields('edwards', CURVE, curveOpts);
    const { h: cofactor, n: CURVE_ORDER } = CURVE;
    _validateObject(curveOpts, {}, { uvRatio: 'function' });
    // Important:
    // There are some places where Fp.BYTES is used instead of nByteLength.
    // So far, everything has been tested with curves of Fp.BYTES == nByteLength.
    // TODO: test and find curves which behave otherwise.
    const MASK = _2n$3 << (BigInt(Fn.BYTES * 8) - _1n$3);
    const modP = (n) => Fp.create(n); // Function overrides
    // sqrt(u/v)
    const uvRatio = curveOpts.uvRatio ||
        ((u, v) => {
            try {
                return { isValid: true, value: Fp.sqrt(Fp.div(u, v)) };
            }
            catch (e) {
                return { isValid: false, value: _0n$1 };
            }
        });
    // Validate whether the passed curve params are valid.
    // equation ax + y = 1 + dxy should work for generator point.
    if (!isEdValidXY(Fp, CURVE, CURVE.Gx, CURVE.Gy))
        throw new Error('bad curve params: generator point');
    /**
     * Asserts coordinate is valid: 0 <= n < MASK.
     * Coordinates >= Fp.ORDER are allowed for zip215.
     */
    function acoord(title, n, banZero = false) {
        const min = banZero ? _1n$3 : _0n$1;
        aInRange('coordinate ' + title, n, min, MASK);
        return n;
    }
    function aextpoint(other) {
        if (!(other instanceof Point))
            throw new Error('ExtendedPoint expected');
    }
    // Converts Extended point to default (x, y) coordinates.
    // Can accept precomputed Z^-1 - for example, from invertBatch.
    const toAffineMemo = memoized((p, iz) => {
        const { ex: x, ey: y, ez: z } = p;
        const is0 = p.is0();
        if (iz == null)
            iz = is0 ? _8n$1 : Fp.inv(z); // 8 was chosen arbitrarily
        const ax = modP(x * iz);
        const ay = modP(y * iz);
        const zz = modP(z * iz);
        if (is0)
            return { x: _0n$1, y: _1n$3 };
        if (zz !== _1n$3)
            throw new Error('invZ was invalid');
        return { x: ax, y: ay };
    });
    const assertValidMemo = memoized((p) => {
        const { a, d } = CURVE;
        if (p.is0())
            throw new Error('bad point: ZERO'); // TODO: optimize, with vars below?
        // Equation in affine coordinates: ax + y = 1 + dxy
        // Equation in projective coordinates (X/Z, Y/Z, Z):  (aX + Y)Z = Z + dXY
        const { ex: X, ey: Y, ez: Z, et: T } = p;
        const X2 = modP(X * X); // X
        const Y2 = modP(Y * Y); // Y
        const Z2 = modP(Z * Z); // Z
        const Z4 = modP(Z2 * Z2); // Z
        const aX2 = modP(X2 * a); // aX
        const left = modP(Z2 * modP(aX2 + Y2)); // (aX + Y)Z
        const right = modP(Z4 + modP(d * modP(X2 * Y2))); // Z + dXY
        if (left !== right)
            throw new Error('bad point: equation left != right (1)');
        // In Extended coordinates we also have T, which is x*y=T/Z: check X*Y == Z*T
        const XY = modP(X * Y);
        const ZT = modP(Z * T);
        if (XY !== ZT)
            throw new Error('bad point: equation left != right (2)');
        return true;
    });
    // Extended Point works in extended coordinates: (X, Y, Z, T)  (x=X/Z, y=Y/Z, T=xy).
    // https://en.wikipedia.org/wiki/Twisted_Edwards_curve#Extended_coordinates
    class Point {
        constructor(ex, ey, ez, et) {
            this.ex = acoord('x', ex);
            this.ey = acoord('y', ey);
            this.ez = acoord('z', ez, true);
            this.et = acoord('t', et);
            Object.freeze(this);
        }
        get x() {
            return this.toAffine().x;
        }
        get y() {
            return this.toAffine().y;
        }
        static fromAffine(p) {
            if (p instanceof Point)
                throw new Error('extended point not allowed');
            const { x, y } = p || {};
            acoord('x', x);
            acoord('y', y);
            return new Point(x, y, _1n$3, modP(x * y));
        }
        static normalizeZ(points) {
            return normalizeZ(Point, 'ez', points);
        }
        // Multiscalar Multiplication
        static msm(points, scalars) {
            return pippenger(Point, Fn, points, scalars);
        }
        // "Private method", don't use it directly
        _setWindowSize(windowSize) {
            this.precompute(windowSize);
        }
        precompute(windowSize = 8, isLazy = true) {
            wnaf.setWindowSize(this, windowSize);
            if (!isLazy)
                this.multiply(_2n$3); // random number
            return this;
        }
        // Not required for fromHex(), which always creates valid points.
        // Could be useful for fromAffine().
        assertValidity() {
            assertValidMemo(this);
        }
        // Compare one point to another.
        equals(other) {
            aextpoint(other);
            const { ex: X1, ey: Y1, ez: Z1 } = this;
            const { ex: X2, ey: Y2, ez: Z2 } = other;
            const X1Z2 = modP(X1 * Z2);
            const X2Z1 = modP(X2 * Z1);
            const Y1Z2 = modP(Y1 * Z2);
            const Y2Z1 = modP(Y2 * Z1);
            return X1Z2 === X2Z1 && Y1Z2 === Y2Z1;
        }
        is0() {
            return this.equals(Point.ZERO);
        }
        negate() {
            // Flips point sign to a negative one (-x, y in affine coords)
            return new Point(modP(-this.ex), this.ey, this.ez, modP(-this.et));
        }
        // Fast algo for doubling Extended Point.
        // https://hyperelliptic.org/EFD/g1p/auto-twisted-extended.html#doubling-dbl-2008-hwcd
        // Cost: 4M + 4S + 1*a + 6add + 1*2.
        double() {
            const { a } = CURVE;
            const { ex: X1, ey: Y1, ez: Z1 } = this;
            const A = modP(X1 * X1); // A = X12
            const B = modP(Y1 * Y1); // B = Y12
            const C = modP(_2n$3 * modP(Z1 * Z1)); // C = 2*Z12
            const D = modP(a * A); // D = a*A
            const x1y1 = X1 + Y1;
            const E = modP(modP(x1y1 * x1y1) - A - B); // E = (X1+Y1)2-A-B
            const G = D + B; // G = D+B
            const F = G - C; // F = G-C
            const H = D - B; // H = D-B
            const X3 = modP(E * F); // X3 = E*F
            const Y3 = modP(G * H); // Y3 = G*H
            const T3 = modP(E * H); // T3 = E*H
            const Z3 = modP(F * G); // Z3 = F*G
            return new Point(X3, Y3, Z3, T3);
        }
        // Fast algo for adding 2 Extended Points.
        // https://hyperelliptic.org/EFD/g1p/auto-twisted-extended.html#addition-add-2008-hwcd
        // Cost: 9M + 1*a + 1*d + 7add.
        add(other) {
            aextpoint(other);
            const { a, d } = CURVE;
            const { ex: X1, ey: Y1, ez: Z1, et: T1 } = this;
            const { ex: X2, ey: Y2, ez: Z2, et: T2 } = other;
            const A = modP(X1 * X2); // A = X1*X2
            const B = modP(Y1 * Y2); // B = Y1*Y2
            const C = modP(T1 * d * T2); // C = T1*d*T2
            const D = modP(Z1 * Z2); // D = Z1*Z2
            const E = modP((X1 + Y1) * (X2 + Y2) - A - B); // E = (X1+Y1)*(X2+Y2)-A-B
            const F = D - C; // F = D-C
            const G = D + C; // G = D+C
            const H = modP(B - a * A); // H = B-a*A
            const X3 = modP(E * F); // X3 = E*F
            const Y3 = modP(G * H); // Y3 = G*H
            const T3 = modP(E * H); // T3 = E*H
            const Z3 = modP(F * G); // Z3 = F*G
            return new Point(X3, Y3, Z3, T3);
        }
        subtract(other) {
            return this.add(other.negate());
        }
        // Constant-time multiplication.
        multiply(scalar) {
            const n = scalar;
            aInRange('scalar', n, _1n$3, CURVE_ORDER); // 1 <= scalar < L
            const { p, f } = wnaf.wNAFCached(this, n, Point.normalizeZ);
            return Point.normalizeZ([p, f])[0];
        }
        // Non-constant-time multiplication. Uses double-and-add algorithm.
        // It's faster, but should only be used when you don't care about
        // an exposed private key e.g. sig verification.
        // Does NOT allow scalars higher than CURVE.n.
        // Accepts optional accumulator to merge with multiply (important for sparse scalars)
        multiplyUnsafe(scalar, acc = Point.ZERO) {
            const n = scalar;
            aInRange('scalar', n, _0n$1, CURVE_ORDER); // 0 <= scalar < L
            if (n === _0n$1)
                return Point.ZERO;
            if (this.is0() || n === _1n$3)
                return this;
            return wnaf.wNAFCachedUnsafe(this, n, Point.normalizeZ, acc);
        }
        // Checks if point is of small order.
        // If you add something to small order point, you will have "dirty"
        // point with torsion component.
        // Multiplies point by cofactor and checks if the result is 0.
        isSmallOrder() {
            return this.multiplyUnsafe(cofactor).is0();
        }
        // Multiplies point by curve order and checks if the result is 0.
        // Returns `false` is the point is dirty.
        isTorsionFree() {
            return wnaf.wNAFCachedUnsafe(this, CURVE_ORDER).is0();
        }
        // Converts Extended point to default (x, y) coordinates.
        // Can accept precomputed Z^-1 - for example, from invertBatch.
        toAffine(invertedZ) {
            return toAffineMemo(this, invertedZ);
        }
        clearCofactor() {
            if (cofactor === _1n$3)
                return this;
            return this.multiplyUnsafe(cofactor);
        }
        static fromBytes(bytes, zip215 = false) {
            abytes(bytes);
            return this.fromHex(bytes, zip215);
        }
        // Converts hash string or Uint8Array to Point.
        // Uses algo from RFC8032 5.1.3.
        static fromHex(hex, zip215 = false) {
            const { d, a } = CURVE;
            const len = Fp.BYTES;
            hex = ensureBytes('pointHex', hex, len); // copy hex to a new array
            abool('zip215', zip215);
            const normed = hex.slice(); // copy again, we'll manipulate it
            const lastByte = hex[len - 1]; // select last byte
            normed[len - 1] = lastByte & -129; // clear last bit
            const y = bytesToNumberLE(normed);
            // zip215=true is good for consensus-critical apps. =false follows RFC8032 / NIST186-5.
            // RFC8032 prohibits >= p, but ZIP215 doesn't
            // zip215=true:  0 <= y < MASK (2^256 for ed25519)
            // zip215=false: 0 <= y < P (2^255-19 for ed25519)
            const max = zip215 ? MASK : Fp.ORDER;
            aInRange('pointHex.y', y, _0n$1, max);
            // Ed25519: x = (y-1)/(dy+1) mod p. Ed448: x = (y-1)/(dy-1) mod p. Generic case:
            // ax+y=1+dxy => y-1=dxy-ax => y-1=x(dy-a) => x=(y-1)/(dy-a)
            const y2 = modP(y * y); // denominator is always non-0 mod p.
            const u = modP(y2 - _1n$3); // u = y - 1
            const v = modP(d * y2 - a); // v = d y + 1.
            let { isValid, value: x } = uvRatio(u, v); // (u/v)
            if (!isValid)
                throw new Error('Point.fromHex: invalid y coordinate');
            const isXOdd = (x & _1n$3) === _1n$3; // There are 2 square roots. Use x_0 bit to select proper
            const isLastByteOdd = (lastByte & 0x80) !== 0; // x_0, last bit
            if (!zip215 && x === _0n$1 && isLastByteOdd)
                // if x=0 and x_0 = 1, fail
                throw new Error('Point.fromHex: x=0 and x_0=1');
            if (isLastByteOdd !== isXOdd)
                x = modP(-x); // if x_0 != x mod 2, set x = p-x
            return Point.fromAffine({ x, y });
        }
        static fromPrivateScalar(scalar) {
            return Point.BASE.multiply(scalar);
        }
        toBytes() {
            const { x, y } = this.toAffine();
            const bytes = numberToBytesLE(y, Fp.BYTES); // each y has 2 x values (x, -y)
            bytes[bytes.length - 1] |= x & _1n$3 ? 0x80 : 0; // when compressing, it's enough to store y
            return bytes; // and use the last byte to encode sign of x
        }
        /** @deprecated use `toBytes` */
        toRawBytes() {
            return this.toBytes();
        }
        toHex() {
            return bytesToHex(this.toBytes());
        }
        toString() {
            return `<Point ${this.is0() ? 'ZERO' : this.toHex()}>`;
        }
    }
    // base / generator point
    Point.BASE = new Point(CURVE.Gx, CURVE.Gy, _1n$3, modP(CURVE.Gx * CURVE.Gy));
    // zero / infinity / identity point
    Point.ZERO = new Point(_0n$1, _1n$3, _1n$3, _0n$1); // 0, 1, 1, 0
    // fields
    Point.Fp = Fp;
    Point.Fn = Fn;
    const wnaf = wNAF(Point, Fn.BYTES * 8); // Fn.BITS?
    return Point;
}
/**
 * Initializes EdDSA signatures over given Edwards curve.
 */
function eddsa(Point, eddsaOpts) {
    _validateObject(eddsaOpts, {
        hash: 'function',
    }, {
        adjustScalarBytes: 'function',
        randomBytes: 'function',
        domain: 'function',
        prehash: 'function',
        mapToCurve: 'function',
    });
    const { prehash, hash: cHash } = eddsaOpts;
    const { BASE: G, Fp, Fn } = Point;
    const CURVE_ORDER = Fn.ORDER;
    const randomBytes_ = eddsaOpts.randomBytes || randomBytes;
    const adjustScalarBytes = eddsaOpts.adjustScalarBytes || ((bytes) => bytes); // NOOP
    const domain = eddsaOpts.domain ||
        ((data, ctx, phflag) => {
            abool('phflag', phflag);
            if (ctx.length || phflag)
                throw new Error('Contexts/pre-hash are not supported');
            return data;
        }); // NOOP
    function modN(a) {
        return Fn.create(a);
    }
    // Little-endian SHA512 with modulo n
    function modN_LE(hash) {
        // Not using Fn.fromBytes: hash can be 2*Fn.BYTES
        return modN(bytesToNumberLE(hash));
    }
    // Get the hashed private scalar per RFC8032 5.1.5
    function getPrivateScalar(key) {
        const len = Fp.BYTES;
        key = ensureBytes('private key', key, len);
        // Hash private key with curve's hash function to produce uniformingly random input
        // Check byte lengths: ensure(64, h(ensure(32, key)))
        const hashed = ensureBytes('hashed private key', cHash(key), 2 * len);
        const head = adjustScalarBytes(hashed.slice(0, len)); // clear first half bits, produce FE
        const prefix = hashed.slice(len, 2 * len); // second half is called key prefix (5.1.6)
        const scalar = modN_LE(head); // The actual private scalar
        return { head, prefix, scalar };
    }
    // Convenience method that creates public key from scalar. RFC8032 5.1.5
    function getExtendedPublicKey(key) {
        const { head, prefix, scalar } = getPrivateScalar(key);
        const point = G.multiply(scalar); // Point on Edwards curve aka public key
        const pointBytes = point.toBytes();
        return { head, prefix, scalar, point, pointBytes };
    }
    // Calculates EdDSA pub key. RFC8032 5.1.5. Privkey is hashed. Use first half with 3 bits cleared
    function getPublicKey(privKey) {
        return getExtendedPublicKey(privKey).pointBytes;
    }
    // int('LE', SHA512(dom2(F, C) || msgs)) mod N
    function hashDomainToScalar(context = Uint8Array.of(), ...msgs) {
        const msg = concatBytes(...msgs);
        return modN_LE(cHash(domain(msg, ensureBytes('context', context), !!prehash)));
    }
    /** Signs message with privateKey. RFC8032 5.1.6 */
    function sign(msg, privKey, options = {}) {
        msg = ensureBytes('message', msg);
        if (prehash)
            msg = prehash(msg); // for ed25519ph etc.
        const { prefix, scalar, pointBytes } = getExtendedPublicKey(privKey);
        const r = hashDomainToScalar(options.context, prefix, msg); // r = dom2(F, C) || prefix || PH(M)
        const R = G.multiply(r).toBytes(); // R = rG
        const k = hashDomainToScalar(options.context, R, pointBytes, msg); // R || A || PH(M)
        const s = modN(r + k * scalar); // S = (r + k * s) mod L
        aInRange('signature.s', s, _0n$1, CURVE_ORDER); // 0 <= s < l
        const L = Fp.BYTES;
        const res = concatBytes(R, numberToBytesLE(s, L));
        return ensureBytes('result', res, L * 2); // 64-byte signature
    }
    const verifyOpts = VERIFY_DEFAULT;
    /**
     * Verifies EdDSA signature against message and public key. RFC8032 5.1.7.
     * An extended group equation is checked.
     */
    function verify(sig, msg, publicKey, options = verifyOpts) {
        const { context, zip215 } = options;
        const len = Fp.BYTES; // Verifies EdDSA signature against message and public key. RFC8032 5.1.7.
        sig = ensureBytes('signature', sig, 2 * len); // An extended group equation is checked.
        msg = ensureBytes('message', msg);
        publicKey = ensureBytes('publicKey', publicKey, len);
        if (zip215 !== undefined)
            abool('zip215', zip215);
        if (prehash)
            msg = prehash(msg); // for ed25519ph, etc
        const s = bytesToNumberLE(sig.slice(len, 2 * len));
        let A, R, SB;
        try {
            // zip215=true is good for consensus-critical apps. =false follows RFC8032 / NIST186-5.
            // zip215=true:  0 <= y < MASK (2^256 for ed25519)
            // zip215=false: 0 <= y < P (2^255-19 for ed25519)
            A = Point.fromHex(publicKey, zip215);
            R = Point.fromHex(sig.slice(0, len), zip215);
            SB = G.multiplyUnsafe(s); // 0 <= s < l is done inside
        }
        catch (error) {
            return false;
        }
        if (!zip215 && A.isSmallOrder())
            return false;
        const k = hashDomainToScalar(context, R.toBytes(), A.toBytes(), msg);
        const RkA = R.add(A.multiplyUnsafe(k));
        // Extended group equation
        // [8][S]B = [8]R + [8][k]A'
        return RkA.subtract(SB).clearCofactor().is0();
    }
    G.precompute(8); // Enable precomputes. Slows down first publicKey computation by 20ms.
    const utils = {
        getExtendedPublicKey,
        /** ed25519 priv keys are uniform 32b. No need to check for modulo bias, like in secp256k1. */
        randomPrivateKey: () => randomBytes_(Fp.BYTES),
        /**
         * We're doing scalar multiplication (used in getPublicKey etc) with precomputed BASE_POINT
         * values. This slows down first getPublicKey() by milliseconds (see Speed section),
         * but allows to speed-up subsequent getPublicKey() calls up to 20x.
         * @param windowSize 2, 4, 8, 16
         */
        precompute(windowSize = 8, point = Point.BASE) {
            return point.precompute(windowSize, false);
        },
    };
    return { getPublicKey, sign, verify, utils, Point };
}
function _eddsa_legacy_opts_to_new(c) {
    const CURVE = {
        a: c.a,
        d: c.d,
        p: c.Fp.ORDER,
        n: c.n,
        h: c.h,
        Gx: c.Gx,
        Gy: c.Gy,
    };
    const Fp = c.Fp;
    const Fn = Field(CURVE.n, c.nBitLength, true);
    const curveOpts = { Fp, Fn, uvRatio: c.uvRatio };
    const eddsaOpts = {
        hash: c.hash,
        randomBytes: c.randomBytes,
        adjustScalarBytes: c.adjustScalarBytes,
        domain: c.domain,
        prehash: c.prehash,
        mapToCurve: c.mapToCurve,
    };
    return { CURVE, curveOpts, eddsaOpts };
}
function _eddsa_new_output_to_legacy(c, eddsa) {
    const legacy = Object.assign({}, eddsa, { ExtendedPoint: eddsa.Point, CURVE: c });
    return legacy;
}
// TODO: remove. Use eddsa
function twistedEdwards(c) {
    const { CURVE, curveOpts, eddsaOpts } = _eddsa_legacy_opts_to_new(c);
    const Point = edwards(CURVE, curveOpts);
    const EDDSA = eddsa(Point, eddsaOpts);
    return _eddsa_new_output_to_legacy(c, EDDSA);
}

/**
 * ed25519 Twisted Edwards curve with following addons:
 * - X25519 ECDH
 * - Ristretto cofactor elimination
 * - Elligator hash-to-group / point indistinguishability
 * @module
 */
/*! noble-curves - MIT License (c) 2022 Paul Miller (paulmillr.com) */
// prettier-ignore
BigInt(0); const _1n$2 = BigInt(1), _2n$2 = BigInt(2); BigInt(3);
// prettier-ignore
const _5n = BigInt(5), _8n = BigInt(8);
// 2n**255n - 19n
// Removing Fp.create() will still work, and is 10% faster on sign
//     a: Fp.create(BigInt(-1)),
// d is -121665/121666 a.k.a. Fp.neg(121665 * Fp.inv(121666))
// Finite field 2n**255n - 19n
// Subgroup order 2n**252n + 27742317777372353535851937790883648493n;
const ed25519_CURVE = {
    p: BigInt('0x7fffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffed'),
    n: BigInt('0x1000000000000000000000000000000014def9dea2f79cd65812631a5cf5d3ed'),
    h: _8n,
    a: BigInt('0x7fffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffec'),
    d: BigInt('0x52036cee2b6ffe738cc740797779e89800700a4d4141d8ab75eb4dca135978a3'),
    Gx: BigInt('0x216936d3cd6e53fec0a4e231fdd6dc5c692cc7609525a7b2c9562d608f25d51a'),
    Gy: BigInt('0x6666666666666666666666666666666666666666666666666666666666666658'),
};
function ed25519_pow_2_252_3(x) {
    // prettier-ignore
    const _10n = BigInt(10), _20n = BigInt(20), _40n = BigInt(40), _80n = BigInt(80);
    const P = ed25519_CURVE.p;
    const x2 = (x * x) % P;
    const b2 = (x2 * x) % P; // x^3, 11
    const b4 = (pow2(b2, _2n$2, P) * b2) % P; // x^15, 1111
    const b5 = (pow2(b4, _1n$2, P) * x) % P; // x^31
    const b10 = (pow2(b5, _5n, P) * b5) % P;
    const b20 = (pow2(b10, _10n, P) * b10) % P;
    const b40 = (pow2(b20, _20n, P) * b20) % P;
    const b80 = (pow2(b40, _40n, P) * b40) % P;
    const b160 = (pow2(b80, _80n, P) * b80) % P;
    const b240 = (pow2(b160, _80n, P) * b80) % P;
    const b250 = (pow2(b240, _10n, P) * b10) % P;
    const pow_p_5_8 = (pow2(b250, _2n$2, P) * x) % P;
    // ^ To pow to (p+3)/8, multiply it by x.
    return { pow_p_5_8, b2 };
}
function adjustScalarBytes(bytes) {
    // Section 5: For X25519, in order to decode 32 random bytes as an integer scalar,
    // set the three least significant bits of the first byte
    bytes[0] &= 248; // 0b1111_1000
    // and the most significant bit of the last to zero,
    bytes[31] &= 127; // 0b0111_1111
    // set the second most significant bit of the last byte to 1
    bytes[31] |= 64; // 0b0100_0000
    return bytes;
}
// (-1) aka (a) aka 2^((p-1)/4)
// Fp.sqrt(Fp.neg(1))
const ED25519_SQRT_M1 = /* @__PURE__ */ BigInt('19681161376707505956807079304988542015446066515923890162744021073123829784752');
// sqrt(u/v)
function uvRatio(u, v) {
    const P = ed25519_CURVE.p;
    const v3 = mod(v * v * v, P); // v
    const v7 = mod(v3 * v3 * v, P); // v
    // (p+3)/8 and (p-5)/8
    const pow = ed25519_pow_2_252_3(u * v7).pow_p_5_8;
    let x = mod(u * v3 * pow, P); // (uv)(uv)^(p-5)/8
    const vx2 = mod(v * x * x, P); // vx
    const root1 = x; // First root candidate
    const root2 = mod(x * ED25519_SQRT_M1, P); // Second root candidate
    const useRoot1 = vx2 === u; // If vx = u (mod p), x is a square root
    const useRoot2 = vx2 === mod(-u, P); // If vx = -u, set x <-- x * 2^((p-1)/4)
    const noRoot = vx2 === mod(-u * ED25519_SQRT_M1, P); // There is no valid root, vx = -u(-1)
    if (useRoot1)
        x = root1;
    if (useRoot2 || noRoot)
        x = root2; // We return root2 anyway, for const-time
    if (isNegativeLE(x, P))
        x = mod(-x, P);
    return { isValid: useRoot1 || useRoot2, value: x };
}
const Fp = /* @__PURE__ */ (() => Field(ed25519_CURVE.p, undefined, true))();
const ed25519Defaults = /* @__PURE__ */ (() => ({
    ...ed25519_CURVE,
    Fp,
    hash: sha512,
    adjustScalarBytes,
    // dom2
    // Ratio of u to v. Allows us to combine inversion and square root. Uses algo from RFC8032 5.1.3.
    // Constant-time, u/v
    uvRatio,
}))();
/**
 * ed25519 curve with EdDSA signatures.
 * @example
 * import { ed25519 } from '@noble/curves/ed25519';
 * const priv = ed25519.utils.randomPrivateKey();
 * const pub = ed25519.getPublicKey(priv);
 * const msg = new TextEncoder().encode('hello');
 * const sig = ed25519.sign(msg, priv);
 * ed25519.verify(sig, msg, pub); // Default mode: follows ZIP215
 * ed25519.verify(sig, msg, pub, { zip215: false }); // RFC8032 / FIPS 186-5
 */
const ed25519 = /* @__PURE__ */ (() => twistedEdwards(ed25519Defaults))();

/**
 * Signing a message failed
 */
/**
 * Verifying a message signature failed
 */
class VerificationError extends Error {
    constructor(message = 'An error occurred while verifying a message') {
        super(message);
        this.name = 'VerificationError';
    }
}
/**
 * WebCrypto was not available in the current context
 */
class WebCryptoMissingError extends Error {
    constructor(message = 'Missing Web Crypto API') {
        super(message);
        this.name = 'WebCryptoMissingError';
    }
}

/* eslint-env browser */
// Check native crypto exists and is enabled (In insecure context `self.crypto`
// exists but `self.crypto.subtle` does not).
var webcrypto = {
    get(win = globalThis) {
        const nativeCrypto = win.crypto;
        if (nativeCrypto?.subtle == null) {
            throw new WebCryptoMissingError('Missing Web Crypto API. ' +
                'The most likely cause of this error is that this page is being accessed ' +
                'from an insecure context (i.e. not HTTPS). For more information and ' +
                'possible resolutions see ' +
                'https://github.com/libp2p/js-libp2p/blob/main/packages/crypto/README.md#web-crypto-api');
        }
        return nativeCrypto;
    }
};

const PUBLIC_KEY_BYTE_LENGTH = 32;
// memoize support result to skip additional awaits every time we use an ed key
let ed25519Supported;
const webCryptoEd25519SupportedPromise = (async () => {
    try {
        await webcrypto.get().subtle.generateKey({ name: 'Ed25519' }, true, ['sign', 'verify']);
        return true;
    }
    catch {
        return false;
    }
})();
async function hashAndVerifyWebCrypto(publicKey, sig, msg) {
    if (publicKey.buffer instanceof ArrayBuffer) {
        const key = await webcrypto.get().subtle.importKey('raw', publicKey.buffer, { name: 'Ed25519' }, false, ['verify']);
        const isValid = await webcrypto.get().subtle.verify({ name: 'Ed25519' }, key, sig, msg instanceof Uint8Array ? msg : msg.subarray());
        return isValid;
    }
    throw new TypeError('WebCrypto does not support SharedArrayBuffer for Ed25519 keys');
}
function hashAndVerifyNoble(publicKey, sig, msg) {
    return ed25519.verify(sig, msg instanceof Uint8Array ? msg : msg.subarray(), publicKey);
}
async function hashAndVerify$1(publicKey, sig, msg) {
    if (ed25519Supported == null) {
        ed25519Supported = await webCryptoEd25519SupportedPromise;
    }
    if (ed25519Supported) {
        return hashAndVerifyWebCrypto(publicKey, sig, msg);
    }
    return hashAndVerifyNoble(publicKey, sig, msg);
}

function isPromise(thing) {
    if (thing == null) {
        return false;
    }
    return typeof thing.then === 'function' &&
        typeof thing.catch === 'function' &&
        typeof thing.finally === 'function';
}

class Ed25519PublicKey {
    type = 'Ed25519';
    raw;
    constructor(key) {
        this.raw = ensureEd25519Key(key, PUBLIC_KEY_BYTE_LENGTH);
    }
    toMultihash() {
        return identity.digest(publicKeyToProtobuf(this));
    }
    toCID() {
        return CID.createV1(114, this.toMultihash());
    }
    toString() {
        return base58btc.encode(this.toMultihash().bytes).substring(1);
    }
    equals(key) {
        if (key == null || !(key.raw instanceof Uint8Array)) {
            return false;
        }
        return equals(this.raw, key.raw);
    }
    verify(data, sig, options) {
        options?.signal?.throwIfAborted();
        const result = hashAndVerify$1(this.raw, sig, data);
        if (isPromise(result)) {
            return result.then(res => {
                options?.signal?.throwIfAborted();
                return res;
            });
        }
        return result;
    }
}

function unmarshalEd25519PublicKey(bytes) {
    bytes = ensureEd25519Key(bytes, PUBLIC_KEY_BYTE_LENGTH);
    return new Ed25519PublicKey(bytes);
}
function ensureEd25519Key(key, length) {
    key = Uint8Array.from(key ?? []);
    if (key.length !== length) {
        throw new InvalidParametersError$1(`Key must be a Uint8Array of length ${length}, got ${key.length}`);
    }
    return key;
}

var KeyType;
(function (KeyType) {
    KeyType["RSA"] = "RSA";
    KeyType["Ed25519"] = "Ed25519";
    KeyType["secp256k1"] = "secp256k1";
    KeyType["ECDSA"] = "ECDSA";
})(KeyType || (KeyType = {}));
var __KeyTypeValues;
(function (__KeyTypeValues) {
    __KeyTypeValues[__KeyTypeValues["RSA"] = 0] = "RSA";
    __KeyTypeValues[__KeyTypeValues["Ed25519"] = 1] = "Ed25519";
    __KeyTypeValues[__KeyTypeValues["secp256k1"] = 2] = "secp256k1";
    __KeyTypeValues[__KeyTypeValues["ECDSA"] = 3] = "ECDSA";
})(__KeyTypeValues || (__KeyTypeValues = {}));
(function (KeyType) {
    KeyType.codec = () => {
        return enumeration(__KeyTypeValues);
    };
})(KeyType || (KeyType = {}));
var PublicKey;
(function (PublicKey) {
    let _codec;
    PublicKey.codec = () => {
        if (_codec == null) {
            _codec = message((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if (obj.Type != null) {
                    w.uint32(8);
                    KeyType.codec().encode(obj.Type, w);
                }
                if (obj.Data != null) {
                    w.uint32(18);
                    w.bytes(obj.Data);
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length, opts = {}) => {
                const obj = {};
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 1: {
                            obj.Type = KeyType.codec().decode(reader);
                            break;
                        }
                        case 2: {
                            obj.Data = reader.bytes();
                            break;
                        }
                        default: {
                            reader.skipType(tag & 7);
                            break;
                        }
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    PublicKey.encode = (obj) => {
        return encodeMessage(obj, PublicKey.codec());
    };
    PublicKey.decode = (buf, opts) => {
        return decodeMessage(buf, PublicKey.codec(), opts);
    };
})(PublicKey || (PublicKey = {}));
var PrivateKey;
(function (PrivateKey) {
    let _codec;
    PrivateKey.codec = () => {
        if (_codec == null) {
            _codec = message((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if (obj.Type != null) {
                    w.uint32(8);
                    KeyType.codec().encode(obj.Type, w);
                }
                if (obj.Data != null) {
                    w.uint32(18);
                    w.bytes(obj.Data);
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length, opts = {}) => {
                const obj = {};
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 1: {
                            obj.Type = KeyType.codec().decode(reader);
                            break;
                        }
                        case 2: {
                            obj.Data = reader.bytes();
                            break;
                        }
                        default: {
                            reader.skipType(tag & 7);
                            break;
                        }
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    PrivateKey.encode = (obj) => {
        return encodeMessage(obj, PrivateKey.codec());
    };
    PrivateKey.decode = (buf, opts) => {
        return decodeMessage(buf, PrivateKey.codec(), opts);
    };
})(PrivateKey || (PrivateKey = {}));

/**
 * HMAC: RFC2104 message authentication code.
 * @module
 */
class HMAC extends Hash {
    constructor(hash, _key) {
        super();
        this.finished = false;
        this.destroyed = false;
        ahash(hash);
        const key = toBytes(_key);
        this.iHash = hash.create();
        if (typeof this.iHash.update !== 'function')
            throw new Error('Expected instance of class which extends utils.Hash');
        this.blockLen = this.iHash.blockLen;
        this.outputLen = this.iHash.outputLen;
        const blockLen = this.blockLen;
        const pad = new Uint8Array(blockLen);
        // blockLen can be bigger than outputLen
        pad.set(key.length > blockLen ? hash.create().update(key).digest() : key);
        for (let i = 0; i < pad.length; i++)
            pad[i] ^= 0x36;
        this.iHash.update(pad);
        // By doing update (processing of first block) of outer hash here we can re-use it between multiple calls via clone
        this.oHash = hash.create();
        // Undo internal XOR && apply outer XOR
        for (let i = 0; i < pad.length; i++)
            pad[i] ^= 0x36 ^ 0x5c;
        this.oHash.update(pad);
        clean(pad);
    }
    update(buf) {
        aexists(this);
        this.iHash.update(buf);
        return this;
    }
    digestInto(out) {
        aexists(this);
        abytes(out, this.outputLen);
        this.finished = true;
        this.iHash.digestInto(out);
        this.oHash.update(out);
        this.oHash.digestInto(out);
        this.destroy();
    }
    digest() {
        const out = new Uint8Array(this.oHash.outputLen);
        this.digestInto(out);
        return out;
    }
    _cloneInto(to) {
        // Create new instance without calling constructor since key already in state and we don't know it.
        to || (to = Object.create(Object.getPrototypeOf(this), {}));
        const { oHash, iHash, finished, destroyed, blockLen, outputLen } = this;
        to = to;
        to.finished = finished;
        to.destroyed = destroyed;
        to.blockLen = blockLen;
        to.outputLen = outputLen;
        to.oHash = oHash._cloneInto(to.oHash);
        to.iHash = iHash._cloneInto(to.iHash);
        return to;
    }
    clone() {
        return this._cloneInto();
    }
    destroy() {
        this.destroyed = true;
        this.oHash.destroy();
        this.iHash.destroy();
    }
}
/**
 * HMAC: RFC2104 message authentication code.
 * @param hash - function that would be used e.g. sha256
 * @param key - message key
 * @param message - message data
 * @example
 * import { hmac } from '@noble/hashes/hmac';
 * import { sha256 } from '@noble/hashes/sha2';
 * const mac1 = hmac(sha256, 'key', 'message');
 */
const hmac = (hash, key, message) => new HMAC(hash, key).update(message).digest();
hmac.create = (hash, key) => new HMAC(hash, key);

/**
 * Short Weierstrass curve methods. The formula is: y = x + ax + b.
 *
 * ### Design rationale for types
 *
 * * Interaction between classes from different curves should fail:
 *   `k256.Point.BASE.add(p256.Point.BASE)`
 * * For this purpose we want to use `instanceof` operator, which is fast and works during runtime
 * * Different calls of `curve()` would return different classes -
 *   `curve(params) !== curve(params)`: if somebody decided to monkey-patch their curve,
 *   it won't affect others
 *
 * TypeScript can't infer types for classes created inside a function. Classes is one instance
 * of nominative types in TypeScript and interfaces only check for shape, so it's hard to create
 * unique type for every function call.
 *
 * We can use generic types via some param, like curve opts, but that would:
 *     1. Enable interaction between `curve(params)` and `curve(params)` (curves of same params)
 *     which is hard to debug.
 *     2. Params can be generic and we can't enforce them to be constant value:
 *     if somebody creates curve from non-constant params,
 *     it would be allowed to interact with other curves with non-constant params
 *
 * @todo https://www.typescriptlang.org/docs/handbook/release-notes/typescript-2-7.html#unique-symbol
 * @module
 */
/*! noble-curves - MIT License (c) 2022 Paul Miller (paulmillr.com) */
function validateSigVerOpts(opts) {
    if (opts.lowS !== undefined)
        abool('lowS', opts.lowS);
    if (opts.prehash !== undefined)
        abool('prehash', opts.prehash);
}
class DERErr extends Error {
    constructor(m = '') {
        super(m);
    }
}
/**
 * ASN.1 DER encoding utilities. ASN is very complex & fragile. Format:
 *
 *     [0x30 (SEQUENCE), bytelength, 0x02 (INTEGER), intLength, R, 0x02 (INTEGER), intLength, S]
 *
 * Docs: https://letsencrypt.org/docs/a-warm-welcome-to-asn1-and-der/, https://luca.ntop.org/Teaching/Appunti/asn1.html
 */
const DER = {
    // asn.1 DER encoding utils
    Err: DERErr,
    // Basic building block is TLV (Tag-Length-Value)
    _tlv: {
        encode: (tag, data) => {
            const { Err: E } = DER;
            if (tag < 0 || tag > 256)
                throw new E('tlv.encode: wrong tag');
            if (data.length & 1)
                throw new E('tlv.encode: unpadded data');
            const dataLen = data.length / 2;
            const len = numberToHexUnpadded(dataLen);
            if ((len.length / 2) & 128)
                throw new E('tlv.encode: long form length too big');
            // length of length with long form flag
            const lenLen = dataLen > 127 ? numberToHexUnpadded((len.length / 2) | 128) : '';
            const t = numberToHexUnpadded(tag);
            return t + lenLen + len + data;
        },
        // v - value, l - left bytes (unparsed)
        decode(tag, data) {
            const { Err: E } = DER;
            let pos = 0;
            if (tag < 0 || tag > 256)
                throw new E('tlv.encode: wrong tag');
            if (data.length < 2 || data[pos++] !== tag)
                throw new E('tlv.decode: wrong tlv');
            const first = data[pos++];
            const isLong = !!(first & 128); // First bit of first length byte is flag for short/long form
            let length = 0;
            if (!isLong)
                length = first;
            else {
                // Long form: [longFlag(1bit), lengthLength(7bit), length (BE)]
                const lenLen = first & 127;
                if (!lenLen)
                    throw new E('tlv.decode(long): indefinite length not supported');
                if (lenLen > 4)
                    throw new E('tlv.decode(long): byte length is too big'); // this will overflow u32 in js
                const lengthBytes = data.subarray(pos, pos + lenLen);
                if (lengthBytes.length !== lenLen)
                    throw new E('tlv.decode: length bytes not complete');
                if (lengthBytes[0] === 0)
                    throw new E('tlv.decode(long): zero leftmost byte');
                for (const b of lengthBytes)
                    length = (length << 8) | b;
                pos += lenLen;
                if (length < 128)
                    throw new E('tlv.decode(long): not minimal encoding');
            }
            const v = data.subarray(pos, pos + length);
            if (v.length !== length)
                throw new E('tlv.decode: wrong value length');
            return { v, l: data.subarray(pos + length) };
        },
    },
    // https://crypto.stackexchange.com/a/57734 Leftmost bit of first byte is 'negative' flag,
    // since we always use positive integers here. It must always be empty:
    // - add zero byte if exists
    // - if next byte doesn't have a flag, leading zero is not allowed (minimal encoding)
    _int: {
        encode(num) {
            const { Err: E } = DER;
            if (num < _0n)
                throw new E('integer: negative integers are not allowed');
            let hex = numberToHexUnpadded(num);
            // Pad with zero byte if negative flag is present
            if (Number.parseInt(hex[0], 16) & 0b1000)
                hex = '00' + hex;
            if (hex.length & 1)
                throw new E('unexpected DER parsing assertion: unpadded hex');
            return hex;
        },
        decode(data) {
            const { Err: E } = DER;
            if (data[0] & 128)
                throw new E('invalid signature integer: negative');
            if (data[0] === 0x00 && !(data[1] & 128))
                throw new E('invalid signature integer: unnecessary leading zero');
            return bytesToNumberBE(data);
        },
    },
    toSig(hex) {
        // parse DER signature
        const { Err: E, _int: int, _tlv: tlv } = DER;
        const data = ensureBytes('signature', hex);
        const { v: seqBytes, l: seqLeftBytes } = tlv.decode(0x30, data);
        if (seqLeftBytes.length)
            throw new E('invalid signature: left bytes after parsing');
        const { v: rBytes, l: rLeftBytes } = tlv.decode(0x02, seqBytes);
        const { v: sBytes, l: sLeftBytes } = tlv.decode(0x02, rLeftBytes);
        if (sLeftBytes.length)
            throw new E('invalid signature: left bytes after parsing');
        return { r: int.decode(rBytes), s: int.decode(sBytes) };
    },
    hexFromSig(sig) {
        const { _tlv: tlv, _int: int } = DER;
        const rs = tlv.encode(0x02, int.encode(sig.r));
        const ss = tlv.encode(0x02, int.encode(sig.s));
        const seq = rs + ss;
        return tlv.encode(0x30, seq);
    },
};
// Be friendly to bad ECMAScript parsers by not using bigint literals
// prettier-ignore
const _0n = BigInt(0), _1n$1 = BigInt(1), _2n$1 = BigInt(2), _3n = BigInt(3), _4n = BigInt(4);
// TODO: remove
function _legacyHelperEquat(Fp, a, b) {
    /**
     * y = x + ax + b: Short weierstrass curve formula. Takes x, returns y.
     * @returns y
     */
    function weierstrassEquation(x) {
        const x2 = Fp.sqr(x); // x * x
        const x3 = Fp.mul(x2, x); // x * x
        return Fp.add(Fp.add(x3, Fp.mul(x, a)), b); // x + a * x + b
    }
    return weierstrassEquation;
}
function _legacyHelperNormPriv(Fn, allowedPrivateKeyLengths, wrapPrivateKey) {
    const { BYTES: expected } = Fn;
    // Validates if priv key is valid and converts it to bigint.
    function normPrivateKeyToScalar(key) {
        let num;
        if (typeof key === 'bigint') {
            num = key;
        }
        else {
            let bytes = ensureBytes('private key', key);
            if (allowedPrivateKeyLengths) {
                if (!allowedPrivateKeyLengths.includes(bytes.length * 2))
                    throw new Error('invalid private key');
                const padded = new Uint8Array(expected);
                padded.set(bytes, padded.length - bytes.length);
                bytes = padded;
            }
            try {
                num = Fn.fromBytes(bytes);
            }
            catch (error) {
                throw new Error(`invalid private key: expected ui8a of size ${expected}, got ${typeof key}`);
            }
        }
        if (wrapPrivateKey)
            num = Fn.create(num); // disabled by default, enabled for BLS
        if (!Fn.isValidNot0(num))
            throw new Error('invalid private key: out of range [1..N-1]');
        return num;
    }
    return normPrivateKeyToScalar;
}
function weierstrassN(CURVE, curveOpts = {}) {
    const { Fp, Fn } = _createCurveFields('weierstrass', CURVE, curveOpts);
    const { h: cofactor, n: CURVE_ORDER } = CURVE;
    _validateObject(curveOpts, {}, {
        allowInfinityPoint: 'boolean',
        clearCofactor: 'function',
        isTorsionFree: 'function',
        fromBytes: 'function',
        toBytes: 'function',
        endo: 'object',
        wrapPrivateKey: 'boolean',
    });
    const { endo } = curveOpts;
    if (endo) {
        // validateObject(endo, { beta: 'bigint', splitScalar: 'function' });
        if (!Fp.is0(CURVE.a) ||
            typeof endo.beta !== 'bigint' ||
            typeof endo.splitScalar !== 'function') {
            throw new Error('invalid endo: expected "beta": bigint and "splitScalar": function');
        }
    }
    function assertCompressionIsSupported() {
        if (!Fp.isOdd)
            throw new Error('compression is not supported: Field does not have .isOdd()');
    }
    // Implements IEEE P1363 point encoding
    function pointToBytes(_c, point, isCompressed) {
        const { x, y } = point.toAffine();
        const bx = Fp.toBytes(x);
        abool('isCompressed', isCompressed);
        if (isCompressed) {
            assertCompressionIsSupported();
            const hasEvenY = !Fp.isOdd(y);
            return concatBytes(pprefix(hasEvenY), bx);
        }
        else {
            return concatBytes(Uint8Array.of(0x04), bx, Fp.toBytes(y));
        }
    }
    function pointFromBytes(bytes) {
        abytes(bytes);
        const L = Fp.BYTES;
        const LC = L + 1; // length compressed, e.g. 33 for 32-byte field
        const LU = 2 * L + 1; // length uncompressed, e.g. 65 for 32-byte field
        const length = bytes.length;
        const head = bytes[0];
        const tail = bytes.subarray(1);
        // No actual validation is done here: use .assertValidity()
        if (length === LC && (head === 0x02 || head === 0x03)) {
            const x = Fp.fromBytes(tail);
            if (!Fp.isValid(x))
                throw new Error('bad point: is not on curve, wrong x');
            const y2 = weierstrassEquation(x); // y = x + ax + b
            let y;
            try {
                y = Fp.sqrt(y2); // y = y ^ (p+1)/4
            }
            catch (sqrtError) {
                const err = sqrtError instanceof Error ? ': ' + sqrtError.message : '';
                throw new Error('bad point: is not on curve, sqrt error' + err);
            }
            assertCompressionIsSupported();
            const isYOdd = Fp.isOdd(y); // (y & _1n) === _1n;
            const isHeadOdd = (head & 1) === 1; // ECDSA-specific
            if (isHeadOdd !== isYOdd)
                y = Fp.neg(y);
            return { x, y };
        }
        else if (length === LU && head === 0x04) {
            // TODO: more checks
            const x = Fp.fromBytes(tail.subarray(L * 0, L * 1));
            const y = Fp.fromBytes(tail.subarray(L * 1, L * 2));
            if (!isValidXY(x, y))
                throw new Error('bad point: is not on curve');
            return { x, y };
        }
        else {
            throw new Error(`bad point: got length ${length}, expected compressed=${LC} or uncompressed=${LU}`);
        }
    }
    const toBytes = curveOpts.toBytes || pointToBytes;
    const fromBytes = curveOpts.fromBytes || pointFromBytes;
    const weierstrassEquation = _legacyHelperEquat(Fp, CURVE.a, CURVE.b);
    // TODO: move top-level
    /** Checks whether equation holds for given x, y: y == x + ax + b */
    function isValidXY(x, y) {
        const left = Fp.sqr(y); // y
        const right = weierstrassEquation(x); // x + ax + b
        return Fp.eql(left, right);
    }
    // Validate whether the passed curve params are valid.
    // Test 1: equation y = x + ax + b should work for generator point.
    if (!isValidXY(CURVE.Gx, CURVE.Gy))
        throw new Error('bad curve params: generator point');
    // Test 2: discriminant  part should be non-zero: 4a + 27b != 0.
    // Guarantees curve is genus-1, smooth (non-singular).
    const _4a3 = Fp.mul(Fp.pow(CURVE.a, _3n), _4n);
    const _27b2 = Fp.mul(Fp.sqr(CURVE.b), BigInt(27));
    if (Fp.is0(Fp.add(_4a3, _27b2)))
        throw new Error('bad curve params: a or b');
    /** Asserts coordinate is valid: 0 <= n < Fp.ORDER. */
    function acoord(title, n, banZero = false) {
        if (!Fp.isValid(n) || (banZero && Fp.is0(n)))
            throw new Error(`bad point coordinate ${title}`);
        return n;
    }
    function aprjpoint(other) {
        if (!(other instanceof Point))
            throw new Error('ProjectivePoint expected');
    }
    // Memoized toAffine / validity check. They are heavy. Points are immutable.
    // Converts Projective point to affine (x, y) coordinates.
    // Can accept precomputed Z^-1 - for example, from invertBatch.
    // (X, Y, Z)  (x=X/Z, y=Y/Z)
    const toAffineMemo = memoized((p, iz) => {
        const { px: x, py: y, pz: z } = p;
        // Fast-path for normalized points
        if (Fp.eql(z, Fp.ONE))
            return { x, y };
        const is0 = p.is0();
        // If invZ was 0, we return zero point. However we still want to execute
        // all operations, so we replace invZ with a random number, 1.
        if (iz == null)
            iz = is0 ? Fp.ONE : Fp.inv(z);
        const ax = Fp.mul(x, iz);
        const ay = Fp.mul(y, iz);
        const zz = Fp.mul(z, iz);
        if (is0)
            return { x: Fp.ZERO, y: Fp.ZERO };
        if (!Fp.eql(zz, Fp.ONE))
            throw new Error('invZ was invalid');
        return { x: ax, y: ay };
    });
    // NOTE: on exception this will crash 'cached' and no value will be set.
    // Otherwise true will be return
    const assertValidMemo = memoized((p) => {
        if (p.is0()) {
            // (0, 1, 0) aka ZERO is invalid in most contexts.
            // In BLS, ZERO can be serialized, so we allow it.
            // (0, 0, 0) is invalid representation of ZERO.
            if (curveOpts.allowInfinityPoint && !Fp.is0(p.py))
                return;
            throw new Error('bad point: ZERO');
        }
        // Some 3rd-party test vectors require different wording between here & `fromCompressedHex`
        const { x, y } = p.toAffine();
        if (!Fp.isValid(x) || !Fp.isValid(y))
            throw new Error('bad point: x or y not field elements');
        if (!isValidXY(x, y))
            throw new Error('bad point: equation left != right');
        if (!p.isTorsionFree())
            throw new Error('bad point: not in prime-order subgroup');
        return true;
    });
    function finishEndo(endoBeta, k1p, k2p, k1neg, k2neg) {
        k2p = new Point(Fp.mul(k2p.px, endoBeta), k2p.py, k2p.pz);
        k1p = negateCt(k1neg, k1p);
        k2p = negateCt(k2neg, k2p);
        return k1p.add(k2p);
    }
    /**
     * Projective Point works in 3d / projective (homogeneous) coordinates:(X, Y, Z)  (x=X/Z, y=Y/Z).
     * Default Point works in 2d / affine coordinates: (x, y).
     * We're doing calculations in projective, because its operations don't require costly inversion.
     */
    class Point {
        /** Does NOT validate if the point is valid. Use `.assertValidity()`. */
        constructor(px, py, pz) {
            this.px = acoord('x', px);
            this.py = acoord('y', py, true);
            this.pz = acoord('z', pz);
            Object.freeze(this);
        }
        /** Does NOT validate if the point is valid. Use `.assertValidity()`. */
        static fromAffine(p) {
            const { x, y } = p || {};
            if (!p || !Fp.isValid(x) || !Fp.isValid(y))
                throw new Error('invalid affine point');
            if (p instanceof Point)
                throw new Error('projective point not allowed');
            // (0, 0) would've produced (0, 0, 1) - instead, we need (0, 1, 0)
            if (Fp.is0(x) && Fp.is0(y))
                return Point.ZERO;
            return new Point(x, y, Fp.ONE);
        }
        get x() {
            return this.toAffine().x;
        }
        get y() {
            return this.toAffine().y;
        }
        static normalizeZ(points) {
            return normalizeZ(Point, 'pz', points);
        }
        static fromBytes(bytes) {
            abytes(bytes);
            return Point.fromHex(bytes);
        }
        /** Converts hash string or Uint8Array to Point. */
        static fromHex(hex) {
            const P = Point.fromAffine(fromBytes(ensureBytes('pointHex', hex)));
            P.assertValidity();
            return P;
        }
        /** Multiplies generator point by privateKey. */
        static fromPrivateKey(privateKey) {
            const normPrivateKeyToScalar = _legacyHelperNormPriv(Fn, curveOpts.allowedPrivateKeyLengths, curveOpts.wrapPrivateKey);
            return Point.BASE.multiply(normPrivateKeyToScalar(privateKey));
        }
        /** Multiscalar Multiplication */
        static msm(points, scalars) {
            return pippenger(Point, Fn, points, scalars);
        }
        /**
         *
         * @param windowSize
         * @param isLazy true will defer table computation until the first multiplication
         * @returns
         */
        precompute(windowSize = 8, isLazy = true) {
            wnaf.setWindowSize(this, windowSize);
            if (!isLazy)
                this.multiply(_3n); // random number
            return this;
        }
        /** "Private method", don't use it directly */
        _setWindowSize(windowSize) {
            this.precompute(windowSize);
        }
        // TODO: return `this`
        /** A point on curve is valid if it conforms to equation. */
        assertValidity() {
            assertValidMemo(this);
        }
        hasEvenY() {
            const { y } = this.toAffine();
            if (!Fp.isOdd)
                throw new Error("Field doesn't support isOdd");
            return !Fp.isOdd(y);
        }
        /** Compare one point to another. */
        equals(other) {
            aprjpoint(other);
            const { px: X1, py: Y1, pz: Z1 } = this;
            const { px: X2, py: Y2, pz: Z2 } = other;
            const U1 = Fp.eql(Fp.mul(X1, Z2), Fp.mul(X2, Z1));
            const U2 = Fp.eql(Fp.mul(Y1, Z2), Fp.mul(Y2, Z1));
            return U1 && U2;
        }
        /** Flips point to one corresponding to (x, -y) in Affine coordinates. */
        negate() {
            return new Point(this.px, Fp.neg(this.py), this.pz);
        }
        // Renes-Costello-Batina exception-free doubling formula.
        // There is 30% faster Jacobian formula, but it is not complete.
        // https://eprint.iacr.org/2015/1060, algorithm 3
        // Cost: 8M + 3S + 3*a + 2*b3 + 15add.
        double() {
            const { a, b } = CURVE;
            const b3 = Fp.mul(b, _3n);
            const { px: X1, py: Y1, pz: Z1 } = this;
            let X3 = Fp.ZERO, Y3 = Fp.ZERO, Z3 = Fp.ZERO; // prettier-ignore
            let t0 = Fp.mul(X1, X1); // step 1
            let t1 = Fp.mul(Y1, Y1);
            let t2 = Fp.mul(Z1, Z1);
            let t3 = Fp.mul(X1, Y1);
            t3 = Fp.add(t3, t3); // step 5
            Z3 = Fp.mul(X1, Z1);
            Z3 = Fp.add(Z3, Z3);
            X3 = Fp.mul(a, Z3);
            Y3 = Fp.mul(b3, t2);
            Y3 = Fp.add(X3, Y3); // step 10
            X3 = Fp.sub(t1, Y3);
            Y3 = Fp.add(t1, Y3);
            Y3 = Fp.mul(X3, Y3);
            X3 = Fp.mul(t3, X3);
            Z3 = Fp.mul(b3, Z3); // step 15
            t2 = Fp.mul(a, t2);
            t3 = Fp.sub(t0, t2);
            t3 = Fp.mul(a, t3);
            t3 = Fp.add(t3, Z3);
            Z3 = Fp.add(t0, t0); // step 20
            t0 = Fp.add(Z3, t0);
            t0 = Fp.add(t0, t2);
            t0 = Fp.mul(t0, t3);
            Y3 = Fp.add(Y3, t0);
            t2 = Fp.mul(Y1, Z1); // step 25
            t2 = Fp.add(t2, t2);
            t0 = Fp.mul(t2, t3);
            X3 = Fp.sub(X3, t0);
            Z3 = Fp.mul(t2, t1);
            Z3 = Fp.add(Z3, Z3); // step 30
            Z3 = Fp.add(Z3, Z3);
            return new Point(X3, Y3, Z3);
        }
        // Renes-Costello-Batina exception-free addition formula.
        // There is 30% faster Jacobian formula, but it is not complete.
        // https://eprint.iacr.org/2015/1060, algorithm 1
        // Cost: 12M + 0S + 3*a + 3*b3 + 23add.
        add(other) {
            aprjpoint(other);
            const { px: X1, py: Y1, pz: Z1 } = this;
            const { px: X2, py: Y2, pz: Z2 } = other;
            let X3 = Fp.ZERO, Y3 = Fp.ZERO, Z3 = Fp.ZERO; // prettier-ignore
            const a = CURVE.a;
            const b3 = Fp.mul(CURVE.b, _3n);
            let t0 = Fp.mul(X1, X2); // step 1
            let t1 = Fp.mul(Y1, Y2);
            let t2 = Fp.mul(Z1, Z2);
            let t3 = Fp.add(X1, Y1);
            let t4 = Fp.add(X2, Y2); // step 5
            t3 = Fp.mul(t3, t4);
            t4 = Fp.add(t0, t1);
            t3 = Fp.sub(t3, t4);
            t4 = Fp.add(X1, Z1);
            let t5 = Fp.add(X2, Z2); // step 10
            t4 = Fp.mul(t4, t5);
            t5 = Fp.add(t0, t2);
            t4 = Fp.sub(t4, t5);
            t5 = Fp.add(Y1, Z1);
            X3 = Fp.add(Y2, Z2); // step 15
            t5 = Fp.mul(t5, X3);
            X3 = Fp.add(t1, t2);
            t5 = Fp.sub(t5, X3);
            Z3 = Fp.mul(a, t4);
            X3 = Fp.mul(b3, t2); // step 20
            Z3 = Fp.add(X3, Z3);
            X3 = Fp.sub(t1, Z3);
            Z3 = Fp.add(t1, Z3);
            Y3 = Fp.mul(X3, Z3);
            t1 = Fp.add(t0, t0); // step 25
            t1 = Fp.add(t1, t0);
            t2 = Fp.mul(a, t2);
            t4 = Fp.mul(b3, t4);
            t1 = Fp.add(t1, t2);
            t2 = Fp.sub(t0, t2); // step 30
            t2 = Fp.mul(a, t2);
            t4 = Fp.add(t4, t2);
            t0 = Fp.mul(t1, t4);
            Y3 = Fp.add(Y3, t0);
            t0 = Fp.mul(t5, t4); // step 35
            X3 = Fp.mul(t3, X3);
            X3 = Fp.sub(X3, t0);
            t0 = Fp.mul(t3, t1);
            Z3 = Fp.mul(t5, Z3);
            Z3 = Fp.add(Z3, t0); // step 40
            return new Point(X3, Y3, Z3);
        }
        subtract(other) {
            return this.add(other.negate());
        }
        is0() {
            return this.equals(Point.ZERO);
        }
        /**
         * Constant time multiplication.
         * Uses wNAF method. Windowed method may be 10% faster,
         * but takes 2x longer to generate and consumes 2x memory.
         * Uses precomputes when available.
         * Uses endomorphism for Koblitz curves.
         * @param scalar by which the point would be multiplied
         * @returns New point
         */
        multiply(scalar) {
            const { endo } = curveOpts;
            if (!Fn.isValidNot0(scalar))
                throw new Error('invalid scalar: out of range'); // 0 is invalid
            let point, fake; // Fake point is used to const-time mult
            const mul = (n) => wnaf.wNAFCached(this, n, Point.normalizeZ);
            /** See docs for {@link EndomorphismOpts} */
            if (endo) {
                const { k1neg, k1, k2neg, k2 } = endo.splitScalar(scalar);
                const { p: k1p, f: k1f } = mul(k1);
                const { p: k2p, f: k2f } = mul(k2);
                fake = k1f.add(k2f);
                point = finishEndo(endo.beta, k1p, k2p, k1neg, k2neg);
            }
            else {
                const { p, f } = mul(scalar);
                point = p;
                fake = f;
            }
            // Normalize `z` for both points, but return only real one
            return Point.normalizeZ([point, fake])[0];
        }
        /**
         * Non-constant-time multiplication. Uses double-and-add algorithm.
         * It's faster, but should only be used when you don't care about
         * an exposed private key e.g. sig verification, which works over *public* keys.
         */
        multiplyUnsafe(sc) {
            const { endo } = curveOpts;
            const p = this;
            if (!Fn.isValid(sc))
                throw new Error('invalid scalar: out of range'); // 0 is valid
            if (sc === _0n || p.is0())
                return Point.ZERO;
            if (sc === _1n$1)
                return p; // fast-path
            if (wnaf.hasPrecomputes(this))
                return this.multiply(sc);
            if (endo) {
                const { k1neg, k1, k2neg, k2 } = endo.splitScalar(sc);
                // `wNAFCachedUnsafe` is 30% slower
                const { p1, p2 } = mulEndoUnsafe(Point, p, k1, k2);
                return finishEndo(endo.beta, p1, p2, k1neg, k2neg);
            }
            else {
                return wnaf.wNAFCachedUnsafe(p, sc);
            }
        }
        multiplyAndAddUnsafe(Q, a, b) {
            const sum = this.multiplyUnsafe(a).add(Q.multiplyUnsafe(b));
            return sum.is0() ? undefined : sum;
        }
        /**
         * Converts Projective point to affine (x, y) coordinates.
         * @param invertedZ Z^-1 (inverted zero) - optional, precomputation is useful for invertBatch
         */
        toAffine(invertedZ) {
            return toAffineMemo(this, invertedZ);
        }
        /**
         * Checks whether Point is free of torsion elements (is in prime subgroup).
         * Always torsion-free for cofactor=1 curves.
         */
        isTorsionFree() {
            const { isTorsionFree } = curveOpts;
            if (cofactor === _1n$1)
                return true;
            if (isTorsionFree)
                return isTorsionFree(Point, this);
            return wnaf.wNAFCachedUnsafe(this, CURVE_ORDER).is0();
        }
        clearCofactor() {
            const { clearCofactor } = curveOpts;
            if (cofactor === _1n$1)
                return this; // Fast-path
            if (clearCofactor)
                return clearCofactor(Point, this);
            return this.multiplyUnsafe(cofactor);
        }
        toBytes(isCompressed = true) {
            abool('isCompressed', isCompressed);
            this.assertValidity();
            return toBytes(Point, this, isCompressed);
        }
        /** @deprecated use `toBytes` */
        toRawBytes(isCompressed = true) {
            return this.toBytes(isCompressed);
        }
        toHex(isCompressed = true) {
            return bytesToHex(this.toBytes(isCompressed));
        }
        toString() {
            return `<Point ${this.is0() ? 'ZERO' : this.toHex()}>`;
        }
    }
    // base / generator point
    Point.BASE = new Point(CURVE.Gx, CURVE.Gy, Fp.ONE);
    // zero / infinity / identity point
    Point.ZERO = new Point(Fp.ZERO, Fp.ONE, Fp.ZERO); // 0, 1, 0
    // fields
    Point.Fp = Fp;
    Point.Fn = Fn;
    const bits = Fn.BITS;
    const wnaf = wNAF(Point, curveOpts.endo ? Math.ceil(bits / 2) : bits);
    return Point;
}
// Points start with byte 0x02 when y is even; otherwise 0x03
function pprefix(hasEvenY) {
    return Uint8Array.of(hasEvenY ? 0x02 : 0x03);
}
function ecdsa(Point, ecdsaOpts, curveOpts = {}) {
    _validateObject(ecdsaOpts, { hash: 'function' }, {
        hmac: 'function',
        lowS: 'boolean',
        randomBytes: 'function',
        bits2int: 'function',
        bits2int_modN: 'function',
    });
    const randomBytes_ = ecdsaOpts.randomBytes || randomBytes;
    const hmac_ = ecdsaOpts.hmac ||
        ((key, ...msgs) => hmac(ecdsaOpts.hash, key, concatBytes(...msgs)));
    const { Fp, Fn } = Point;
    const { ORDER: CURVE_ORDER, BITS: fnBits } = Fn;
    function isBiggerThanHalfOrder(number) {
        const HALF = CURVE_ORDER >> _1n$1;
        return number > HALF;
    }
    function normalizeS(s) {
        return isBiggerThanHalfOrder(s) ? Fn.neg(s) : s;
    }
    function aValidRS(title, num) {
        if (!Fn.isValidNot0(num))
            throw new Error(`invalid signature ${title}: out of range 1..CURVE.n`);
    }
    /**
     * ECDSA signature with its (r, s) properties. Supports DER & compact representations.
     */
    class Signature {
        constructor(r, s, recovery) {
            aValidRS('r', r); // r in [1..N-1]
            aValidRS('s', s); // s in [1..N-1]
            this.r = r;
            this.s = s;
            if (recovery != null)
                this.recovery = recovery;
            Object.freeze(this);
        }
        // pair (bytes of r, bytes of s)
        static fromCompact(hex) {
            const L = Fn.BYTES;
            const b = ensureBytes('compactSignature', hex, L * 2);
            return new Signature(Fn.fromBytes(b.subarray(0, L)), Fn.fromBytes(b.subarray(L, L * 2)));
        }
        // DER encoded ECDSA signature
        // https://bitcoin.stackexchange.com/questions/57644/what-are-the-parts-of-a-bitcoin-transaction-input-script
        static fromDER(hex) {
            const { r, s } = DER.toSig(ensureBytes('DER', hex));
            return new Signature(r, s);
        }
        /**
         * @todo remove
         * @deprecated
         */
        assertValidity() { }
        addRecoveryBit(recovery) {
            return new Signature(this.r, this.s, recovery);
        }
        // ProjPointType<bigint>
        recoverPublicKey(msgHash) {
            const FIELD_ORDER = Fp.ORDER;
            const { r, s, recovery: rec } = this;
            if (rec == null || ![0, 1, 2, 3].includes(rec))
                throw new Error('recovery id invalid');
            // ECDSA recovery is hard for cofactor > 1 curves.
            // In sign, `r = q.x mod n`, and here we recover q.x from r.
            // While recovering q.x >= n, we need to add r+n for cofactor=1 curves.
            // However, for cofactor>1, r+n may not get q.x:
            // r+n*i would need to be done instead where i is unknown.
            // To easily get i, we either need to:
            // a. increase amount of valid recid values (4, 5...); OR
            // b. prohibit non-prime-order signatures (recid > 1).
            const hasCofactor = CURVE_ORDER * _2n$1 < FIELD_ORDER;
            if (hasCofactor && rec > 1)
                throw new Error('recovery id is ambiguous for h>1 curve');
            const radj = rec === 2 || rec === 3 ? r + CURVE_ORDER : r;
            if (!Fp.isValid(radj))
                throw new Error('recovery id 2 or 3 invalid');
            const x = Fp.toBytes(radj);
            const R = Point.fromHex(concatBytes(pprefix((rec & 1) === 0), x));
            const ir = Fn.inv(radj); // r^-1
            const h = bits2int_modN(ensureBytes('msgHash', msgHash)); // Truncate hash
            const u1 = Fn.create(-h * ir); // -hr^-1
            const u2 = Fn.create(s * ir); // sr^-1
            // (sr^-1)R-(hr^-1)G = -(hr^-1)G + (sr^-1). unsafe is fine: there is no private data.
            const Q = Point.BASE.multiplyUnsafe(u1).add(R.multiplyUnsafe(u2));
            if (Q.is0())
                throw new Error('point at infinify');
            Q.assertValidity();
            return Q;
        }
        // Signatures should be low-s, to prevent malleability.
        hasHighS() {
            return isBiggerThanHalfOrder(this.s);
        }
        normalizeS() {
            return this.hasHighS() ? new Signature(this.r, Fn.neg(this.s), this.recovery) : this;
        }
        toBytes(format) {
            if (format === 'compact')
                return concatBytes(Fn.toBytes(this.r), Fn.toBytes(this.s));
            if (format === 'der')
                return hexToBytes(DER.hexFromSig(this));
            throw new Error('invalid format');
        }
        // DER-encoded
        toDERRawBytes() {
            return this.toBytes('der');
        }
        toDERHex() {
            return bytesToHex(this.toBytes('der'));
        }
        // padded bytes of r, then padded bytes of s
        toCompactRawBytes() {
            return this.toBytes('compact');
        }
        toCompactHex() {
            return bytesToHex(this.toBytes('compact'));
        }
    }
    const normPrivateKeyToScalar = _legacyHelperNormPriv(Fn, curveOpts.allowedPrivateKeyLengths, curveOpts.wrapPrivateKey);
    const utils = {
        isValidPrivateKey(privateKey) {
            try {
                normPrivateKeyToScalar(privateKey);
                return true;
            }
            catch (error) {
                return false;
            }
        },
        normPrivateKeyToScalar: normPrivateKeyToScalar,
        /**
         * Produces cryptographically secure private key from random of size
         * (groupLen + ceil(groupLen / 2)) with modulo bias being negligible.
         */
        randomPrivateKey: () => {
            const n = CURVE_ORDER;
            return mapHashToField(randomBytes_(getMinHashLength(n)), n);
        },
        precompute(windowSize = 8, point = Point.BASE) {
            return point.precompute(windowSize, false);
        },
    };
    /**
     * Computes public key for a private key. Checks for validity of the private key.
     * @param privateKey private key
     * @param isCompressed whether to return compact (default), or full key
     * @returns Public key, full when isCompressed=false; short when isCompressed=true
     */
    function getPublicKey(privateKey, isCompressed = true) {
        return Point.fromPrivateKey(privateKey).toBytes(isCompressed);
    }
    /**
     * Quick and dirty check for item being public key. Does not validate hex, or being on-curve.
     */
    function isProbPub(item) {
        if (typeof item === 'bigint')
            return false;
        if (item instanceof Point)
            return true;
        const arr = ensureBytes('key', item);
        const length = arr.length;
        const L = Fp.BYTES;
        const LC = L + 1; // e.g. 33 for 32
        const LU = 2 * L + 1; // e.g. 65 for 32
        if (curveOpts.allowedPrivateKeyLengths || Fn.BYTES === LC) {
            return undefined;
        }
        else {
            return length === LC || length === LU;
        }
    }
    /**
     * ECDH (Elliptic Curve Diffie Hellman).
     * Computes shared public key from private key and public key.
     * Checks: 1) private key validity 2) shared key is on-curve.
     * Does NOT hash the result.
     * @param privateA private key
     * @param publicB different public key
     * @param isCompressed whether to return compact (default), or full key
     * @returns shared public key
     */
    function getSharedSecret(privateA, publicB, isCompressed = true) {
        if (isProbPub(privateA) === true)
            throw new Error('first arg must be private key');
        if (isProbPub(publicB) === false)
            throw new Error('second arg must be public key');
        const b = Point.fromHex(publicB); // check for being on-curve
        return b.multiply(normPrivateKeyToScalar(privateA)).toBytes(isCompressed);
    }
    // RFC6979: ensure ECDSA msg is X bytes and < N. RFC suggests optional truncating via bits2octets.
    // FIPS 186-4 4.6 suggests the leftmost min(nBitLen, outLen) bits, which matches bits2int.
    // bits2int can produce res>N, we can do mod(res, N) since the bitLen is the same.
    // int2octets can't be used; pads small msgs with 0: unacceptatble for trunc as per RFC vectors
    const bits2int = ecdsaOpts.bits2int ||
        function (bytes) {
            // Our custom check "just in case", for protection against DoS
            if (bytes.length > 8192)
                throw new Error('input is too large');
            // For curves with nBitLength % 8 !== 0: bits2octets(bits2octets(m)) !== bits2octets(m)
            // for some cases, since bytes.length * 8 is not actual bitLength.
            const num = bytesToNumberBE(bytes); // check for == u8 done here
            const delta = bytes.length * 8 - fnBits; // truncate to nBitLength leftmost bits
            return delta > 0 ? num >> BigInt(delta) : num;
        };
    const bits2int_modN = ecdsaOpts.bits2int_modN ||
        function (bytes) {
            return Fn.create(bits2int(bytes)); // can't use bytesToNumberBE here
        };
    // NOTE: pads output with zero as per spec
    const ORDER_MASK = bitMask(fnBits);
    /**
     * Converts to bytes. Checks if num in `[0..ORDER_MASK-1]` e.g.: `[0..2^256-1]`.
     */
    function int2octets(num) {
        // IMPORTANT: the check ensures working for case `Fn.BYTES != Fn.BITS * 8`
        aInRange('num < 2^' + fnBits, num, _0n, ORDER_MASK);
        return Fn.toBytes(num);
    }
    // Steps A, D of RFC6979 3.2
    // Creates RFC6979 seed; converts msg/privKey to numbers.
    // Used only in sign, not in verify.
    // NOTE: we cannot assume here that msgHash has same amount of bytes as curve order,
    // this will be invalid at least for P521. Also it can be bigger for P224 + SHA256
    function prepSig(msgHash, privateKey, opts = defaultSigOpts) {
        if (['recovered', 'canonical'].some((k) => k in opts))
            throw new Error('sign() legacy options not supported');
        const { hash } = ecdsaOpts;
        let { lowS, prehash, extraEntropy: ent } = opts; // generates low-s sigs by default
        if (lowS == null)
            lowS = true; // RFC6979 3.2: we skip step A, because we already provide hash
        msgHash = ensureBytes('msgHash', msgHash);
        validateSigVerOpts(opts);
        if (prehash)
            msgHash = ensureBytes('prehashed msgHash', hash(msgHash));
        // We can't later call bits2octets, since nested bits2int is broken for curves
        // with fnBits % 8 !== 0. Because of that, we unwrap it here as int2octets call.
        // const bits2octets = (bits) => int2octets(bits2int_modN(bits))
        const h1int = bits2int_modN(msgHash);
        const d = normPrivateKeyToScalar(privateKey); // validate private key, convert to bigint
        const seedArgs = [int2octets(d), int2octets(h1int)];
        // extraEntropy. RFC6979 3.6: additional k' (optional).
        if (ent != null && ent !== false) {
            // K = HMAC_K(V || 0x00 || int2octets(x) || bits2octets(h1) || k')
            const e = ent === true ? randomBytes_(Fp.BYTES) : ent; // generate random bytes OR pass as-is
            seedArgs.push(ensureBytes('extraEntropy', e)); // check for being bytes
        }
        const seed = concatBytes(...seedArgs); // Step D of RFC6979 3.2
        const m = h1int; // NOTE: no need to call bits2int second time here, it is inside truncateHash!
        // Converts signature params into point w r/s, checks result for validity.
        // Can use scalar blinding b^-1(bm + bdr) where b  [1,q1] according to
        // https://tches.iacr.org/index.php/TCHES/article/view/7337/6509. We've decided against it:
        // a) dependency on CSPRNG b) 15% slowdown c) doesn't really help since bigints are not CT
        function k2sig(kBytes) {
            // RFC 6979 Section 3.2, step 3: k = bits2int(T)
            // Important: all mod() calls here must be done over N
            const k = bits2int(kBytes); // Cannot use fields methods, since it is group element
            if (!Fn.isValidNot0(k))
                return; // Valid scalars (including k) must be in 1..N-1
            const ik = Fn.inv(k); // k^-1 mod n
            const q = Point.BASE.multiply(k).toAffine(); // q = Gk
            const r = Fn.create(q.x); // r = q.x mod n
            if (r === _0n)
                return;
            const s = Fn.create(ik * Fn.create(m + r * d)); // Not using blinding here, see comment above
            if (s === _0n)
                return;
            let recovery = (q.x === r ? 0 : 2) | Number(q.y & _1n$1); // recovery bit (2 or 3, when q.x > n)
            let normS = s;
            if (lowS && isBiggerThanHalfOrder(s)) {
                normS = normalizeS(s); // if lowS was passed, ensure s is always
                recovery ^= 1; // // in the bottom half of N
            }
            return new Signature(r, normS, recovery); // use normS, not s
        }
        return { seed, k2sig };
    }
    const defaultSigOpts = { lowS: ecdsaOpts.lowS, prehash: false };
    const defaultVerOpts = { lowS: ecdsaOpts.lowS, prehash: false };
    /**
     * Signs message hash with a private key.
     * ```
     * sign(m, d, k) where
     *   (x, y) = G  k
     *   r = x mod n
     *   s = (m + dr)/k mod n
     * ```
     * @param msgHash NOT message. msg needs to be hashed to `msgHash`, or use `prehash`.
     * @param privKey private key
     * @param opts lowS for non-malleable sigs. extraEntropy for mixing randomness into k. prehash will hash first arg.
     * @returns signature with recovery param
     */
    function sign(msgHash, privKey, opts = defaultSigOpts) {
        const { seed, k2sig } = prepSig(msgHash, privKey, opts); // Steps A, D of RFC6979 3.2.
        const drbg = createHmacDrbg(ecdsaOpts.hash.outputLen, Fn.BYTES, hmac_);
        return drbg(seed, k2sig); // Steps B, C, D, E, F, G
    }
    // Enable precomputes. Slows down first publicKey computation by 20ms.
    Point.BASE.precompute(8);
    /**
     * Verifies a signature against message hash and public key.
     * Rejects lowS signatures by default: to override,
     * specify option `{lowS: false}`. Implements section 4.1.4 from https://www.secg.org/sec1-v2.pdf:
     *
     * ```
     * verify(r, s, h, P) where
     *   U1 = hs^-1 mod n
     *   U2 = rs^-1 mod n
     *   R = U1G - U2P
     *   mod(R.x, n) == r
     * ```
     */
    function verify(signature, msgHash, publicKey, opts = defaultVerOpts) {
        const sg = signature;
        msgHash = ensureBytes('msgHash', msgHash);
        publicKey = ensureBytes('publicKey', publicKey);
        // Verify opts
        validateSigVerOpts(opts);
        const { lowS, prehash, format } = opts;
        // TODO: remove
        if ('strict' in opts)
            throw new Error('options.strict was renamed to lowS');
        if (format !== undefined && !['compact', 'der', 'js'].includes(format))
            throw new Error('format must be "compact", "der" or "js"');
        const isHex = typeof sg === 'string' || isBytes(sg);
        const isObj = !isHex &&
            !format &&
            typeof sg === 'object' &&
            sg !== null &&
            typeof sg.r === 'bigint' &&
            typeof sg.s === 'bigint';
        if (!isHex && !isObj)
            throw new Error('invalid signature, expected Uint8Array, hex string or Signature instance');
        let _sig = undefined;
        let P;
        // deduce signature format
        try {
            // if (format === 'js') {
            //   if (sg != null && !isBytes(sg)) _sig = new Signature(sg.r, sg.s);
            // } else if (format === 'compact') {
            //   _sig = Signature.fromCompact(sg);
            // } else if (format === 'der') {
            //   _sig = Signature.fromDER(sg);
            // } else {
            //   throw new Error('invalid format');
            // }
            if (isObj) {
                if (format === undefined || format === 'js') {
                    _sig = new Signature(sg.r, sg.s);
                }
                else {
                    throw new Error('invalid format');
                }
            }
            if (isHex) {
                // TODO: remove this malleable check
                // Signature can be represented in 2 ways: compact (2*Fn.BYTES) & DER (variable-length).
                // Since DER can also be 2*Fn.BYTES bytes, we check for it first.
                try {
                    if (format !== 'compact')
                        _sig = Signature.fromDER(sg);
                }
                catch (derError) {
                    if (!(derError instanceof DER.Err))
                        throw derError;
                }
                if (!_sig && format !== 'der')
                    _sig = Signature.fromCompact(sg);
            }
            P = Point.fromHex(publicKey);
        }
        catch (error) {
            return false;
        }
        if (!_sig)
            return false;
        if (lowS && _sig.hasHighS())
            return false;
        // todo: optional.hash => hash
        if (prehash)
            msgHash = ecdsaOpts.hash(msgHash);
        const { r, s } = _sig;
        const h = bits2int_modN(msgHash); // Cannot use fields methods, since it is group element
        const is = Fn.inv(s); // s^-1
        const u1 = Fn.create(h * is); // u1 = hs^-1 mod n
        const u2 = Fn.create(r * is); // u2 = rs^-1 mod n
        const R = Point.BASE.multiplyUnsafe(u1).add(P.multiplyUnsafe(u2));
        if (R.is0())
            return false;
        const v = Fn.create(R.x); // v = r.x mod n
        return v === r;
    }
    // TODO: clarify API for cloning .clone({hash: sha512}) ? .createWith({hash: sha512})?
    // const clone = (hash: CHash): ECDSA => ecdsa(Point, { ...ecdsaOpts, ...getHash(hash) }, curveOpts);
    return Object.freeze({
        getPublicKey,
        getSharedSecret,
        sign,
        verify,
        utils,
        Point,
        Signature,
    });
}
function _weierstrass_legacy_opts_to_new(c) {
    const CURVE = {
        a: c.a,
        b: c.b,
        p: c.Fp.ORDER,
        n: c.n,
        h: c.h,
        Gx: c.Gx,
        Gy: c.Gy,
    };
    const Fp = c.Fp;
    const Fn = Field(CURVE.n, c.nBitLength);
    const curveOpts = {
        Fp,
        Fn,
        allowedPrivateKeyLengths: c.allowedPrivateKeyLengths,
        allowInfinityPoint: c.allowInfinityPoint,
        endo: c.endo,
        wrapPrivateKey: c.wrapPrivateKey,
        isTorsionFree: c.isTorsionFree,
        clearCofactor: c.clearCofactor,
        fromBytes: c.fromBytes,
        toBytes: c.toBytes,
    };
    return { CURVE, curveOpts };
}
function _ecdsa_legacy_opts_to_new(c) {
    const { CURVE, curveOpts } = _weierstrass_legacy_opts_to_new(c);
    const ecdsaOpts = {
        hash: c.hash,
        hmac: c.hmac,
        randomBytes: c.randomBytes,
        lowS: c.lowS,
        bits2int: c.bits2int,
        bits2int_modN: c.bits2int_modN,
    };
    return { CURVE, curveOpts, ecdsaOpts };
}
function _ecdsa_new_output_to_legacy(c, ecdsa) {
    return Object.assign({}, ecdsa, {
        ProjectivePoint: ecdsa.Point,
        CURVE: c,
    });
}
// _ecdsa_legacy
function weierstrass(c) {
    const { CURVE, curveOpts, ecdsaOpts } = _ecdsa_legacy_opts_to_new(c);
    const Point = weierstrassN(CURVE, curveOpts);
    const signs = ecdsa(Point, ecdsaOpts, curveOpts);
    return _ecdsa_new_output_to_legacy(c, signs);
}

/**
 * Utilities for short weierstrass curves, combined with noble-hashes.
 * @module
 */
/*! noble-curves - MIT License (c) 2022 Paul Miller (paulmillr.com) */
function createCurve(curveDef, defHash) {
    const create = (hash) => weierstrass({ ...curveDef, hash: hash });
    return { ...create(defHash), create };
}

/**
 * SECG secp256k1. See [pdf](https://www.secg.org/sec2-v2.pdf).
 *
 * Belongs to Koblitz curves: it has efficiently-computable GLV endomorphism ,
 * check out {@link EndomorphismOpts}. Seems to be rigid (not backdoored).
 * @module
 */
/*! noble-curves - MIT License (c) 2022 Paul Miller (paulmillr.com) */
// Seems like generator was produced from some seed:
// `Point.BASE.multiply(Point.Fn.inv(2n, N)).toAffine().x`
// // gives short x 0x3b78ce563f89a0ed9414f5aa28ad0d96d6795f9c63n
const secp256k1_CURVE = {
    p: BigInt('0xfffffffffffffffffffffffffffffffffffffffffffffffffffffffefffffc2f'),
    n: BigInt('0xfffffffffffffffffffffffffffffffebaaedce6af48a03bbfd25e8cd0364141'),
    h: BigInt(1),
    a: BigInt(0),
    b: BigInt(7),
    Gx: BigInt('0x79be667ef9dcbbac55a06295ce870b07029bfcdb2dce28d959f2815b16f81798'),
    Gy: BigInt('0x483ada7726a3c4655da4fbfc0e1108a8fd17b448a68554199c47d08ffb10d4b8'),
};
BigInt(0);
const _1n = BigInt(1);
const _2n = BigInt(2);
const divNearest = (a, b) => (a + b / _2n) / b;
/**
 * n = n^((p+1)/4) for fields p = 3 mod 4. We unwrap the loop and multiply bit-by-bit.
 * (P+1n/4n).toString(2) would produce bits [223x 1, 0, 22x 1, 4x 0, 11, 00]
 */
function sqrtMod(y) {
    const P = secp256k1_CURVE.p;
    // prettier-ignore
    const _3n = BigInt(3), _6n = BigInt(6), _11n = BigInt(11), _22n = BigInt(22);
    // prettier-ignore
    const _23n = BigInt(23), _44n = BigInt(44), _88n = BigInt(88);
    const b2 = (y * y * y) % P; // x^3, 11
    const b3 = (b2 * b2 * y) % P; // x^7
    const b6 = (pow2(b3, _3n, P) * b3) % P;
    const b9 = (pow2(b6, _3n, P) * b3) % P;
    const b11 = (pow2(b9, _2n, P) * b2) % P;
    const b22 = (pow2(b11, _11n, P) * b11) % P;
    const b44 = (pow2(b22, _22n, P) * b22) % P;
    const b88 = (pow2(b44, _44n, P) * b44) % P;
    const b176 = (pow2(b88, _88n, P) * b88) % P;
    const b220 = (pow2(b176, _44n, P) * b44) % P;
    const b223 = (pow2(b220, _3n, P) * b3) % P;
    const t1 = (pow2(b223, _23n, P) * b22) % P;
    const t2 = (pow2(t1, _6n, P) * b2) % P;
    const root = pow2(t2, _2n, P);
    if (!Fpk1.eql(Fpk1.sqr(root), y))
        throw new Error('Cannot find square root');
    return root;
}
const Fpk1 = Field(secp256k1_CURVE.p, undefined, undefined, { sqrt: sqrtMod });
/**
 * secp256k1 curve, ECDSA and ECDH methods.
 *
 * Field: `2n**256n - 2n**32n - 2n**9n - 2n**8n - 2n**7n - 2n**6n - 2n**4n - 1n`
 *
 * @example
 * ```js
 * import { secp256k1 } from '@noble/curves/secp256k1';
 * const priv = secp256k1.utils.randomPrivateKey();
 * const pub = secp256k1.getPublicKey(priv);
 * const msg = new Uint8Array(32).fill(1); // message hash (not message) in ecdsa
 * const sig = secp256k1.sign(msg, priv); // `{prehash: true}` option is available
 * const isValid = secp256k1.verify(sig, msg, pub) === true;
 * ```
 */
const secp256k1 = createCurve({
    ...secp256k1_CURVE,
    Fp: Fpk1,
    lowS: true, // Allow only low-S signatures by default in sign() and verify()
    endo: {
        // Endomorphism, see above
        beta: BigInt('0x7ae96a2b657c07106e64479eac3434e99cf0497512f58995c1396c28719501ee'),
        splitScalar: (k) => {
            const n = secp256k1_CURVE.n;
            const a1 = BigInt('0x3086d221a7d46bcde86c90e49284eb15');
            const b1 = -_1n * BigInt('0xe4437ed6010e88286f547fa90abfe4c3');
            const a2 = BigInt('0x114ca50f7a8e2f3f657c1108d9d44cfd8');
            const b2 = a1;
            const POW_2_128 = BigInt('0x100000000000000000000000000000000'); // (2n**128n).toString(16)
            const c1 = divNearest(b2 * k, n);
            const c2 = divNearest(-b1 * k, n);
            let k1 = mod(k - c1 * a1 - c2 * a2, n);
            let k2 = mod(-c1 * b1 - c2 * b2, n);
            const k1neg = k1 > POW_2_128;
            const k2neg = k2 > POW_2_128;
            if (k1neg)
                k1 = n - k1;
            if (k2neg)
                k2 = n - k2;
            if (k1 > POW_2_128 || k2 > POW_2_128) {
                throw new Error('splitScalar: Endomorphism failed, k=' + k);
            }
            return { k1neg, k1, k2neg, k2 };
        },
    },
}, sha256$2);

/**
 * Hash message and verify signature with public key
 */
function hashAndVerify(key, sig, msg, options) {
    const p = sha256.digest(msg instanceof Uint8Array ? msg : msg.subarray());
    if (isPromise(p)) {
        return p
            .then(({ digest }) => {
            options?.signal?.throwIfAborted();
            return secp256k1.verify(sig, digest, key);
        })
            .catch(err => {
            if (err.name === 'AbortError') {
                throw err;
            }
            throw new VerificationError(String(err));
        });
    }
    try {
        options?.signal?.throwIfAborted();
        return secp256k1.verify(sig, p.digest, key);
    }
    catch (err) {
        throw new VerificationError(String(err));
    }
}

class Secp256k1PublicKey {
    type = 'secp256k1';
    raw;
    _key;
    constructor(key) {
        this._key = validateSecp256k1PublicKey(key);
        this.raw = compressSecp256k1PublicKey(this._key);
    }
    toMultihash() {
        return identity.digest(publicKeyToProtobuf(this));
    }
    toCID() {
        return CID.createV1(114, this.toMultihash());
    }
    toString() {
        return base58btc.encode(this.toMultihash().bytes).substring(1);
    }
    equals(key) {
        if (key == null || !(key.raw instanceof Uint8Array)) {
            return false;
        }
        return equals(this.raw, key.raw);
    }
    verify(data, sig, options) {
        return hashAndVerify(this._key, sig, data, options);
    }
}

function unmarshalSecp256k1PublicKey(bytes) {
    return new Secp256k1PublicKey(bytes);
}
function compressSecp256k1PublicKey(key) {
    const point = secp256k1.ProjectivePoint.fromHex(key).toRawBytes(true);
    return point;
}
function validateSecp256k1PublicKey(key) {
    try {
        secp256k1.ProjectivePoint.fromHex(key);
        return key;
    }
    catch (err) {
        throw new InvalidPublicKeyError(String(err));
    }
}

/**
 * @packageDocumentation
 *
 * ## Supported Key Types
 *
 * Currently the `'RSA'`, `'ed25519'`, and `secp256k1` types are supported, although ed25519 and secp256k1 keys support only signing and verification of messages.
 *
 * For encryption / decryption support, RSA keys should be used.
 */
/**
 * Creates a public key from an identity multihash which contains a protobuf
 * encoded Ed25519 or secp256k1 public key.
 *
 * RSA keys are not supported as in practice we they are not stored in identity
 * multihash since the hash would be very large.
 */
function publicKeyFromMultihash(digest) {
    const { Type, Data } = PublicKey.decode(digest.digest);
    const data = Data ?? new Uint8Array();
    switch (Type) {
        case KeyType.Ed25519:
            return unmarshalEd25519PublicKey(data);
        case KeyType.secp256k1:
            return unmarshalSecp256k1PublicKey(data);
        case KeyType.ECDSA:
            return unmarshalECDSAPublicKey(data);
        default:
            throw new UnsupportedKeyTypeError();
    }
}
/**
 * Converts a public key object into a protobuf serialized public key
 */
function publicKeyToProtobuf(key) {
    return PublicKey.encode({
        Type: KeyType[key.type],
        Data: key.raw
    });
}

/**
 * @packageDocumentation
 *
 * An implementation of a peer id
 *
 * @example
 *
 * ```TypeScript
 * import { peerIdFromString } from '@libp2p/peer-id'
 * const peer = peerIdFromString('k51qzi5uqu5dkwkqm42v9j9kqcam2jiuvloi16g72i4i4amoo2m8u3ol3mqu6s')
 *
 * console.log(peer.toCID()) // CID(bafzaa...)
 * console.log(peer.toString()) // "12D3K..."
 * ```
 */
const inspect$1 = Symbol.for('nodejs.util.inspect.custom');
// these values are from https://github.com/multiformats/multicodec/blob/master/table.csv
const LIBP2P_KEY_CODE$1 = 0x72;
class PeerIdImpl {
    type;
    multihash;
    publicKey;
    string;
    constructor(init) {
        this.type = init.type;
        this.multihash = init.multihash;
        // mark string cache as non-enumerable
        Object.defineProperty(this, 'string', {
            enumerable: false,
            writable: true
        });
    }
    get [Symbol.toStringTag]() {
        return `PeerId(${this.toString()})`;
    }
    [peerIdSymbol] = true;
    toString() {
        if (this.string == null) {
            this.string = base58btc.encode(this.multihash.bytes).slice(1);
        }
        return this.string;
    }
    toMultihash() {
        return this.multihash;
    }
    // return self-describing String representation
    // in default format from RFC 0001: https://github.com/libp2p/specs/pull/209
    toCID() {
        return CID.createV1(LIBP2P_KEY_CODE$1, this.multihash);
    }
    toJSON() {
        return this.toString();
    }
    /**
     * Checks the equality of `this` peer against a given PeerId
     */
    equals(id) {
        if (id == null) {
            return false;
        }
        if (id instanceof Uint8Array) {
            return equals(this.multihash.bytes, id);
        }
        else if (typeof id === 'string') {
            return this.toString() === id;
        }
        else if (id?.toMultihash()?.bytes != null) {
            return equals(this.multihash.bytes, id.toMultihash().bytes);
        }
        else {
            throw new Error('not valid Id');
        }
    }
    /**
     * Returns PeerId as a human-readable string
     * https://nodejs.org/api/util.html#utilinspectcustom
     *
     * @example
     * ```TypeScript
     * import { peerIdFromString } from '@libp2p/peer-id'
     *
     * console.info(peerIdFromString('QmFoo'))
     * // 'PeerId(QmFoo)'
     * ```
     */
    [inspect$1]() {
        return `PeerId(${this.toString()})`;
    }
}
class RSAPeerId extends PeerIdImpl {
    type = 'RSA';
    publicKey;
    constructor(init) {
        super({ ...init, type: 'RSA' });
        this.publicKey = init.publicKey;
    }
}
class Ed25519PeerId extends PeerIdImpl {
    type = 'Ed25519';
    publicKey;
    constructor(init) {
        super({ ...init, type: 'Ed25519' });
        this.publicKey = init.publicKey;
    }
}
class Secp256k1PeerId extends PeerIdImpl {
    type = 'secp256k1';
    publicKey;
    constructor(init) {
        super({ ...init, type: 'secp256k1' });
        this.publicKey = init.publicKey;
    }
}
// these values are from https://github.com/multiformats/multicodec/blob/master/table.csv
const TRANSPORT_IPFS_GATEWAY_HTTP_CODE$1 = 0x0920;
class URLPeerId {
    type = 'url';
    multihash;
    publicKey;
    url;
    constructor(url) {
        this.url = url.toString();
        this.multihash = identity.digest(fromString(this.url));
    }
    [inspect$1]() {
        return `PeerId(${this.url})`;
    }
    [peerIdSymbol] = true;
    toString() {
        return this.toCID().toString();
    }
    toMultihash() {
        return this.multihash;
    }
    toCID() {
        return CID.createV1(TRANSPORT_IPFS_GATEWAY_HTTP_CODE$1, this.toMultihash());
    }
    toJSON() {
        return this.toString();
    }
    equals(other) {
        if (other == null) {
            return false;
        }
        if (other instanceof Uint8Array) {
            other = toString(other);
        }
        return other.toString() === this.toString();
    }
}

/**
 * @packageDocumentation
 *
 * An implementation of a peer id
 *
 * @example
 *
 * ```TypeScript
 * import { peerIdFromString } from '@libp2p/peer-id'
 * const peer = peerIdFromString('12D3KooWKnDdG3iXw9eTFijk3EWSunZcFi54Zka4wmtqtt6rPxc8')
 *
 * console.log(peer.toCID()) // CID(bafzaa...)
 * console.log(peer.toString()) // "12D3K..."
 * ```
 */
// these values are from https://github.com/multiformats/multicodec/blob/master/table.csv
const LIBP2P_KEY_CODE = 0x72;
const TRANSPORT_IPFS_GATEWAY_HTTP_CODE = 0x0920;
function peerIdFromString(str, decoder) {
    let multihash;
    if (str.charAt(0) === '1' || str.charAt(0) === 'Q') {
        // identity hash ed25519/secp256k1 key or sha2-256 hash of
        // rsa public key - base58btc encoded either way
        multihash = decode$1(base58btc.decode(`z${str}`));
    }
    else if (str.startsWith('k51qzi5uqu5') || str.startsWith('kzwfwjn5ji4') || str.startsWith('k2k4r8') || str.startsWith('bafz')) {
        // base36 encoded CIDv1 with libp2p-key and identity hash (for ed25519/secp256k1/rsa) or base32 encoded CIDv1 with libp2p-key and identity hash (for ed25519/secp256k1/rsa)
        return peerIdFromCID(CID.parse(str));
    }
    else {
        {
            throw new InvalidParametersError$1('Please pass a multibase decoder for strings that do not start with "1" or "Q"');
        }
    }
    return peerIdFromMultihash(multihash);
}
function peerIdFromMultihash(multihash) {
    if (isSha256Multihash(multihash)) {
        return new RSAPeerId({ multihash });
    }
    else if (isIdentityMultihash(multihash)) {
        try {
            const publicKey = publicKeyFromMultihash(multihash);
            if (publicKey.type === 'Ed25519') {
                return new Ed25519PeerId({ multihash, publicKey });
            }
            else if (publicKey.type === 'secp256k1') {
                return new Secp256k1PeerId({ multihash, publicKey });
            }
        }
        catch (err) {
            // was not Ed or secp key, try URL
            const url = toString(multihash.digest);
            return new URLPeerId(new URL(url));
        }
    }
    throw new InvalidMultihashError('Supplied PeerID Multihash is invalid');
}
function peerIdFromCID(cid) {
    if (cid?.multihash == null || cid.version == null || (cid.version === 1 && (cid.code !== LIBP2P_KEY_CODE) && cid.code !== TRANSPORT_IPFS_GATEWAY_HTTP_CODE)) {
        throw new InvalidCIDError('Supplied PeerID CID is invalid');
    }
    if (cid.code === TRANSPORT_IPFS_GATEWAY_HTTP_CODE) {
        const url = toString(cid.multihash.digest);
        return new URLPeerId(new URL(url));
    }
    return peerIdFromMultihash(cid.multihash);
}
function isIdentityMultihash(multihash) {
    return multihash.code === identity.code;
}
function isSha256Multihash(multihash) {
    return multihash.code === sha256.code;
}

/**
 * Thrown when an invalid multiaddr is encountered
 */
class InvalidMultiaddrError extends Error {
    static name = 'InvalidMultiaddrError';
    name = 'InvalidMultiaddrError';
}
class ValidationError extends Error {
    static name = 'ValidationError';
    name = 'ValidationError';
}
class InvalidParametersError extends Error {
    static name = 'InvalidParametersError';
    name = 'InvalidParametersError';
}
class UnknownProtocolError extends Error {
    static name = 'UnknownProtocolError';
    name = 'UnknownProtocolError';
}

/* eslint-disable @typescript-eslint/no-unsafe-return */
class Parser {
    index = 0;
    input = "";
    new(input) {
        this.index = 0;
        this.input = input;
        return this;
    }
    /** Run a parser, and restore the pre-parse state if it fails. */
    readAtomically(fn) {
        const index = this.index;
        const result = fn();
        if (result === undefined) {
            this.index = index;
        }
        return result;
    }
    /** Run a parser, but fail if the entire input wasn't consumed. Doesn't run atomically. */
    parseWith(fn) {
        const result = fn();
        if (this.index !== this.input.length) {
            return undefined;
        }
        return result;
    }
    /** Peek the next character from the input */
    peekChar() {
        if (this.index >= this.input.length) {
            return undefined;
        }
        return this.input[this.index];
    }
    /** Read the next character from the input */
    readChar() {
        if (this.index >= this.input.length) {
            return undefined;
        }
        return this.input[this.index++];
    }
    /** Read the next character from the input if it matches the target. */
    readGivenChar(target) {
        return this.readAtomically(() => {
            const char = this.readChar();
            if (char !== target) {
                return undefined;
            }
            return char;
        });
    }
    /**
     * Helper for reading separators in an indexed loop. Reads the separator
     * character iff index > 0, then runs the parser. When used in a loop,
     * the separator character will only be read on index > 0 (see
     * readIPv4Addr for an example)
     */
    readSeparator(sep, index, inner) {
        return this.readAtomically(() => {
            if (index > 0) {
                if (this.readGivenChar(sep) === undefined) {
                    return undefined;
                }
            }
            return inner();
        });
    }
    /**
     * Read a number off the front of the input in the given radix, stopping
     * at the first non-digit character or eof. Fails if the number has more
     * digits than max_digits or if there is no number.
     */
    readNumber(radix, maxDigits, allowZeroPrefix, maxBytes) {
        return this.readAtomically(() => {
            let result = 0;
            let digitCount = 0;
            const leadingChar = this.peekChar();
            if (leadingChar === undefined) {
                return undefined;
            }
            const hasLeadingZero = leadingChar === "0";
            const maxValue = 2 ** (8 * maxBytes) - 1;
            // eslint-disable-next-line no-constant-condition
            while (true) {
                const digit = this.readAtomically(() => {
                    const char = this.readChar();
                    if (char === undefined) {
                        return undefined;
                    }
                    const num = Number.parseInt(char, radix);
                    if (Number.isNaN(num)) {
                        return undefined;
                    }
                    return num;
                });
                if (digit === undefined) {
                    break;
                }
                result *= radix;
                result += digit;
                if (result > maxValue) {
                    return undefined;
                }
                digitCount += 1;
                if (maxDigits !== undefined) {
                    if (digitCount > maxDigits) {
                        return undefined;
                    }
                }
            }
            if (digitCount === 0) {
                return undefined;
            }
            else if (!allowZeroPrefix && hasLeadingZero && digitCount > 1) {
                return undefined;
            }
            else {
                return result;
            }
        });
    }
    /** Read an IPv4 address. */
    readIPv4Addr() {
        return this.readAtomically(() => {
            const out = new Uint8Array(4);
            for (let i = 0; i < out.length; i++) {
                const ix = this.readSeparator(".", i, () => this.readNumber(10, 3, false, 1));
                if (ix === undefined) {
                    return undefined;
                }
                out[i] = ix;
            }
            return out;
        });
    }
    /** Read an IPv6 Address. */
    readIPv6Addr() {
        /**
         * Read a chunk of an IPv6 address into `groups`. Returns the number
         * of groups read, along with a bool indicating if an embedded
         * trailing IPv4 address was read. Specifically, read a series of
         * colon-separated IPv6 groups (0x0000 - 0xFFFF), with an optional
         * trailing embedded IPv4 address.
         */
        const readGroups = (groups) => {
            for (let i = 0; i < groups.length / 2; i++) {
                const ix = i * 2;
                // Try to read a trailing embedded IPv4 address. There must be at least 4 groups left.
                if (i < groups.length - 3) {
                    const ipv4 = this.readSeparator(":", i, () => this.readIPv4Addr());
                    if (ipv4 !== undefined) {
                        groups[ix] = ipv4[0];
                        groups[ix + 1] = ipv4[1];
                        groups[ix + 2] = ipv4[2];
                        groups[ix + 3] = ipv4[3];
                        return [ix + 4, true];
                    }
                }
                const group = this.readSeparator(":", i, () => this.readNumber(16, 4, true, 2));
                if (group === undefined) {
                    return [ix, false];
                }
                groups[ix] = group >> 8;
                groups[ix + 1] = group & 255;
            }
            return [groups.length, false];
        };
        return this.readAtomically(() => {
            // Read the front part of the address; either the whole thing, or up to the first ::
            const head = new Uint8Array(16);
            const [headSize, headIp4] = readGroups(head);
            if (headSize === 16) {
                return head;
            }
            // IPv4 part is not allowed before `::`
            if (headIp4) {
                return undefined;
            }
            // Read `::` if previous code parsed less than 8 groups.
            // `::` indicates one or more groups of 16 bits of zeros.
            if (this.readGivenChar(":") === undefined) {
                return undefined;
            }
            if (this.readGivenChar(":") === undefined) {
                return undefined;
            }
            // Read the back part of the address. The :: must contain at least one
            // set of zeroes, so our max length is 7.
            const tail = new Uint8Array(14);
            const limit = 16 - (headSize + 2);
            const [tailSize] = readGroups(tail.subarray(0, limit));
            // Concat the head and tail of the IP address
            head.set(tail.subarray(0, tailSize), 16 - tailSize);
            return head;
        });
    }
    /** Read an IP Address, either IPv4 or IPv6. */
    readIPAddr() {
        return this.readIPv4Addr() ?? this.readIPv6Addr();
    }
}

// See https://stackoverflow.com/questions/166132/maximum-length-of-the-textual-representation-of-an-ipv6-address
const MAX_IPV6_LENGTH = 45;
const MAX_IPV4_LENGTH = 15;
const parser = new Parser();
/** Parse `input` into IPv4 bytes. */
function parseIPv4(input) {
    if (input.length > MAX_IPV4_LENGTH) {
        return undefined;
    }
    return parser.new(input).parseWith(() => parser.readIPv4Addr());
}
/** Parse `input` into IPv6 bytes. */
function parseIPv6(input) {
    // strip zone index if it is present
    if (input.includes("%")) {
        input = input.split("%")[0];
    }
    if (input.length > MAX_IPV6_LENGTH) {
        return undefined;
    }
    return parser.new(input).parseWith(() => parser.readIPv6Addr());
}

/** Check if `input` is IPv4. */
function isIPv4(input) {
    return Boolean(parseIPv4(input));
}
/** Check if `input` is IPv6. */
function isIPv6(input) {
    return Boolean(parseIPv6(input));
}

// the values here come from https://github.com/multiformats/multiaddr/blob/master/protocols.csv
const CODE_IP4 = 4;
const CODE_TCP = 6;
const CODE_UDP = 273;
const CODE_DCCP = 33;
const CODE_IP6 = 41;
const CODE_IP6ZONE = 42;
const CODE_IPCIDR = 43;
const CODE_DNS = 53;
const CODE_DNS4 = 54;
const CODE_DNS6 = 55;
const CODE_DNSADDR = 56;
const CODE_SCTP = 132;
const CODE_UDT = 301;
const CODE_UTP = 302;
const CODE_UNIX = 400;
const CODE_P2P = 421; // also IPFS
const CODE_ONION = 444;
const CODE_ONION3 = 445;
const CODE_GARLIC64 = 446;
const CODE_GARLIC32 = 447;
const CODE_TLS = 448;
const CODE_SNI = 449;
const CODE_NOISE = 454;
const CODE_QUIC = 460;
const CODE_QUIC_V1 = 461;
const CODE_WEBTRANSPORT = 465;
const CODE_CERTHASH = 466;
const CODE_HTTP = 480;
const CODE_HTTP_PATH = 481;
const CODE_HTTPS = 443;
const CODE_WS = 477;
const CODE_WSS = 478;
const CODE_P2P_WEBSOCKET_STAR = 479;
const CODE_P2P_STARDUST = 277;
const CODE_P2P_WEBRTC_STAR = 275;
const CODE_P2P_WEBRTC_DIRECT = 276;
const CODE_WEBRTC_DIRECT = 280;
const CODE_WEBRTC = 281;
const CODE_P2P_CIRCUIT = 290;
const CODE_MEMORY = 777;

function bytesToString(base) {
    return (buf) => {
        return toString(buf, base);
    };
}
function stringToBytes(base) {
    return (buf) => {
        return fromString(buf, base);
    };
}
function bytes2port(buf) {
    const view = new DataView(buf.buffer);
    return view.getUint16(buf.byteOffset).toString();
}
function port2bytes(port) {
    const buf = new ArrayBuffer(2);
    const view = new DataView(buf);
    view.setUint16(0, typeof port === 'string' ? parseInt(port) : port);
    return new Uint8Array(buf);
}
function onion2bytes(str) {
    const addr = str.split(':');
    if (addr.length !== 2) {
        throw new Error(`failed to parse onion addr: ["'${addr.join('", "')}'"]' does not contain a port number`);
    }
    if (addr[0].length !== 16) {
        throw new Error(`failed to parse onion addr: ${addr[0]} not a Tor onion address.`);
    }
    // onion addresses do not include the multibase prefix, add it before decoding
    const buf = fromString(addr[0], 'base32');
    // onion port number
    const port = parseInt(addr[1], 10);
    if (port < 1 || port > 65536) {
        throw new Error('Port number is not in range(1, 65536)');
    }
    const portBuf = port2bytes(port);
    return concat([buf, portBuf], buf.length + portBuf.length);
}
function onion32bytes(str) {
    const addr = str.split(':');
    if (addr.length !== 2) {
        throw new Error(`failed to parse onion addr: ["'${addr.join('", "')}'"]' does not contain a port number`);
    }
    if (addr[0].length !== 56) {
        throw new Error(`failed to parse onion addr: ${addr[0]} not a Tor onion3 address.`);
    }
    // onion addresses do not include the multibase prefix, add it before decoding
    const buf = base32.decode(`b${addr[0]}`);
    // onion port number
    const port = parseInt(addr[1], 10);
    if (port < 1 || port > 65536) {
        throw new Error('Port number is not in range(1, 65536)');
    }
    const portBuf = port2bytes(port);
    return concat([buf, portBuf], buf.length + portBuf.length);
}
function bytes2onion(buf) {
    const addrBytes = buf.subarray(0, buf.length - 2);
    const portBytes = buf.subarray(buf.length - 2);
    const addr = toString(addrBytes, 'base32');
    const port = bytes2port(portBytes);
    return `${addr}:${port}`;
}
// Copied from https://github.com/indutny/node-ip/blob/master/lib/ip.js#L7
// but with buf/offset args removed because we don't use them
const ip4ToBytes = function (ip) {
    ip = ip.toString().trim();
    const bytes = new Uint8Array(4);
    ip.split(/\./g).forEach((byte, index) => {
        const value = parseInt(byte, 10);
        if (isNaN(value) || value < 0 || value > 0xff) {
            throw new InvalidMultiaddrError('Invalid byte value in IP address');
        }
        bytes[index] = value;
    });
    return bytes;
};
// Copied from https://github.com/indutny/node-ip/blob/master/lib/ip.js#L7
// but with buf/offset args removed because we don't use them
const ip6ToBytes = function (ip) {
    let offset = 0;
    ip = ip.toString().trim();
    const sections = ip.split(':', 8);
    let i;
    for (i = 0; i < sections.length; i++) {
        const isv4 = isIPv4(sections[i]);
        let v4Buffer;
        if (isv4) {
            v4Buffer = ip4ToBytes(sections[i]);
            sections[i] = toString(v4Buffer.subarray(0, 2), 'base16');
        }
        if (v4Buffer != null && ++i < 8) {
            sections.splice(i, 0, toString(v4Buffer.subarray(2, 4), 'base16'));
        }
    }
    if (sections[0] === '') {
        while (sections.length < 8) {
            sections.unshift('0');
        }
    }
    else if (sections[sections.length - 1] === '') {
        while (sections.length < 8) {
            sections.push('0');
        }
    }
    else if (sections.length < 8) {
        for (i = 0; i < sections.length && sections[i] !== ''; i++) { }
        const argv = [i, 1];
        for (i = 9 - sections.length; i > 0; i--) {
            argv.push('0');
        }
        sections.splice.apply(sections, argv);
    }
    const bytes = new Uint8Array(offset + 16);
    for (i = 0; i < sections.length; i++) {
        if (sections[i] === '') {
            sections[i] = '0';
        }
        const word = parseInt(sections[i], 16);
        if (isNaN(word) || word < 0 || word > 0xffff) {
            throw new InvalidMultiaddrError('Invalid byte value in IP address');
        }
        bytes[offset++] = (word >> 8) & 0xff;
        bytes[offset++] = word & 0xff;
    }
    return bytes;
};
// Copied from https://github.com/indutny/node-ip/blob/master/lib/ip.js#L63
const ip4ToString = function (buf) {
    if (buf.byteLength !== 4) {
        throw new InvalidMultiaddrError('IPv4 address was incorrect length');
    }
    const result = [];
    for (let i = 0; i < buf.byteLength; i++) {
        result.push(buf[i]);
    }
    return result.join('.');
};
const ip6ToString = function (buf) {
    if (buf.byteLength !== 16) {
        throw new InvalidMultiaddrError('IPv6 address was incorrect length');
    }
    const result = [];
    for (let i = 0; i < buf.byteLength; i += 2) {
        const byte1 = buf[i];
        const byte2 = buf[i + 1];
        const tuple = `${byte1.toString(16).padStart(2, '0')}${byte2.toString(16).padStart(2, '0')}`;
        result.push(tuple);
    }
    const ip = result.join(':');
    try {
        const url = new URL(`http://[${ip}]`);
        return url.hostname.substring(1, url.hostname.length - 1);
    }
    catch {
        throw new InvalidMultiaddrError(`Invalid IPv6 address "${ip}"`);
    }
};
function ip6StringToValue(str) {
    try {
        const url = new URL(`http://[${str}]`);
        return url.hostname.substring(1, url.hostname.length - 1);
    }
    catch {
        throw new InvalidMultiaddrError(`Invalid IPv6 address "${str}"`);
    }
}
const decoders = Object.values(bases).map((c) => c.decoder);
const anybaseDecoder = (function () {
    let acc = decoders[0].or(decoders[1]);
    decoders.slice(2).forEach((d) => (acc = acc.or(d)));
    return acc;
})();
function mb2bytes(mbstr) {
    return anybaseDecoder.decode(mbstr);
}
function bytes2mb(base) {
    return (buf) => {
        return base.encoder.encode(buf);
    };
}

function integer(value) {
    const int = parseInt(value);
    if (int.toString() !== value) {
        throw new ValidationError('Value must be an integer');
    }
}
function positive(value) {
    if (value < 0) {
        throw new ValidationError('Value must be a positive integer, or zero');
    }
}
function maxValue(max) {
    return (value) => {
        if (value > max) {
            throw new ValidationError(`Value must be smaller than or equal to ${max}`);
        }
    };
}
function validate$1(...funcs) {
    return (value) => {
        for (const fn of funcs) {
            fn(value);
        }
    };
}
const validatePort = validate$1(integer, positive, maxValue(65_535));

const V = -1;
class Registry {
    protocolsByCode = new Map();
    protocolsByName = new Map();
    getProtocol(key) {
        let codec;
        if (typeof key === 'string') {
            codec = this.protocolsByName.get(key);
        }
        else {
            codec = this.protocolsByCode.get(key);
        }
        if (codec == null) {
            throw new UnknownProtocolError(`Protocol ${key} was unknown`);
        }
        return codec;
    }
    addProtocol(codec) {
        this.protocolsByCode.set(codec.code, codec);
        this.protocolsByName.set(codec.name, codec);
        codec.aliases?.forEach(alias => {
            this.protocolsByName.set(alias, codec);
        });
    }
    removeProtocol(code) {
        const codec = this.protocolsByCode.get(code);
        if (codec == null) {
            return;
        }
        this.protocolsByCode.delete(codec.code);
        this.protocolsByName.delete(codec.name);
        codec.aliases?.forEach(alias => {
            this.protocolsByName.delete(alias);
        });
    }
}
const registry = new Registry();
const codecs = [{
        code: CODE_IP4,
        name: 'ip4',
        size: 32,
        valueToBytes: ip4ToBytes,
        bytesToValue: ip4ToString,
        validate: (value) => {
            if (!isIPv4(value)) {
                throw new ValidationError(`Invalid IPv4 address "${value}"`);
            }
        }
    }, {
        code: CODE_TCP,
        name: 'tcp',
        size: 16,
        valueToBytes: port2bytes,
        bytesToValue: bytes2port,
        validate: validatePort
    }, {
        code: CODE_UDP,
        name: 'udp',
        size: 16,
        valueToBytes: port2bytes,
        bytesToValue: bytes2port,
        validate: validatePort
    }, {
        code: CODE_DCCP,
        name: 'dccp',
        size: 16,
        valueToBytes: port2bytes,
        bytesToValue: bytes2port,
        validate: validatePort
    }, {
        code: CODE_IP6,
        name: 'ip6',
        size: 128,
        valueToBytes: ip6ToBytes,
        bytesToValue: ip6ToString,
        stringToValue: ip6StringToValue,
        validate: (value) => {
            if (!isIPv6(value)) {
                throw new ValidationError(`Invalid IPv6 address "${value}"`);
            }
        }
    }, {
        code: CODE_IP6ZONE,
        name: 'ip6zone',
        size: V
    }, {
        code: CODE_IPCIDR,
        name: 'ipcidr',
        size: 8,
        bytesToValue: bytesToString('base10'),
        valueToBytes: stringToBytes('base10')
    }, {
        code: CODE_DNS,
        name: 'dns',
        size: V,
        resolvable: true
    }, {
        code: CODE_DNS4,
        name: 'dns4',
        size: V,
        resolvable: true
    }, {
        code: CODE_DNS6,
        name: 'dns6',
        size: V,
        resolvable: true
    }, {
        code: CODE_DNSADDR,
        name: 'dnsaddr',
        size: V,
        resolvable: true
    }, {
        code: CODE_SCTP,
        name: 'sctp',
        size: 16,
        valueToBytes: port2bytes,
        bytesToValue: bytes2port,
        validate: validatePort
    }, {
        code: CODE_UDT,
        name: 'udt'
    }, {
        code: CODE_UTP,
        name: 'utp'
    }, {
        code: CODE_UNIX,
        name: 'unix',
        size: V,
        path: true,
        stringToValue: (str) => decodeURIComponent(str),
        valueToString: (val) => encodeURIComponent(val)
    }, {
        code: CODE_P2P,
        name: 'p2p',
        aliases: ['ipfs'],
        size: V,
        bytesToValue: bytesToString('base58btc'),
        valueToBytes: (val) => {
            if (val.startsWith('Q') || val.startsWith('1')) {
                return stringToBytes('base58btc')(val);
            }
            return CID.parse(val).multihash.bytes;
        }
    }, {
        code: CODE_ONION,
        name: 'onion',
        size: 96,
        bytesToValue: bytes2onion,
        valueToBytes: onion2bytes
    }, {
        code: CODE_ONION3,
        name: 'onion3',
        size: 296,
        bytesToValue: bytes2onion,
        valueToBytes: onion32bytes
    }, {
        code: CODE_GARLIC64,
        name: 'garlic64',
        size: V
    }, {
        code: CODE_GARLIC32,
        name: 'garlic32',
        size: V
    }, {
        code: CODE_TLS,
        name: 'tls'
    }, {
        code: CODE_SNI,
        name: 'sni',
        size: V
    }, {
        code: CODE_NOISE,
        name: 'noise'
    }, {
        code: CODE_QUIC,
        name: 'quic'
    }, {
        code: CODE_QUIC_V1,
        name: 'quic-v1'
    }, {
        code: CODE_WEBTRANSPORT,
        name: 'webtransport'
    }, {
        code: CODE_CERTHASH,
        name: 'certhash',
        size: V,
        bytesToValue: bytes2mb(base64url),
        valueToBytes: mb2bytes
    }, {
        code: CODE_HTTP,
        name: 'http'
    }, {
        code: CODE_HTTP_PATH,
        name: 'http-path',
        size: V,
        stringToValue: (str) => `/${decodeURIComponent(str)}`,
        valueToString: (val) => encodeURIComponent(val.substring(1))
    }, {
        code: CODE_HTTPS,
        name: 'https'
    }, {
        code: CODE_WS,
        name: 'ws'
    }, {
        code: CODE_WSS,
        name: 'wss'
    }, {
        code: CODE_P2P_WEBSOCKET_STAR,
        name: 'p2p-websocket-star'
    }, {
        code: CODE_P2P_STARDUST,
        name: 'p2p-stardust'
    }, {
        code: CODE_P2P_WEBRTC_STAR,
        name: 'p2p-webrtc-star'
    }, {
        code: CODE_P2P_WEBRTC_DIRECT,
        name: 'p2p-webrtc-direct'
    }, {
        code: CODE_WEBRTC_DIRECT,
        name: 'webrtc-direct'
    }, {
        code: CODE_WEBRTC,
        name: 'webrtc'
    }, {
        code: CODE_P2P_CIRCUIT,
        name: 'p2p-circuit'
    }, {
        code: CODE_MEMORY,
        name: 'memory',
        size: V
    }];
codecs.forEach(codec => {
    registry.addProtocol(codec);
});

function bytesToComponents(bytes) {
    const components = [];
    let i = 0;
    while (i < bytes.length) {
        const code = decode$4(bytes, i);
        const codec = registry.getProtocol(code);
        const codeLength = encodingLength$1(code);
        const size = sizeForAddr(codec, bytes, i + codeLength);
        let sizeLength = 0;
        if (size > 0 && codec.size === V) {
            sizeLength = encodingLength$1(size);
        }
        const componentLength = codeLength + sizeLength + size;
        const component = {
            code,
            name: codec.name,
            bytes: bytes.subarray(i, i + componentLength)
        };
        if (size > 0) {
            const valueOffset = i + codeLength + sizeLength;
            const valueBytes = bytes.subarray(valueOffset, valueOffset + size);
            component.value = codec.bytesToValue?.(valueBytes) ?? toString(valueBytes);
        }
        components.push(component);
        i += componentLength;
    }
    return components;
}
function componentsToBytes(components) {
    let length = 0;
    const bytes = [];
    for (const component of components) {
        if (component.bytes == null) {
            const codec = registry.getProtocol(component.code);
            const codecLength = encodingLength$1(component.code);
            let valueBytes;
            let valueLength = 0;
            let valueLengthLength = 0;
            if (component.value != null) {
                valueBytes = codec.valueToBytes?.(component.value) ?? fromString(component.value);
                valueLength = valueBytes.byteLength;
                if (codec.size === V) {
                    valueLengthLength = encodingLength$1(valueLength);
                }
            }
            const bytes = new Uint8Array(codecLength + valueLengthLength + valueLength);
            // encode the protocol code
            let offset = 0;
            encodeUint8Array(component.code, bytes, offset);
            offset += codecLength;
            // if there is a value
            if (valueBytes != null) {
                // if the value has variable length, encode the length
                if (codec.size === V) {
                    encodeUint8Array(valueLength, bytes, offset);
                    offset += valueLengthLength;
                }
                // finally encode the value
                bytes.set(valueBytes, offset);
            }
            component.bytes = bytes;
        }
        bytes.push(component.bytes);
        length += component.bytes.byteLength;
    }
    return concat(bytes, length);
}
function stringToComponents(string) {
    if (string.charAt(0) !== '/') {
        throw new InvalidMultiaddrError('String multiaddr must start with "/"');
    }
    const components = [];
    let collecting = 'protocol';
    let value = '';
    let protocol = '';
    for (let i = 1; i < string.length; i++) {
        const char = string.charAt(i);
        if (char !== '/') {
            if (collecting === 'protocol') {
                protocol += string.charAt(i);
            }
            else {
                value += string.charAt(i);
            }
        }
        const ended = i === string.length - 1;
        if (char === '/' || ended) {
            const codec = registry.getProtocol(protocol);
            if (collecting === 'protocol') {
                if (codec.size == null || codec.size === 0) {
                    // a protocol without an address, eg. `/tls`
                    components.push({
                        code: codec.code,
                        name: codec.name
                    });
                    value = '';
                    protocol = '';
                    collecting = 'protocol';
                    continue;
                }
                else if (ended) {
                    throw new InvalidMultiaddrError(`Component ${protocol} was missing value`);
                }
                // continue collecting value
                collecting = 'value';
            }
            else if (collecting === 'value') {
                const component = {
                    code: codec.code,
                    name: codec.name
                };
                if (codec.size != null && codec.size !== 0) {
                    if (value === '') {
                        throw new InvalidMultiaddrError(`Component ${protocol} was missing value`);
                    }
                    component.value = codec.stringToValue?.(value) ?? value;
                }
                components.push(component);
                value = '';
                protocol = '';
                collecting = 'protocol';
            }
        }
    }
    if (protocol !== '' && value !== '') {
        throw new InvalidMultiaddrError('Incomplete multiaddr');
    }
    return components;
}
function componentsToString(components) {
    return `/${components.flatMap(component => {
        if (component.value == null) {
            return component.name;
        }
        const codec = registry.getProtocol(component.code);
        if (codec == null) {
            throw new InvalidMultiaddrError(`Unknown protocol code ${component.code}`);
        }
        return [
            component.name,
            codec.valueToString?.(component.value) ?? component.value
        ];
    }).join('/')}`;
}
/**
 * For the passed address, return the serialized size
 */
function sizeForAddr(codec, bytes, offset) {
    if (codec.size == null || codec.size === 0) {
        return 0;
    }
    if (codec.size > 0) {
        return codec.size / 8;
    }
    return decode$4(bytes, offset);
}

const inspect = Symbol.for('nodejs.util.inspect.custom');
const symbol = Symbol.for('@multiformats/multiaddr');
const DNS_CODES = [
    CODE_DNS,
    CODE_DNS4,
    CODE_DNS6,
    CODE_DNSADDR
];
class NoAvailableResolverError extends Error {
    constructor(message = 'No available resolver') {
        super(message);
        this.name = 'NoAvailableResolverError';
    }
}
function toComponents(addr) {
    if (addr == null) {
        addr = '/';
    }
    if (isMultiaddr(addr)) {
        return addr.getComponents();
    }
    if (addr instanceof Uint8Array) {
        return bytesToComponents(addr);
    }
    if (typeof addr === 'string') {
        addr = addr
            .replace(/\/(\/)+/, '/')
            .replace(/(\/)+$/, '');
        if (addr === '') {
            addr = '/';
        }
        return stringToComponents(addr);
    }
    if (Array.isArray(addr)) {
        return addr;
    }
    throw new InvalidMultiaddrError('Must be a string, Uint8Array, Component[], or another Multiaddr');
}
/**
 * Creates a {@link Multiaddr} from a {@link MultiaddrInput}
 */
class Multiaddr {
    [symbol] = true;
    #components;
    // cache string representation
    #string;
    // cache byte representation
    #bytes;
    constructor(addr = '/', options = {}) {
        this.#components = toComponents(addr);
        if (options.validate !== false) {
            validate(this);
        }
    }
    get bytes() {
        if (this.#bytes == null) {
            this.#bytes = componentsToBytes(this.#components);
        }
        return this.#bytes;
    }
    toString() {
        if (this.#string == null) {
            this.#string = componentsToString(this.#components);
        }
        return this.#string;
    }
    toJSON() {
        return this.toString();
    }
    toOptions() {
        let family;
        let transport;
        let host;
        let port;
        let zone = '';
        for (const { code, name, value } of this.#components) {
            if (code === CODE_IP6ZONE) {
                zone = `%${value ?? ''}`;
            }
            // default to https when protocol & port are omitted from DNS addrs
            if (DNS_CODES.includes(code)) {
                transport = 'tcp';
                port = 443;
                host = `${value ?? ''}${zone}`;
                family = code === CODE_DNS6 ? 6 : 4;
            }
            if (code === CODE_TCP || code === CODE_UDP) {
                transport = name === 'tcp' ? 'tcp' : 'udp';
                port = parseInt(value ?? '');
            }
            if (code === CODE_IP4 || code === CODE_IP6) {
                transport = 'tcp';
                host = `${value ?? ''}${zone}`;
                family = code === CODE_IP6 ? 6 : 4;
            }
        }
        if (family == null || transport == null || host == null || port == null) {
            throw new Error('multiaddr must have a valid format: "/{ip4, ip6, dns4, dns6, dnsaddr}/{address}/{tcp, udp}/{port}".');
        }
        const opts = {
            family,
            host,
            transport,
            port
        };
        return opts;
    }
    getComponents() {
        return [
            ...this.#components
        ];
    }
    protos() {
        return this.#components.map(({ code, value }) => {
            const codec = registry.getProtocol(code);
            return {
                code,
                size: codec.size ?? 0,
                name: codec.name,
                resolvable: Boolean(codec.resolvable),
                path: Boolean(codec.path)
            };
        });
    }
    protoCodes() {
        return this.#components.map(({ code }) => code);
    }
    protoNames() {
        return this.#components.map(({ name }) => name);
    }
    tuples() {
        return this.#components.map(({ code, value }) => {
            if (value == null) {
                return [code];
            }
            const codec = registry.getProtocol(code);
            const output = [code];
            if (value != null) {
                output.push(codec.valueToBytes?.(value) ?? fromString(value));
            }
            return output;
        });
    }
    stringTuples() {
        return this.#components.map(({ code, value }) => {
            if (value == null) {
                return [code];
            }
            return [code, value];
        });
    }
    encapsulate(addr) {
        const ma = new Multiaddr(addr);
        return new Multiaddr([
            ...this.#components,
            ...ma.getComponents()
        ], {
            validate: false
        });
    }
    decapsulate(addr) {
        const addrString = addr.toString();
        const s = this.toString();
        const i = s.lastIndexOf(addrString);
        if (i < 0) {
            throw new InvalidParametersError(`Address ${this.toString()} does not contain subaddress: ${addr.toString()}`);
        }
        return new Multiaddr(s.slice(0, i), {
            validate: false
        });
    }
    decapsulateCode(code) {
        let index;
        for (let i = this.#components.length - 1; i > -1; i--) {
            if (this.#components[i].code === code) {
                index = i;
                break;
            }
        }
        return new Multiaddr(this.#components.slice(0, index), {
            validate: false
        });
    }
    getPeerId() {
        try {
            let tuples = [];
            this.#components.forEach(({ code, value }) => {
                if (code === CODE_P2P) {
                    tuples.push([code, value]);
                }
                // if this is a p2p-circuit address, return the target peer id if present
                // not the peer id of the relay
                if (code === CODE_P2P_CIRCUIT) {
                    tuples = [];
                }
            });
            // Get the last ipfs tuple ['p2p', 'peerid string']
            const tuple = tuples.pop();
            if (tuple?.[1] != null) {
                const peerIdStr = tuple[1];
                // peer id is base58btc encoded string but not multibase encoded so add the `z`
                // prefix so we can validate that it is correctly encoded
                if (peerIdStr[0] === 'Q' || peerIdStr[0] === '1') {
                    return toString(base58btc.decode(`z${peerIdStr}`), 'base58btc');
                }
                // try to parse peer id as CID
                return toString(CID.parse(peerIdStr).multihash.bytes, 'base58btc');
            }
            return null;
        }
        catch (e) {
            return null;
        }
    }
    getPath() {
        for (const component of this.#components) {
            const codec = registry.getProtocol(component.code);
            if (!codec.path) {
                continue;
            }
            return component.value ?? null;
        }
        return null;
    }
    equals(addr) {
        return equals(this.bytes, addr.bytes);
    }
    async resolve(options) {
        const resolvableProto = this.protos().find((p) => p.resolvable);
        // Multiaddr is not resolvable?
        if (resolvableProto == null) {
            return [this];
        }
        const resolver = resolvers.get(resolvableProto.name);
        if (resolver == null) {
            throw new NoAvailableResolverError(`no available resolver for ${resolvableProto.name}`);
        }
        const result = await resolver(this, options);
        return result.map(str => multiaddr(str));
    }
    nodeAddress() {
        const options = this.toOptions();
        if (options.transport !== 'tcp' && options.transport !== 'udp') {
            throw new Error(`multiaddr must have a valid format - no protocol with name: "${options.transport}". Must have a valid transport protocol: "{tcp, udp}"`);
        }
        return {
            family: options.family,
            address: options.host,
            port: options.port
        };
    }
    isThinWaistAddress() {
        if (this.#components.length !== 2) {
            return false;
        }
        if (this.#components[0].code !== CODE_IP4 && this.#components[0].code !== CODE_IP6) {
            return false;
        }
        if (this.#components[1].code !== CODE_TCP && this.#components[1].code !== CODE_UDP) {
            return false;
        }
        return true;
    }
    /**
     * Returns Multiaddr as a human-readable string
     * https://nodejs.org/api/util.html#utilinspectcustom
     *
     * @example
     * ```js
     * import { multiaddr } from '@multiformats/multiaddr'
     *
     * console.info(multiaddr('/ip4/127.0.0.1/tcp/4001'))
     * // 'Multiaddr(/ip4/127.0.0.1/tcp/4001)'
     * ```
     */
    [inspect]() {
        return `Multiaddr(${this.toString()})`;
    }
}
/**
 * Ensures all multiaddr tuples are correct. Throws if any invalid protocols or
 * values are encountered.
 */
function validate(addr) {
    addr.getComponents()
        .forEach(component => {
        const codec = registry.getProtocol(component.code);
        if (component.value == null) {
            return;
        }
        codec.validate?.(component.value);
    });
}

/**
 * @packageDocumentation
 *
 * A standard way to represent addresses that
 *
 * - support any standard network protocol
 * - are self-describing
 * - have a binary packed format
 * - have a nice string representation
 * - encapsulate well
 *
 * @example
 *
 * ```TypeScript
 * import { multiaddr } from '@multiformats/multiaddr'
 *
 * const addr = multiaddr('/ip4/127.0.0.1/udp/1234')
 * // Multiaddr(/ip4/127.0.0.1/udp/1234)
 *
 * addr.bytes
 * // <Uint8Array 04 7f 00 00 01 11 04 d2>
 *
 * addr.toString()
 * // '/ip4/127.0.0.1/udp/1234'
 *
 * addr.protos()
 * // [
 * //   {code: 4, name: 'ip4', size: 32},
 * //   {code: 273, name: 'udp', size: 16}
 * // ]
 *
 * // gives you an object that is friendly with what Node.js core modules expect for addresses
 * addr.nodeAddress()
 * // {
 * //   family: 4,
 * //   port: 1234,
 * //   address: "127.0.0.1"
 * // }
 *
 * addr.encapsulate('/sctp/5678')
 * // Multiaddr(/ip4/127.0.0.1/udp/1234/sctp/5678)
 * ```
 *
 * ## Resolving DNSADDR addresses
 *
 * [DNSADDR](https://github.com/multiformats/multiaddr/blob/master/protocols/DNSADDR.md) is a spec that allows storing a TXT DNS record that contains a Multiaddr.
 *
 * To resolve DNSADDR addresses, call the `.resolve()` function the multiaddr, optionally passing a `DNS` resolver.
 *
 * DNSADDR addresses can resolve to multiple multiaddrs, since there is no limit to the number of TXT records that can be stored.
 *
 * @example Resolving DNSADDR Multiaddrs
 *
 * ```TypeScript
 * import { multiaddr, resolvers } from '@multiformats/multiaddr'
 * import { dnsaddrResolver } from '@multiformats/multiaddr/resolvers'
 *
 * resolvers.set('dnsaddr', dnsaddrResolver)
 *
 * const ma = multiaddr('/dnsaddr/bootstrap.libp2p.io')
 *
 * // resolve with a 5s timeout
 * const resolved = await ma.resolve({
 *   signal: AbortSignal.timeout(5000)
 * })
 *
 * console.info(resolved)
 * // [Multiaddr('/ip4/147.75...'), Multiaddr('/ip4/147.75...'), Multiaddr('/ip4/147.75...')...]
 * ```
 *
 * @example Using a custom DNS resolver to resolve DNSADDR Multiaddrs
 *
 * See the docs for [@multiformats/dns](https://www.npmjs.com/package/@multiformats/dns) for a full breakdown of how to specify multiple resolvers or resolvers that can be used for specific TLDs.
 *
 * ```TypeScript
 * import { multiaddr } from '@multiformats/multiaddr'
 * import { dns } from '@multiformats/dns'
 * import { dnsJsonOverHttps } from '@multiformats/dns/resolvers'
 *
 * const resolver = dns({
 *   resolvers: {
 *     '.': dnsJsonOverHttps('https://cloudflare-dns.com/dns-query')
 *   }
 * })
 *
 * const ma = multiaddr('/dnsaddr/bootstrap.libp2p.io')
 * const resolved = await ma.resolve({
 *  dns: resolver
 * })
 *
 * console.info(resolved)
 * // [Multiaddr('/ip4/147.75...'), Multiaddr('/ip4/147.75...'), Multiaddr('/ip4/147.75...')...]
 * ```
 *
 * @example Adding custom protocols
 *
 * To add application-specific or experimental protocols, add a protocol codec
 * to the protocol registry:
 *
 * ```ts
 * import { registry, V, multiaddr } from '@multiformats/multiaddr'
 * import type { ProtocolCodec } from '@multiformats/multiaddr'
 *
 * const maWithCustomTuple = '/custom-protocol/hello'
 *
 * // throws UnknownProtocolError
 * multiaddr(maWithCustomTuple)
 *
 * const protocol: ProtocolCodec = {
 *   code: 2059,
 *   name: 'custom-protocol',
 *   size: V
 *   // V means variable length, can also be 0, a positive integer (e.g. a fixed
 *   // length or omitted
 * }
 *
 * registry.addProtocol(protocol)
 *
 * // does not throw UnknownProtocolError
 * multiaddr(maWithCustomTuple)
 *
 * // protocols can also be removed
 * registry.removeProtocol(protocol.code)
 * ```
 */
/**
 * All configured {@link Resolver}s
 *
 * @deprecated DNS resolving will be removed in a future release
 */
const resolvers = new Map();
/**
 * Check if object is a {@link Multiaddr} instance
 *
 * @example
 *
 * ```js
 * import { isMultiaddr, multiaddr } from '@multiformats/multiaddr'
 *
 * isMultiaddr(5)
 * // false
 * isMultiaddr(multiaddr('/ip4/127.0.0.1'))
 * // true
 * ```
 */
function isMultiaddr(value) {
    return Boolean(value?.[symbol]);
}
/**
 * A function that takes a {@link MultiaddrInput} and returns a {@link Multiaddr}
 *
 * @example
 * ```js
 * import { multiaddr } from '@libp2p/multiaddr'
 *
 * multiaddr('/ip4/127.0.0.1/tcp/4001')
 * // Multiaddr(/ip4/127.0.0.1/tcp/4001)
 * ```
 *
 * @param {MultiaddrInput} [addr] - If String or Uint8Array, needs to adhere to the address format of a [multiaddr](https://github.com/multiformats/multiaddr#string-format)
 */
function multiaddr(addr) {
    return new Multiaddr(addr);
}

/**
 * Reads peer's metadata and retrieves ping value.
 * @param peer Peer or null
 * @returns -1 if no ping attached, otherwise returns ping value
 */
const getPeerPing = (peer) => {
    if (!peer) {
        return -1;
    }
    try {
        const bytes = peer.metadata.get("ping");
        if (!bytes) {
            return -1;
        }
        return Number(bytesToUtf8(bytes));
    }
    catch (e) {
        return -1;
    }
};
/**
 * Maps a PeerId or MultiaddrInput to a PeerId or Multiaddr.
 * @param input - The PeerId or MultiaddrInput to map.
 * @returns The PeerId or Multiaddr.
 * @throws {Error} If the input is not a valid PeerId or MultiaddrInput.
 */
const mapToPeerIdOrMultiaddr = (input) => {
    return isPeerId(input) ? input : multiaddr(input);
};
/**
 * Maps a PeerId or MultiaddrInput to a PeerId.
 * @param input - The PeerId or MultiaddrInput to map.
 * @returns The PeerId.
 * @throws {Error} If the input is not a valid PeerId or MultiaddrInput.
 */
const mapToPeerId = (input) => {
    return isPeerId(input)
        ? input
        : peerIdFromString(multiaddr(input).getPeerId());
};
/**
 * Checks if the address is supported by the libp2p instance.
 * @param libp2p - The libp2p instance.
 * @param addresses - The addresses to check.
 * @returns True if the addresses are supported, false otherwise.
 */
const isAddressesSupported = (libp2p, addresses) => {
    const transports = libp2p?.components?.transportManager?.getTransports() || [];
    if (transports.length === 0) {
        return false;
    }
    return transports
        .map((transport) => transport.dialFilter(addresses))
        .some((supportedAddresses) => supportedAddresses.length > 0);
};

const log$6 = new Logger("connection-limiter");
const DEFAULT_CONNECTION_MONITOR_INTERVAL = 5 * 1_000;
/**
 * This class is responsible for limiting the number of connections to peers.
 * It also dials all known peers because libp2p might have emitted `peer:discovery` before initialization
 * and listen to `peer:connect` and `peer:disconnect` events to manage connections.
 */
class ConnectionLimiter {
    libp2p;
    events;
    networkMonitor;
    dialer;
    connectionMonitorInterval = null;
    options;
    constructor(options) {
        this.libp2p = options.libp2p;
        this.events = options.events;
        this.networkMonitor = options.networkMonitor;
        this.dialer = options.dialer;
        this.options = options.options;
        this.onWakuConnectionEvent = this.onWakuConnectionEvent.bind(this);
        this.onDisconnectedEvent = this.onDisconnectedEvent.bind(this);
    }
    start() {
        // dial all known peers because libp2p might have emitted `peer:discovery` before initialization
        void this.dialPeersFromStore();
        if (this.options.enableAutoRecovery &&
            this.connectionMonitorInterval === null) {
            this.connectionMonitorInterval = setInterval(() => void this.maintainConnections(), DEFAULT_CONNECTION_MONITOR_INTERVAL);
        }
        this.events.addEventListener(WakuEvent.Connection, this.onWakuConnectionEvent);
        /**
         * NOTE: Event is not being emitted on closing nor losing a connection.
         * @see https://github.com/libp2p/js-libp2p/issues/939
         * @see https://github.com/status-im/js-waku/issues/252
         *
         * >This event will be triggered anytime we are disconnected from another peer,
         * >regardless of the circumstances of that disconnection.
         * >If we happen to have multiple connections to a peer,
         * >this event will **only** be triggered when the last connection is closed.
         * @see https://github.com/libp2p/js-libp2p/blob/bad9e8c0ff58d60a78314077720c82ae331cc55b/doc/API.md?plain=1#L2100
         */
        this.libp2p.addEventListener("peer:disconnect", this.onDisconnectedEvent);
    }
    stop() {
        this.events.removeEventListener(WakuEvent.Connection, this.onWakuConnectionEvent);
        this.libp2p.removeEventListener("peer:disconnect", this.onDisconnectedEvent);
        if (this.connectionMonitorInterval) {
            clearInterval(this.connectionMonitorInterval);
            this.connectionMonitorInterval = null;
        }
    }
    onWakuConnectionEvent() {
        if (!this.options.enableAutoRecovery) {
            log$6.info(`Auto recovery is disabled, skipping`);
            return;
        }
        if (this.networkMonitor.isBrowserConnected()) {
            void this.dialPeersFromStore();
        }
    }
    async maintainConnections() {
        await this.maintainConnectionsCount();
        await this.maintainBootstrapConnections();
    }
    async onDisconnectedEvent() {
        if (this.libp2p.getConnections().length === 0) {
            log$6.info(`No connections, dialing peers from store`);
            await this.dialPeersFromStore();
        }
    }
    async maintainConnectionsCount() {
        log$6.info(`Maintaining connections count`);
        const connections = this.libp2p.getConnections();
        if (connections.length <= this.options.maxConnections) {
            log$6.info(`Node has less than max connections ${this.options.maxConnections}, trying to dial more peers`);
            const peers = await this.getPrioritizedPeers();
            if (peers.length === 0) {
                log$6.info(`No peers to dial, skipping`);
                await this.triggerBootstrap();
                return;
            }
            const promises = peers
                .slice(0, this.options.maxConnections - connections.length)
                .map((p) => this.dialer.dial(p.id));
            await Promise.all(promises);
            return;
        }
        log$6.info(`Node has more than max connections ${this.options.maxConnections}, dropping connections`);
        try {
            const connectionsToDrop = connections
                .filter((c) => !c.tags.includes(CONNECTION_LOCKED_TAG))
                .slice(this.options.maxConnections);
            if (connectionsToDrop.length === 0) {
                log$6.info(`No connections to drop, skipping`);
                return;
            }
            const promises = connectionsToDrop.map((c) => this.libp2p.hangUp(c.remotePeer));
            await Promise.all(promises);
            log$6.info(`Dropped ${connectionsToDrop.length} connections`);
        }
        catch (error) {
            log$6.error(`Unexpected error while maintaining connections`, error);
        }
    }
    async maintainBootstrapConnections() {
        log$6.info(`Maintaining bootstrap connections`);
        const bootstrapPeers = await this.getBootstrapPeers();
        if (bootstrapPeers.length <= this.options.maxBootstrapPeers) {
            return;
        }
        try {
            const peersToDrop = bootstrapPeers.slice(this.options.maxBootstrapPeers);
            log$6.info(`Dropping ${peersToDrop.length} bootstrap connections because node has more than max bootstrap connections ${this.options.maxBootstrapPeers}`);
            const promises = peersToDrop.map((p) => this.libp2p.hangUp(p.id));
            await Promise.all(promises);
            log$6.info(`Dropped ${peersToDrop.length} bootstrap connections`);
        }
        catch (error) {
            log$6.error(`Unexpected error while maintaining bootstrap connections`, error);
        }
    }
    async dialPeersFromStore() {
        log$6.info(`Dialing peers from store`);
        try {
            const peers = await this.getPrioritizedPeers();
            if (peers.length === 0) {
                log$6.info(`No peers to dial, skipping`);
                await this.triggerBootstrap();
                return;
            }
            const promises = peers.map((p) => this.dialer.dial(p.id));
            log$6.info(`Dialing ${peers.length} peers from store`);
            await Promise.all(promises);
            log$6.info(`Dialed ${promises.length} peers from store`);
        }
        catch (error) {
            log$6.error(`Unexpected error while dialing peer store peers`, error);
        }
    }
    /**
     * Returns a list of peers ordered by priority:
     * - bootstrap peers
     * - peers from peer exchange
     * - peers from peer cache (last because we are not sure that locally stored information is up to date)
     */
    async getPrioritizedPeers() {
        const allPeers = await this.libp2p.peerStore.all();
        const allConnections = this.libp2p.getConnections();
        const allConnectionsSet = new Set(allConnections.map((c) => c.remotePeer.toString()));
        log$6.info(`Found ${allPeers.length} peers in store, and found ${allConnections.length} connections`);
        const notConnectedPeers = allPeers.filter((p) => !allConnectionsSet.has(p.id.toString()) &&
            isAddressesSupported(this.libp2p, p.addresses.map((a) => a.multiaddr)));
        const bootstrapPeers = notConnectedPeers.filter((p) => p.tags.has(Tags.BOOTSTRAP));
        const peerExchangePeers = notConnectedPeers.filter((p) => p.tags.has(Tags.PEER_EXCHANGE));
        const localStorePeers = notConnectedPeers.filter((p) => p.tags.has(Tags.PEER_CACHE));
        const restPeers = notConnectedPeers.filter((p) => !p.tags.has(Tags.BOOTSTRAP) &&
            !p.tags.has(Tags.PEER_EXCHANGE) &&
            !p.tags.has(Tags.PEER_CACHE));
        return [
            ...bootstrapPeers,
            ...peerExchangePeers,
            ...localStorePeers,
            ...restPeers
        ];
    }
    async getBootstrapPeers() {
        const peers = await Promise.all(this.libp2p
            .getConnections()
            .map((conn) => conn.remotePeer)
            .map((id) => this.getPeer(id)));
        return peers.filter((peer) => peer && peer.tags.has(Tags.BOOTSTRAP));
    }
    async getPeer(peerId) {
        try {
            return await this.libp2p.peerStore.get(peerId);
        }
        catch (error) {
            log$6.error(`Failed to get peer ${peerId}, error: ${error}`);
            return null;
        }
    }
    /**
     * Triggers the bootstrap or peer cache discovery if they are mounted.
     * @returns void
     */
    async triggerBootstrap() {
        log$6.info("Triggering bootstrap discovery");
        const bootstrapComponents = Object.values(this.libp2p.components.components)
            .filter((c) => !!c)
            .filter((c) => [`@waku/${Tags.BOOTSTRAP}`, `@waku/${Tags.PEER_CACHE}`].includes(c?.[Symbol.toStringTag]));
        if (bootstrapComponents.length === 0) {
            log$6.warn("No bootstrap components found to trigger");
            return;
        }
        log$6.info(`Found ${bootstrapComponents.length} bootstrap components, starting them`);
        const promises = bootstrapComponents.map(async (component) => {
            try {
                await component?.stop?.();
                await component?.start?.();
                log$6.info("Successfully started bootstrap component");
            }
            catch (error) {
                log$6.error("Failed to start bootstrap component", error);
            }
        });
        await Promise.all(promises);
    }
}

const log$5 = new Logger("dialer");
class Dialer {
    libp2p;
    shardReader;
    options;
    dialingQueue = [];
    dialHistory = new Map();
    failedDials = new Map();
    dialingInterval = null;
    isProcessing = false;
    isImmediateDialing = false;
    constructor(options) {
        this.libp2p = options.libp2p;
        this.shardReader = options.shardReader;
        this.options = options.options;
    }
    start() {
        log$5.info("Starting dialer");
        if (!this.dialingInterval) {
            this.dialingInterval = setInterval(() => {
                void this.processQueue();
            }, 500);
        }
        this.dialHistory.clear();
        this.failedDials.clear();
    }
    stop() {
        log$5.info("Stopping dialer");
        if (this.dialingInterval) {
            clearInterval(this.dialingInterval);
            this.dialingInterval = null;
        }
        this.dialHistory.clear();
        this.failedDials.clear();
    }
    async dial(peerId) {
        const shouldSkip = await this.shouldSkipPeer(peerId);
        if (shouldSkip) {
            log$5.info(`Skipping peer: ${peerId}`);
            return;
        }
        const isEmptyQueue = this.dialingQueue.length === 0;
        const isNotDialing = !this.isProcessing && !this.isImmediateDialing;
        // If queue is empty and we're not currently processing, dial immediately
        if (isEmptyQueue && isNotDialing) {
            this.isImmediateDialing = true;
            log$5.info("Dialed peer immediately");
            await this.dialPeer(peerId);
            this.isImmediateDialing = false;
            log$5.info("Released immediate dial lock");
        }
        else {
            this.dialingQueue.push(peerId);
            log$5.info(`Added peer to dialing queue, queue size: ${this.dialingQueue.length}`);
        }
    }
    async processQueue() {
        if (this.dialingQueue.length === 0 || this.isProcessing) {
            return;
        }
        this.isProcessing = true;
        try {
            const peersToDial = this.dialingQueue.slice(0, this.options.maxDialingPeers);
            this.dialingQueue = this.dialingQueue.slice(peersToDial.length);
            log$5.info(`Processing dial queue: dialing ${peersToDial.length} peers, ${this.dialingQueue.length} remaining in queue`);
            await Promise.all(peersToDial.map((peerId) => this.dialPeer(peerId)));
        }
        finally {
            this.isProcessing = false;
        }
    }
    async dialPeer(peerId) {
        try {
            log$5.info(`Dialing peer from queue: ${peerId}`);
            await this.libp2p.dial(peerId);
            this.dialHistory.set(peerId.toString(), Date.now());
            this.failedDials.delete(peerId.toString());
            log$5.info(`Successfully dialed peer from queue: ${peerId}`);
        }
        catch (error) {
            log$5.error(`Error dialing peer ${peerId}`, error);
            this.failedDials.set(peerId.toString(), Date.now());
        }
    }
    async shouldSkipPeer(peerId) {
        const hasConnection = this.libp2p.getPeers().some((p) => p.equals(peerId));
        if (hasConnection) {
            log$5.info(`Skipping peer ${peerId} - already connected`);
            return true;
        }
        if (this.isRecentlyDialed(peerId)) {
            log$5.info(`Skipping peer ${peerId} - already dialed in the last 10 seconds`);
            return true;
        }
        if (this.isRecentlyFailed(peerId)) {
            log$5.info(`Skipping peer ${peerId} - recently failed to dial`);
            return true;
        }
        try {
            const hasShardInfo = await this.shardReader.hasShardInfo(peerId);
            if (!hasShardInfo) {
                log$5.info(`Skipping peer ${peerId} - no shard info`);
                return false;
            }
            const isOnSameCluster = await this.shardReader.isPeerOnCluster(peerId);
            if (!isOnSameCluster) {
                log$5.info(`Skipping peer ${peerId} - not on same cluster`);
                return true;
            }
            return false;
        }
        catch (error) {
            log$5.error(`Error checking shard info for peer ${peerId}`, error);
            return true; // Skip peer when there's an error
        }
    }
    isRecentlyDialed(peerId) {
        const lastDialed = this.dialHistory.get(peerId.toString());
        if (lastDialed &&
            Date.now() - lastDialed < this.options.dialCooldown * 1000) {
            return true;
        }
        return false;
    }
    isRecentlyFailed(peerId) {
        const lastFailed = this.failedDials.get(peerId.toString());
        if (lastFailed &&
            Date.now() - lastFailed < this.options.failedDialCooldown * 1000) {
            return true;
        }
        return false;
    }
}

const log$4 = new Logger("discovery-dialer");
/**
 * This class is responsible for dialing peers that are discovered by the libp2p node.
 * Managing limits for the peers is out of scope for this class.
 * Dialing after discovery is needed to identify the peer and get all other information: metadata, protocols, etc.
 */
class DiscoveryDialer {
    libp2p;
    dialer;
    constructor(options) {
        this.libp2p = options.libp2p;
        this.dialer = options.dialer;
        this.onPeerDiscovery = this.onPeerDiscovery.bind(this);
    }
    start() {
        this.libp2p.addEventListener("peer:discovery", this.onPeerDiscovery);
    }
    stop() {
        this.libp2p.removeEventListener("peer:discovery", this.onPeerDiscovery);
    }
    async onPeerDiscovery(event) {
        const peerId = event.detail.id;
        log$4.info(`Discovered new peer: ${peerId}`);
        try {
            await this.updatePeerStore(peerId, event.detail.multiaddrs);
            await this.dialer.dial(peerId);
        }
        catch (error) {
            log$4.error(`Error dialing peer ${peerId}`, error);
        }
    }
    async updatePeerStore(peerId, multiaddrs) {
        try {
            log$4.info(`Updating peer store for ${peerId}`);
            const peer = await this.getPeer(peerId);
            if (!peer) {
                log$4.info(`Peer ${peerId} not found in store, saving`);
                await this.libp2p.peerStore.save(peerId, {
                    multiaddrs: multiaddrs
                });
                return;
            }
            const hasSameAddr = multiaddrs.every((addr) => peer.addresses.some((a) => a.multiaddr.equals(addr)));
            if (hasSameAddr) {
                log$4.info(`Peer ${peerId} has same addresses in peer store, skipping`);
                return;
            }
            log$4.info(`Merging peer ${peerId} addresses in peer store`);
            await this.libp2p.peerStore.merge(peerId, {
                multiaddrs: multiaddrs
            });
        }
        catch (error) {
            log$4.error(`Error updating peer store for ${peerId}`, error);
        }
    }
    async getPeer(peerId) {
        try {
            return await this.libp2p.peerStore.get(peerId);
        }
        catch (error) {
            log$4.error(`Error getting peer info for ${peerId}`, error);
            return undefined;
        }
    }
}

const RelayPingContentTopic = "/relay-ping/1/ping/null";
const log$3 = new Logger("keep-alive");
class KeepAliveManager {
    relay;
    networkConfig;
    libp2p;
    options;
    pingKeepAliveTimers = new Map();
    relayKeepAliveTimers = new Map();
    constructor({ options, relay, networkConfig, libp2p }) {
        this.options = options;
        this.relay = relay;
        this.networkConfig = networkConfig;
        this.libp2p = libp2p;
        this.onPeerConnect = this.onPeerConnect.bind(this);
        this.onPeerDisconnect = this.onPeerDisconnect.bind(this);
    }
    start() {
        this.libp2p.addEventListener("peer:connect", this.onPeerConnect);
        this.libp2p.addEventListener("peer:disconnect", this.onPeerDisconnect);
    }
    stop() {
        this.libp2p.removeEventListener("peer:connect", this.onPeerConnect);
        this.libp2p.removeEventListener("peer:disconnect", this.onPeerDisconnect);
        for (const timer of this.pingKeepAliveTimers.values()) {
            clearInterval(timer);
        }
        for (const timerArray of this.relayKeepAliveTimers.values()) {
            for (const timer of timerArray) {
                clearInterval(timer);
            }
        }
        this.pingKeepAliveTimers.clear();
        this.relayKeepAliveTimers.clear();
    }
    onPeerConnect(evt) {
        const peerId = evt.detail;
        this.startPingForPeer(peerId);
    }
    onPeerDisconnect(evt) {
        const peerId = evt.detail;
        this.stopPingForPeer(peerId);
    }
    startPingForPeer(peerId) {
        // Just in case a timer already exists for this peer
        this.stopPingForPeer(peerId);
        this.startLibp2pPing(peerId);
        this.startRelayPing(peerId);
    }
    stopPingForPeer(peerId) {
        this.stopLibp2pPing(peerId);
        this.stopRelayPing(peerId);
    }
    startLibp2pPing(peerId) {
        if (this.options.pingKeepAlive === 0) {
            log$3.warn(`Ping keep alive is disabled pingKeepAlive:${this.options.pingKeepAlive}, skipping start for libp2p ping`);
            return;
        }
        const peerIdStr = peerId.toString();
        if (this.pingKeepAliveTimers.has(peerIdStr)) {
            log$3.warn(`Ping already started for peer: ${peerIdStr}, skipping start for libp2p ping`);
            return;
        }
        const interval = setInterval(() => {
            void this.pingLibp2p(peerId);
        }, this.options.pingKeepAlive * 1000);
        this.pingKeepAliveTimers.set(peerIdStr, interval);
    }
    stopLibp2pPing(peerId) {
        const peerIdStr = peerId.toString();
        if (!this.pingKeepAliveTimers.has(peerIdStr)) {
            log$3.warn(`Ping not started for peer: ${peerIdStr}, skipping stop for ping`);
            return;
        }
        clearInterval(this.pingKeepAliveTimers.get(peerIdStr));
        this.pingKeepAliveTimers.delete(peerIdStr);
    }
    startRelayPing(peerId) {
        if (!this.relay) {
            return;
        }
        if (this.options.relayKeepAlive === 0) {
            log$3.warn(`Relay keep alive is disabled relayKeepAlive:${this.options.relayKeepAlive}, skipping start for relay ping`);
            return;
        }
        if (this.relayKeepAliveTimers.has(peerId.toString())) {
            log$3.warn(`Relay ping already started for peer: ${peerId.toString()}, skipping start for relay ping`);
            return;
        }
        const intervals = [];
        for (const topic of this.relay.pubsubTopics) {
            const meshPeers = this.relay.getMeshPeers(topic);
            if (!meshPeers.includes(peerId.toString())) {
                log$3.warn(`Peer: ${peerId.toString()} is not in the mesh for topic: ${topic}, skipping start for relay ping`);
                continue;
            }
            const routingInfo = createRoutingInfo(this.networkConfig, {
                contentTopic: RelayPingContentTopic,
                pubsubTopic: topic
            });
            const encoder = createEncoder({
                routingInfo: routingInfo,
                contentTopic: RelayPingContentTopic,
                ephemeral: true
            });
            const interval = setInterval(() => {
                void this.pingRelay(encoder);
            }, this.options.relayKeepAlive * 1000);
            intervals.push(interval);
        }
        this.relayKeepAliveTimers.set(peerId.toString(), intervals);
    }
    stopRelayPing(peerId) {
        if (!this.relay) {
            return;
        }
        const peerIdStr = peerId.toString();
        if (!this.relayKeepAliveTimers.has(peerIdStr)) {
            log$3.warn(`Relay ping not started for peer: ${peerIdStr}, skipping stop for relay ping`);
            return;
        }
        this.relayKeepAliveTimers.get(peerIdStr)?.map(clearInterval);
        this.relayKeepAliveTimers.delete(peerIdStr);
    }
    async pingRelay(encoder) {
        try {
            log$3.info("Sending Waku Relay ping message");
            await this.relay.send(encoder, { payload: new Uint8Array([1]) });
        }
        catch (e) {
            log$3.error("Failed to send relay ping", e);
        }
    }
    async pingLibp2p(peerId) {
        try {
            log$3.info(`Pinging libp2p peer (${peerId.toString()})`);
            const ping = await this.libp2p.services.ping.ping(peerId);
            log$3.info(`Ping succeeded (${peerId.toString()})`, ping);
            await this.libp2p.peerStore.merge(peerId, {
                metadata: {
                    ping: utf8ToBytes(ping.toString())
                }
            });
            log$3.info(`Ping updated for peer (${peerId.toString()})`);
        }
        catch (e) {
            log$3.error(`Ping failed for peer (${peerId.toString()})`, e);
        }
    }
}

class NetworkMonitor {
    libp2p;
    events;
    isNetworkConnected = false;
    constructor(options) {
        this.libp2p = options.libp2p;
        this.events = options.events;
        this.onConnectedEvent = this.onConnectedEvent.bind(this);
        this.onDisconnectedEvent = this.onDisconnectedEvent.bind(this);
        this.dispatchNetworkEvent = this.dispatchNetworkEvent.bind(this);
    }
    start() {
        this.libp2p.addEventListener("peer:connect", this.onConnectedEvent);
        this.libp2p.addEventListener("peer:disconnect", this.onDisconnectedEvent);
        try {
            globalThis.addEventListener("online", this.dispatchNetworkEvent);
            globalThis.addEventListener("offline", this.dispatchNetworkEvent);
        }
        catch (err) {
            // ignore
        }
    }
    stop() {
        this.libp2p.removeEventListener("peer:connect", this.onConnectedEvent);
        this.libp2p.removeEventListener("peer:disconnect", this.onDisconnectedEvent);
        try {
            globalThis.removeEventListener("online", this.dispatchNetworkEvent);
            globalThis.removeEventListener("offline", this.dispatchNetworkEvent);
        }
        catch (err) {
            // ignore
        }
    }
    /**
     * Returns true if the node is connected to the network via libp2p and browser.
     */
    isConnected() {
        if (!this.isBrowserConnected()) {
            return false;
        }
        return this.isP2PConnected();
    }
    /**
     * Returns true if the node is connected to the network via libp2p.
     */
    isP2PConnected() {
        return this.isNetworkConnected;
    }
    /**
     * Returns true if the node is connected to the network via browser.
     */
    isBrowserConnected() {
        try {
            if (globalThis?.navigator && !globalThis?.navigator?.onLine) {
                return false;
            }
        }
        catch (err) {
            // ignore
        }
        return true;
    }
    onConnectedEvent() {
        if (!this.isNetworkConnected) {
            this.isNetworkConnected = true;
            this.dispatchNetworkEvent();
        }
    }
    onDisconnectedEvent() {
        if (this.isNetworkConnected && this.libp2p.getConnections().length === 0) {
            this.isNetworkConnected = false;
            this.dispatchNetworkEvent();
        }
    }
    dispatchNetworkEvent() {
        this.events.dispatchEvent(new CustomEvent(WakuEvent.Connection, {
            detail: this.isConnected()
        }));
    }
}

const log$2 = new Logger("shard-reader");
/**
 * This class is responsible for reading the shard info from the libp2p peer store or from the current node's network config.
 */
class ShardReader {
    libp2p;
    clusterId;
    constructor(options) {
        this.libp2p = options.libp2p;
        this.clusterId = options.networkConfig.clusterId;
    }
    async isPeerOnCluster(id) {
        const peerRelayShards = await this.getRelayShards(id);
        if (!peerRelayShards) {
            return false;
        }
        return peerRelayShards.clusterId === this.clusterId;
    }
    async hasShardInfo(id) {
        const shardInfo = await this.getRelayShards(id);
        return !!shardInfo;
    }
    async isPeerOnTopic(id, pubsubTopic) {
        try {
            const { clusterId, shard } = pubsubTopicToSingleShardInfo(pubsubTopic);
            if (clusterId !== this.clusterId)
                return false;
            return await this.isPeerOnShard(id, shard);
        }
        catch (error) {
            log$2.error(`Error comparing pubsub topic ${pubsubTopic} with shard info for ${id}`, error);
            return false;
        }
    }
    async isPeerOnShard(id, shard) {
        const peerShardInfo = await this.getRelayShards(id);
        log$2.info(`Checking if peer on same shard: this { clusterId: ${this.clusterId}, shardId: ${shard} },` +
            `${id} { clusterId: ${peerShardInfo?.clusterId}, shards: ${peerShardInfo?.shards} }`);
        if (!peerShardInfo) {
            return false;
        }
        return (peerShardInfo.clusterId === this.clusterId &&
            peerShardInfo.shards.includes(shard));
    }
    async getRelayShards(id) {
        try {
            const peer = await this.libp2p.peerStore.get(id);
            const shardInfoBytes = peer.metadata.get("shardInfo");
            if (!shardInfoBytes) {
                return undefined;
            }
            return decodeRelayShard(shardInfoBytes);
        }
        catch (error) {
            log$2.error(`Error getting shard info for ${id}`, error);
            return undefined;
        }
    }
}

const log$1 = new Logger("connection-manager");
const DEFAULT_MAX_BOOTSTRAP_PEERS_ALLOWED = 3;
const DEFAULT_PING_KEEP_ALIVE_SEC = 5 * 60;
const DEFAULT_RELAY_KEEP_ALIVE_SEC = 5 * 60;
const DEFAULT_ENABLE_AUTO_RECOVERY = true;
const DEFAULT_MAX_CONNECTIONS = 10;
const DEFAULT_MAX_DIALING_PEERS = 3;
const DEFAULT_FAILED_DIAL_COOLDOWN_SEC = 60;
const DEFAULT_DIAL_COOLDOWN_SEC = 10;
class ConnectionManager {
    keepAliveManager;
    discoveryDialer;
    dialer;
    shardReader;
    networkMonitor;
    connectionLimiter;
    options;
    libp2p;
    constructor(options) {
        this.libp2p = options.libp2p;
        this.options = {
            maxBootstrapPeers: DEFAULT_MAX_BOOTSTRAP_PEERS_ALLOWED,
            maxConnections: DEFAULT_MAX_CONNECTIONS,
            pingKeepAlive: DEFAULT_PING_KEEP_ALIVE_SEC,
            relayKeepAlive: DEFAULT_RELAY_KEEP_ALIVE_SEC,
            enableAutoRecovery: DEFAULT_ENABLE_AUTO_RECOVERY,
            maxDialingPeers: DEFAULT_MAX_DIALING_PEERS,
            failedDialCooldown: DEFAULT_FAILED_DIAL_COOLDOWN_SEC,
            dialCooldown: DEFAULT_DIAL_COOLDOWN_SEC,
            ...options.config
        };
        this.keepAliveManager = new KeepAliveManager({
            relay: options.relay,
            libp2p: options.libp2p,
            networkConfig: options.networkConfig,
            options: {
                pingKeepAlive: this.options.pingKeepAlive,
                relayKeepAlive: this.options.relayKeepAlive
            }
        });
        this.shardReader = new ShardReader({
            libp2p: options.libp2p,
            networkConfig: options.networkConfig
        });
        this.dialer = new Dialer({
            libp2p: options.libp2p,
            shardReader: this.shardReader,
            options: this.options
        });
        this.discoveryDialer = new DiscoveryDialer({
            libp2p: options.libp2p,
            dialer: this.dialer
        });
        this.networkMonitor = new NetworkMonitor({
            libp2p: options.libp2p,
            events: options.events
        });
        this.connectionLimiter = new ConnectionLimiter({
            libp2p: options.libp2p,
            events: options.events,
            networkMonitor: this.networkMonitor,
            dialer: this.dialer,
            options: this.options
        });
    }
    start() {
        this.dialer.start();
        this.networkMonitor.start();
        this.discoveryDialer.start();
        this.keepAliveManager.start();
        this.connectionLimiter.start();
    }
    stop() {
        this.dialer.stop();
        this.networkMonitor.stop();
        this.discoveryDialer.stop();
        this.keepAliveManager.stop();
        this.connectionLimiter.stop();
    }
    isConnected() {
        return this.networkMonitor.isConnected();
    }
    async dial(peer, protocolCodecs) {
        const ma = mapToPeerIdOrMultiaddr(peer);
        log$1.info(`Dialing peer ${ma.toString()} with protocols ${protocolCodecs}`);
        // must use libp2p directly instead of dialer because we need to dial the peer right away
        const stream = await this.libp2p.dialProtocol(ma, protocolCodecs);
        log$1.info(`Dialed peer ${ma.toString()} with protocols ${protocolCodecs}`);
        return stream;
    }
    async hangUp(peer) {
        const peerId = mapToPeerId(peer);
        try {
            log$1.info(`Dropping connection with peer ${peerId.toString()}`);
            await this.libp2p.hangUp(peerId);
            log$1.info(`Dropped connection with peer ${peerId.toString()}`);
            return true;
        }
        catch (error) {
            log$1.error(`Error dropping connection with peer ${peerId.toString()} - ${error}`);
            return false;
        }
    }
    async getConnectedPeers(codec) {
        const peerIDs = this.libp2p.getPeers();
        log$1.info(`Getting connected peers for codec ${codec}`);
        if (peerIDs.length === 0) {
            log$1.info(`No connected peers`);
            return [];
        }
        const peers = await Promise.all(peerIDs.map(async (id) => {
            try {
                return await this.libp2p.peerStore.get(id);
            }
            catch (e) {
                return null;
            }
        }));
        const result = peers
            .filter((p) => !!p)
            .filter((p) => (codec ? p.protocols.includes(codec) : true))
            .sort((left, right) => getPeerPing(left) - getPeerPing(right));
        log$1.info(`Found ${result.length} connected peers for codec ${codec}`);
        return result;
    }
    async hasShardInfo(peerId) {
        return this.shardReader.hasShardInfo(peerId);
    }
    async isPeerOnTopic(peerId, pubsubTopic) {
        return this.shardReader.isPeerOnTopic(peerId, pubsubTopic);
    }
    async isPeerOnShard(peerId, shardId) {
        return this.shardReader.isPeerOnShard(peerId, shardId);
    }
}

const log = new Logger("metadata");
const MetadataCodec = "/vac/waku/metadata/1.0.0";
class Metadata {
    clusterId;
    streamManager;
    libp2pComponents;
    handshakesConfirmed = new Map();
    multicodec = MetadataCodec;
    constructor(clusterId, libp2p) {
        this.clusterId = clusterId;
        this.streamManager = new StreamManager(MetadataCodec, libp2p);
        this.libp2pComponents = libp2p;
        void libp2p.registrar.handle(MetadataCodec, (streamData) => {
            void this.onRequest(streamData);
        });
    }
    /**
     * Make a metadata query to a peer
     */
    async query(peerId) {
        const request = WakuMetadataRequest.encode({
            clusterId: this.clusterId,
            shards: [] // Only services node need to provide shards
        });
        const peer = await this.libp2pComponents.peerStore.get(peerId);
        if (!peer) {
            return {
                shardInfo: null,
                error: ProtocolError.NO_PEER_AVAILABLE
            };
        }
        const stream = await this.streamManager.getStream(peerId);
        if (!stream) {
            log.error(`Failed to get a stream for remote peer:${peerId.toString()}`);
            return {
                shardInfo: null,
                error: ProtocolError.NO_STREAM_AVAILABLE
            };
        }
        const encodedResponse = await pipe([request], encode, stream, decode, async (source) => await all(source));
        const { error, shardInfo } = this.decodeMetadataResponse(encodedResponse);
        if (error) {
            return {
                shardInfo: null,
                error
            };
        }
        await this.savePeerShardInfo(peerId, shardInfo);
        return {
            shardInfo,
            error: null
        };
    }
    async confirmOrAttemptHandshake(peerId) {
        const shardInfo = this.handshakesConfirmed.get(peerId.toString());
        if (shardInfo) {
            return {
                shardInfo,
                error: null
            };
        }
        return await this.query(peerId);
    }
    /**
     * Handle an incoming metadata request
     */
    async onRequest(streamData) {
        try {
            const { stream, connection } = streamData;
            const encodedShardInfo = WakuMetadataResponse.encode({
                clusterId: this.clusterId,
                shards: [] // Only service nodes need to provide shards
            });
            const encodedResponse = await pipe([encodedShardInfo], encode, stream, decode, async (source) => await all(source));
            const { error, shardInfo } = this.decodeMetadataResponse(encodedResponse);
            if (error) {
                return;
            }
            await this.savePeerShardInfo(connection.remotePeer, shardInfo);
        }
        catch (error) {
            log.error("Error handling metadata request", error);
        }
    }
    decodeMetadataResponse(encodedResponse) {
        const bytes = new Uint8ArrayList();
        encodedResponse.forEach((chunk) => {
            bytes.append(chunk);
        });
        const response = WakuMetadataResponse.decode(bytes);
        if (!response) {
            log.error("Error decoding metadata response");
            return {
                shardInfo: null,
                error: ProtocolError.DECODE_FAILED
            };
        }
        return {
            shardInfo: response,
            error: null
        };
    }
    async savePeerShardInfo(peerId, shardInfo) {
        // add or update the shardInfo to peer store
        await this.libp2pComponents.peerStore.merge(peerId, {
            metadata: {
                shardInfo: encodeRelayShard(shardInfo)
            }
        });
        this.handshakesConfirmed.set(peerId.toString(), shardInfo);
    }
}
function wakuMetadata(clusterId) {
    return (components) => new Metadata(clusterId, components);
}

export { ConnectionManager, FilterCodecs, FilterCore, LightPushCodec, LightPushCodecV2, LightPushCore, MetadataCodec, StoreCodec, StoreCore, StreamManager, createEncoder, index$3 as message, wakuMetadata, index$2 as waku_filter, index$1 as waku_light_push, index as waku_store };
